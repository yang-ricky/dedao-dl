# 207｜下一代计算：成果商业化加速

## 模块总结

模块的话题是下一代计算机，我们介绍了三个重点：

第一，传统经典计算机的发展是基于摩尔定律的，它面临着一个物理极限。于是，人们也在量子计算机、光子计算机和 DNA 计算机等几个方向上探索。

下一代计算机将来未必会取代现有计算机系统，很有可能是两者同时共存，并且与云计算相结合，发挥各自的优势。

不管你是不是 IT 从业者，它的发展都值得你关注。如果它的技术取得了突破，会为 IT 产业以及 IT 技术在其它产业上的应用，带来很多意想不到的机会。

第二，量子计算机是基础架构角度的创新，各大 IT 巨头都在争取“量子霸权”，希望使自己在产业竞争中优先占据有利地位。

但在目前：

* 量子计算机基本上不是样机就是测试芯片，它还有很长的路要走；

* 光子计算机是对现有计算机的补充，相对于量子计算机来说，可能会更快实现实用化；

* DNA 生物计算机也有望极大降低大规模运算的成本，特别是大规模储存的成本。

第三，D-Wave 和 Optalysys 这两家公司，分别在量子计算机和光子计算机领域率先走上了商业化的道路。

特别是 D-Wave，它在10多年前发布了第一台量子计算原型机之后，引发了众多 IT 巨头开始尝试商业化的道路，未来从研发到商业化的成果转化周期会越来越短。

## 用户问答

> “盗梦人”问：
> 
> 王老师，量子计算机的发展是否会影响加密货币的发展？

 **我的回答是： **

从原理上说是会的，因为我们讲过，量子计算机的原理，决定了每增加一个量子比特，理论上的计算能力就会翻倍，而我们也听过那个故事，国际象棋棋盘上第一个格子放1粒米，第二个格子放2粒米，第三个格子放4粒米，第四个格子放8粒米，这么一直放下去，全世界的粮食都放不满64个格子。

所以，  **未来量子计算机的量子比特数上去之后，对现有的数字加密算法能够实现破解，数字货币就不成立了。 **

但是这一天还很远，因为要做到足够多的量子实现纠缠是很难的，一方面要制造出足够多的量子纠缠，另一方面还要维持足够长的时间。

我们介绍了舒考夫定律，大约每3年时间，量子退相干的速度会被延迟10倍，可见量子计算的发展是要以年计的，短期难以有大突破，但只要有这种指数级的增长存在，未来就一定会很强大。

当然，对数字货币而言，也许计算能力的强大会催生出新的加密算法，未来也许会有新的更高级的数字货币诞生。

> “夏宝辉”问：
> 
> 现在的计算机、云计算、大数据、人工智能的开发研究方向都是基于机器学习，用无穷试错的办法，到了量子计算机时代，会有新的机器思维逻辑出现吗？不是靠不断试错来找最近的路和大数分解，而是在逻辑领域有新的底层架构，加快人工智能向更智能化的方向发展吗？

 **我的回答是： **

不能这么笼统地说，机器学习目前还只是人工智能的一个分支，而计算机并不是架构在机器学习基础上的。而人工智能、机器学习，乃至量子计算机都没有突破计算机的基础，也就是图灵机的思路。

所谓图灵机，简单说就是把现实问题转换成0、1、0、1这样的数学符号，能够进行逻辑运算以求解的系统，自然界大量问题都是可以进行这样的转化的，所以我们的计算机不光能做数学运算，还能帮我们解决很多现实问题。

人工智能延用的还是这样的思路，只不过在计算方法上大大改进了，使得效率提升。

 **量子计算机可以看作是另一次方法的改进和效率的飞跃，但其图灵机的思路没变，所以也会碰到图灵机的问题，就是现实世界当中确实存在不可计算的问题。 **

当然，可计算问题也存在计算量的问题，有些问题可计算，但计算量大到无法承受，比如我们前一个问题说到的加密算法问题。可计算，但现有最好水平的计算机也要上千年才能计算出来，那这个加密算法就已经安全了。

 **人工智能提升计算效率是有特定前提的，并不是无穷试错，而是模式识别。 ** 通过抽提出模式更快地找到解，这在用计算机来解决人类所擅长的问题时会有价值。

比如图像识别，因为人类最擅长的其实就是模式识别，和现有的人工智能系统很像，但在粗暴计算时人工智能就没有用了，所以用人工智能算法难以缩短破解基于大数据分解原理而设定的密码的时间。

而量子计算适用的领域则不同，利用到量子纠缠以提升通用型的算力，我们上一个问题提到了量子纠缠的算力提升是指数级的，这个还是通用计算，或者我们讲到的很多量子计算是指利用量子隧道效应的退火算法来计算路径问题和天气问题等特定问题。

所谓退火，就是给定一个不稳定态，让它自动降低能级进入稳定态，因为这个稳定态其实就是最后的解，所以我们说也相当于是自然算法，但必须量子计算才行。

我们打个比方，相当于从山顶释放一堆小球，它们最后滚到的谷底就是最稳定的状态，但是现实世界里的实体小球可能滚到了山腰上的洼地就不能继续向下滚了，而量子隧道效应的意思是，在量子世界，这些物理的障碍不存在，只要有能级更低的地方，小球就可以继续滚，就好像有个隧道使小球从山这边的洼地穿到了山那边更低的低谷。

而有很多问题不利用量子计算，用传统算法，需要的算力是很惊人的。

 **所以我们说，通用的量子计算提升整体计算水平，但特定领域的量子计算和人工智能一样，各有各的应用场景，互相不能替代。 **

> “Rick_Zheng”问：
> 
> 王老师，这两天 Google Assistant 帮主人预约理发师的这段演示刷屏了，对方完全没有意识到是跟人工智能对话，能请你评价一下这个新闻吗？

 **我的回答是： **

这是典型的人工智能的进步，我们说过，智能翻译这两年会有突破，我们在前哨大会上也都用到了搜狗的智能翻译，其核心是语音识别和语意识别，这两者都要用到人工智能。

我们说人工智能的进步有三部分：

> 算法、算力和大数据训练。

谷歌的算法很多是 DeepMind 团队在开发，就在谷歌展示 Google Assistant 的 I/O 大会的第二天，《自然》杂志在线发表了 DeepMind 团队的新论文。

我们说人类的空间识别和空间规划能力很强，但是其原因原来一直不知道，直到2005年才被科学家找到：

> 人类大脑中存在一类网格细胞。

这个成果获得了2014年的诺贝尔生理学奖。

 **现在 DeepMind 团队用人工智能自己找到了类似网格细胞的能力，空间识别和规划能力大大加强，也能够像人一样识别最优路径并且抄近道了。 **

我们说原来是人工智能向人类智能学习，有所谓的神经网络算法、类脑计算等等。

 **现在人工智能进化的速度大大加快，有很多地方赶上了人脑，如果在人类对人脑技能尚不清楚的领域，很可能可以反过来借助人工智能来了解大脑构造和机能，这可能会对认知科学带来飞跃，这是一个了不起的进步。 **

而从算力角度看，谷歌公布的新的人工智能处理器 TPU3.0，性能比上一代 TPU 提升了8倍，达到了每秒1000万亿次浮点计算的速度。

我们可以对比一下英伟达在2018年1月在 CES 展上推出的 Xavier 处理器，其处理能力是30万亿次浮点计算，比谷歌新推出的 TPU 要弱了30倍。

当然，不是说谷歌就能干掉英伟达了，因为英伟达主要用在自动驾驶上，自动驾驶还有一个能耗问题，而谷歌的 TPU 是不卖的，只用在自己的云计算平台上，也就是放在自己的数据中心里，数据中心里的处理器相对而言对能耗的要求没那么高。

当然另一方面讲，谷歌 TPU 不卖，所以没有第三方能够跑谷歌的处理器和别人的处理器来作对比，所以我们只能相信谷歌自己公布的数据了，不过这也体现了谷歌对数据中心的重视，生产多少 TPU 自己消化得了，都用得了，而且据说还采购了不少英伟达的 GPU。

尤其是未来有了 5G，可以用云计算支持本地的计算需求，所以未来人工智能的云计算市场可是太大了。我们会像今天离不开互联网一样离不开人工智能的支持的。

至于说第三点，数据集，那就是谷歌音箱、谷歌搜索、谷歌 Android 手机操作系统的价值了，这些都有机会让谷歌收集大量互动数据，不断完善自己的人工智能能力。所以谷歌在人工智能领域的第一梯队的位置还是相当牢固的。

当然，即使做到这个水平，人工智能距离人还是有差距的，因为这都还是单一领域的智能，所以叫弱人工智能，而人最强的是多领域的综合分析和判断，叫做通用人工智能。

不过就像我们讲到的，人工智能对认知科学会有促进，现在已经有人工智能在试图把两个甚至两个以上的领域的数据进行整合了。

也许有一天会达到人的高度，人会突然发现其实所谓强人工智能也没有什么特别的，就是把几个弱人工智能整合起来就是了。

或者发现强人工智能不是弱人工智能的简单整合，人工智能还是赶不上人，那也能够促使我们发现人脑的更深层的智能结构，所以未来我们对人工智能和对人的理解，能够互相促进，共同深入。

## 下一模块预告

我们下一个模块的话题是“云计算平台”。

“云”这个概念已经不陌生了，相信不少用户已经在使用“微云”、“云盘”这样的服务，但可能你还没有意识到，在我们看不见的地方，“云计算平台”已经在各行各业中开始应用了。

各大 IT 巨头都在争夺老大的位置，包括我们刚才讲到的，各大 IT 巨头包括谷歌都在云平台上部署人工智能。

这背后的商业逻辑和各 IT 巨头的优势在哪里？现在云计算平台发展到什么程度了？在这个领域里会有哪些机会和陷阱呢？

我将在下一个模块中跟你分享。

## 划重点

1.未来量子计算机的量子比特数上去之后，对现有的数字加密算法能够实现破解，数字货币就不成立了。
2.量子计算机没有突破计算机的基础，因此通用的量子计算能提升整体计算水平，但特定领域的量子计算和人工智能一样，各有各的应用场景，互相不能替代。
3.人工智能进化的速度加快，很多地方赶上了人脑，很可能我们会借助人工智能来了解大脑构造和机能。

> 王煜全
> 
> 我是王煜全，你的全球科技前哨侦察兵，咱们下一讲见。

---
