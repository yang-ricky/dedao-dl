# 第244封信丨凡事都要专注——AlphaGo的核心芯片TPU解析

## 读者，你好！

今天和明天，我来剖析一下最近在围棋比赛中战胜柯洁的Google AlphaGo的技术，也分享一下我对这件事情的感悟（当然是技术之外的）。今天我先来谈一下它的核心硬件TPU(Tensor Processing Unit)，明天谈谈它的软件，即增强机器学习。哪怕你没有任何技术背景，我希望通过我的讲解后，你对这两个最前沿的技术都能有一定的理解。 

今天通过介绍AlphaGo的硬件，我希望能给你讲清楚两件事：1. 计算机处理器发展的简单过程，以及今天很多媒体上讲来讲去的人工智能芯片是怎么回事；2. 一个方法论，即什么时候做事情要专注，什么时候，又需要全才。

AlphaGo棋下得好的一个重要原因是采用了Google自己开发的一种新的计算机处理器TPU，简单地讲这是一种只适合人工智能计算的专用处理器。我们知道，任何一台计算机，也包括智能手机，游戏机等有计算能力的设备，都有一个计算的核心芯片，叫做CPU（Central Processing Unit），即中央处理器，它负责所有的计算，并且控制计算机的全部工作。

CPU的性能从上个世纪60年代中期开始，几乎按照每18个月翻一番的速度在进步，从1965年至今，差不多翻了34次了，也就是说计算速度提高了160亿倍。如果再把这个进步分解一下，又可以分成两个维度，一个是主频的提高，另一个是集成电路芯片密度（称为集成度）的提高。

主频提高后，本来一秒钟算10万个周期，现在可以算30亿个，增加了几万倍。密度提高后，本来几个周期完成一次计算任务，现在可以流水作业、分工合作，一个周期完成好几次计算。两者的加速是叠加的，使得今天计算机的速度变得飞快。

但是，CPU的主频不可能无限制提高，因为光速是一个绝对的瓶颈，今天计算机CPU内部，电子运动的速度已经接近光速所给的极限了，几乎没有了再提高的可能性，事实上从10年前开始，这条路就走不通了。

那么怎么办呢？英特尔公司的办法是，将计算机CPU的集成度进一步提高，最早一个集成电路中只有几千个晶体管，今天最多的有60亿个，这样计算可以并行开展，这也是为什么我们计算机和手机CPU有什么四核、八核之说。

那么接下来，为什么不能做成16核、32核甚至100核呢？因为以今天的工艺，做到那么多核处理器的体积要大得不得了，光是散热问题就没法解决。面对这个问题怎么办呢？英特尔总的态度是，没法解决，你们多买我一些处理器，多建造一些服务器，再把计算中心修得大一点就好了。且不说这个法子灵不灵，在很多场合也没有条件这么做，比如在无人驾驶汽车中，总不能扛着一个机柜上路吧。

我们知道，有主动性的人，总是想方设法寻找更好的解决方法。英伟达的创始人黄仁勋就是这样的人。黄仁勋和他在英伟达的同事就想，CPU的计算速度之所以不够快，是因为它被设计成能够适应所有的计算了，里面很多晶体管都用来搭建控制电路了。

另外，因为计算太复杂，因此处理器本身设计得太复杂。而在计算机里面，有一种计算相对单一，就是控制显示器的图形计算，于是英伟达就为这一类计算专门设计了一种处理器，叫做GPU，即图形处理器。

当然，在英伟达之前，做图形工作站的太阳公司和SGI公司也设计出类似的产品，但是不通用。GPU比CPU的好处有两个：

第一，控制电路简单了，因此更多的晶体管用于了计算，而不是控制，这样本来10亿个晶体管可以搭建四个内核，还有希望搭建八个、十六个甚至更多。

第二，将单个儿单个儿的计算，变成一批一批的计算。在现实生活中，大部分的计算每次都是在两个数之间进行的，比如A＋B＝C，它是一个运算指令（“+”）带上两个数字（“A”和“B”），下一次做X－Y，是另一个运算指令（“－”）带上另外两个数字（“X”和“Y”）。因此计算机处理器实际上是按照一个指令通道（流）对应一个数据通道设计的（被称为SISD）。打个不很恰当的比方，一般的计算就如同你蹲在地上一个个地捡豆子。

而图形计算是整个一条线（在计算机科学里被称为向量）按照同一种操作一口气算完，比如A1+B1=C1，A2+B2=C2，……，最后A1000+B1000=C1000，对于这些计算来讲，指令都是一样的，只是使用不同的数据而已，因此它可以设计出非常多的功能简单的计算核心，然后对一条指令开发很多数据通道（即所谓的SIMD）即可。

这就相当于用一个吸尘器在地上吸豆子，你走过一条线，就吸起一大堆，效率就高多了。对此，英伟达提出一种所谓的“统一计算架构”（CUDA）的概念，就是很多很多核都做同一件事情，并且在此基础上设计出图形处理器GPU。

有了GPU，很多重复一致的计算就可以并行了。GPU最早是针对图形计算设计的，但是后来英伟达发现机器学习的算法也可以用这种方式实现，于是到了2016年，英伟达又针对机器学习的特点，设计了针对机器学习的GPU，它最新的P40处理器内部有多达3000个所谓“统一计算架构”的内核。

虽然每一个能力都比不上英特尔四核处理器中的一个内核，但是P40等GPU的内核数量非常多，因此做人工智能计算就非常快。今天特斯拉搞的辅助驾驶，一片这样的处理器就能解决所有的问题。在去年对阵李世石的AlphaGo中，就是用了176个英伟达的GPU，承担了主要的计算功能。

但是毕竟机器学习中的向量计算和通用的向量计算还是有所不同，能否让计算的内核功能再专一一点，只做和一种非常特定的机器学习算法（即Google的人工神经网络算法）相关的向量计算呢？ 

于是，Google提出了一种张量（Tensor）计算的概念。所谓张量，它原本是一个数学概念，表示各种向量或者数值之间的关系。比如你的两张照片是两个不同的向量，它们之间的一些相似性就是一个张量。人工神经网络的算法可以看成是张量的计算，至于为什么，大家不必细究，记住这个结论就可以了。

接下来，Google就在英伟达等公司GPU的基础上，进一步让计算变得专注，设计了一种仅仅针对特定张量计算的处理器，叫做TPU，其中T就代表张量（Tensor）。Google宣称，一个TPU对AlphaGo这样的任务，效率抵得上15-30个英伟达的GPU，这也就是为什么这一次Google讲新版的AlphaGo在硬件上瘦身了的原因。

我在第225封来信中介绍过，去年战胜李世石的AlphaGo的耗电量是人脑的300倍，如今的AlphaGo用的机器少了很多，至少少了一个数量级，也就是说耗电量从人脑的300倍下降到30倍以下，这个进步速度还是很惊人的。

当然，英伟达表示不服气，说你Google是在拿苹果和橘子比，而用我的测试处理器性能的程序来评测，我的P40可比你的TPU快多了。其实TPU和GPU谁更好，完全要看做什么事情了。

 *从CPU到GPU，再到TPU，效率提升的根本原因在于两个字——专注* ，相比之下，我们手机和电脑的CPU是非常“不专注”的。

在社会生活中，情况和计算机处理器其实很相似。工业革命开始后，英国工厂主把分工做得特别细，于是效率大增。亚当·斯密在《国富论》中讲，即使是制作缝衣服针这件事，当分工很细致后，一个工人一天能生产上千根，如果一个工人做所有的工序，一天恐怕连10根都做不了。因此，英国工业革命后，就把整个欧洲的加工业碾压了。这其实就好比TPU和CPU的关系。

但是，TPU的使用有一个前提，就是这种芯片的市场至少要有上百万片，否则就不值得做，因为它做一个样片的成本就得上百万美元，而设计成本则是上千万。如果市场需求量只有几万片，还不如用很多CPU来工作呢。这就如同制作缝衣服针，一年仅欧洲恐怕要用到上亿根，才值得做社会分工。如果只用三五十根，还不如让几个工人慢慢磨呢！因此，分工和专注的前提都是市场规模足够大。

 *最后讲一下人的技能，什么时候需要专而精，什么时候需要广博，其实没有一定之规，但是一个很好的判断标准就是市场是否大到需要非常专而精。*

以手术为例，很多手术非常常见，比如今天激光矫正视力的手术，它就值得一个医生一辈子把这一件事情做好，一个有1000例手术经验的医生通常要比一个只做了10例的好很多，由于市场足够大，他做好这件事可以吃一辈子。

但是很多手术一辈子也见不到两次，一个医院为此专门准备一个医生，效率就太低了。一项技能，如果应用的场景特别多，就值得做精做深，因为这样足够吃一辈子。相反，如果使用的场合比较少，就不值得花时间，不如把自己培养得广博些。

人在社会中，什么技能用得最多，要用的时间最长呢？我这里先抛砖引玉讲两个（也请你在思考题中再举一些新的例子）：一个是和人打交道的技能，这个值得花时间练习好。另一个是好的思维方式，这个要用一辈子而且在各种场合都很重要，也值得好好培养。

明天，我再聊聊AlphaGo的机器学习方法，然后看看我们能受到什么样的启发。

![https://piccdn3.umiwi.com/img/201706/12/201706121022135579089819.png](https://piccdn3.umiwi.com/img/201706/12/201706121022135579089819.png)

![https://piccdn3.umiwi.com/img/201706/12/201706121022322032979595.jpg](https://piccdn3.umiwi.com/img/201706/12/201706121022322032979595.jpg)

> 今日思考
> 
> 吴军： 人在社会中，什么技能值得我们花很长时间搞得很精深，什么技能不值得？

---
