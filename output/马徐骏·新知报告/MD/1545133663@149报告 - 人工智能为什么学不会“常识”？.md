# 149报告 | 人工智能为什么学不会“常识”？

## 今日报告：人工智能为什么学不会“常识”？

 *我们需要想办法让AI掌握常识，因为它们需要依靠常识来展开推理，理解这个世界。*

 *——《连线》*

> 马徐骏
> 
> 强大的人工智能，遇到了最初级的难题——它们竟然学不会常识，这是为什么？
> 
> 
> 
> 
> 
> 今天的内容分为两个部分：
> 
>   · 深度学习为什么教不出常识？
> 
>   · 如何让人工智能学会常识？

最新一期的《连线》杂志（2018年12月刊），封面文章探讨的是人工智能的“天花板”。你可能觉得，咦？人工智能现在不是风头正劲吗，怎么就遇到了天花板呢？

说起来很有意思，这个天花板，竟然就是非常简单的、连小孩子都知道的“常识”。

常识，英文叫common-sense knowledge，就是指人类对于世界万物的一些基本认识，比如说液体加热后会沸腾、圆的东西可以滚动等等。

虽然这些常识并不高深，但掌握它们却非常重要。它决定了我们如何在这个世界上更好地生存，就算我们生存的环境发生了变化，人类也可以调用常识，快速去适应。

但人工智能就不行了，一旦条件发生变化，它会当场束手无策。想要教会它应对新情况？可以，你要从头再来，让它重新学习。

原因出在哪呢？《连线》杂志指出，人工智能之所以无法具有常识，是因为目前主流的“深度学习”技术本身存在着局限性。它能让人工智人工智能彻底攻克围棋，却无法让具备人类才有的推理能力，而没有推理能力，你就无法对知识进行归纳和迁移。换句话说，你就难以积累常识，更无法用常识来对这个世界产生正确的认知。

现在，已经有计算机科学家开始想办法打破这个天花板，让人工智能也能拥有常识，可是这个过程却非常艰难。为什么呢？我们稍后详细说。

我先送上今天的金句：

 *We need to start figuring out how to imbue AI with everyday common sense, because it needs rules that can help it reason about the world.*

这句话的意思是：我们需要想办法让人工智能掌握常识，因为它们需要依靠常识来展开推理，理解这个世界。

![https://piccdn3.umiwi.com/img/201812/18/201812181953303769095569.gif](https://piccdn3.umiwi.com/img/201812/18/201812181953303769095569.gif)

 **| 深度学习为什么教不出常识？**

你可能有点想不明白的是，现在的深度学习技术这么强大，人工智能都能依靠深度学习，掌握围棋那么复杂的规则，难道还学不会常识吗？

没错，常识确实很简单，但要有常识，必须具备一种能力，那就是推理能力，英文叫reasoning。人工智能可以深度学习，但它没有推理能力。

什么意思呢？我说一个例子你就明白了。小时候你有没有玩过一个很经典的游戏叫“打砖块”？这个游戏长这样：屏幕上方是一堆砖块，玩家控制下方的球拍左右移动，不断把一只白色的球反弹回去，被打中的砖块会消失。这个游戏越玩到最后越难，因为剩余的砖块越少，你就越得找准角度，这需要技巧。

五年前，开发出AlphaGo的那家著名的英国科技公司DeepMind尝试让人工智能来玩这个游戏。他们没有事先输入任何设定，而是让人工智能用深度学习的方法来自学。最开始自然是输得一塌糊涂，但玩了上百局之后，人工智能开始找到了窍门。在600局的时候，人工智能的水平已经达到了高手级别，可以说是通关了。

![https://piccdn3.umiwi.com/img/201812/18/201812181954100177753940.jpg](https://piccdn3.umiwi.com/img/201812/18/201812181954100177753940.jpg)

有意思的是，就在去年，硅谷一家叫Vicarious的科技公司也复制了这个实验。只是在最后，他们突然调整了一下游戏规则，把球拍的位置往上提高了一点，又在砖块中间添加了一块打不穿的区域。对于这两个调整，人类玩家很快就适应了，而人工智能呢？完全不会玩了。

这是怎么回事呢？科学家分析说，这是因为人工智能和人类的认知机制是完全不同的。人工智能的深度学习，靠的是用神经网络逐步建立一种“识别模式”。比如说，你想让人工智能识别猫，你要先建立一些算法的“神经元”，然后把这些神经元用叠层的方式连在一起，就好像三明治那样一层层的，这就是所谓的“深度”。

当你拿出猫的照片交给人工智能，它的神经网络就开始工作，第一层的神经元首先会进行判断，信号传到第二层，再进行判断，以此类推。最后，整个神经网络会做出一个最终决定，判断照片中的是不是猫。

无论判断对错，这时候，你都要给人工智能反馈。如果判断错了，它就弱化那些导致错误结果的神经元连接，如果判断对了，它就强化这些连接。只要次数足够多，人工智能就会形成一个有效的识别猫的模式，达到很高的正确率。

但是，人类大脑并不是这么工作的， *人类的认知并不是建立在“层层识别”的基础上，而是看穿现象背后的逻辑和因果关系，再归纳出抽象的知识，然后用这些知识来应对新情况* 。

概括地来说，这就是一种推理能力。这种能力最大的好处，就是让人不用依赖大量的数据就能学习。

举个例子，想让小孩子认识什么叫“车”，就不需要让他们看上万张车的图片才能认出来，他们会总结——带轮子的、能在地上跑的就是车。哪怕下次碰到的是之前从来没见过的拖车，小孩子也能知道这算是一种车。

但人工智能就做不到，它能准确识别一万次车，但它依然不理解车是什么。每次要辨认新种类的车，它都必须从头开始学习，每一次学习都要靠海量的数据来训练。

听到这你应该就明白了，人工智能和人在“学习”这件事上是有区别的。人类就是靠推理能力，快速学习，也快速积累了常识。这些常识不但帮人类认识世界，还能帮人类应对不断出现的新情况。

假如AI也能学会这些常识，那它们不就可以像人类那样，做到灵活变通了吗？

问题是，AI能不能学会常识呢？答案是：能。

![https://piccdn3.umiwi.com/img/201812/18/201812181954385110865782.gif](https://piccdn3.umiwi.com/img/201812/18/201812181954385110865782.gif)

 **| 如何让人工智能学会常识? **

怎么才能让人工智能学会常识呢？两个解决方案，一个是靠人类来帮AI总结出一套常识性的陈述，让它用深度学习的方法来训练；另外一个，是直接给AI预先输入一些基本逻辑，让它在实践中用这些逻辑去做判断。这两种方案都有一定的效果，但也都有短板。

先来说第一种方案。思路其实很清晰，人工智能不会自己归纳不出来常识对吧？好，那就让人来归纳，人工智能来学习这些常识就好了。

美国西雅图有一家人工智能研究所，他们的科学家团队用的就是这个思路。他们收集了很多常识性的陈述，作为人工智能学习的素材。

这些常识哪里来呢？就是靠人来给。亚马逊有一个劳务众包平台，有很多人在线接一些散活儿。研究人员就付费请这些众包人员来制作常识性的陈述。

比如“X 把 Y 打昏了”这样一个陈述，他们就找很多人来描述 X 的意图：X为什么这样做？研究人员收集了 2万5千条这样的陈述之后，就用这些陈述来训练AI，然后再让AI来分析新句子，推断出句子当中的情绪或者意图。

有时候，AI能做出一些非常靠谱的推测，比如说，咱们换个问题：“杰克做了感恩节晚餐” ，AI会回答：“杰克的目的，是想要给家人留下美好的回忆”。这很不错了，对吧？

但是，从总体来看，AI的正确率不算高，最好的情况，也就能答对一半。而且这个方法太需要依赖人力了，你想，有那么多条常识性的陈述，如果都要靠人工来想，这个工作量实在太恐怖了。

![https://piccdn3.umiwi.com/img/201812/18/201812181955310386874058.gif](https://piccdn3.umiwi.com/img/201812/18/201812181955310386874058.gif)

另外一个方案就彻底放弃了传统的深度学习的路子，直接把基本逻辑用硬编码的方式植入AI。

咱们之前提到的Vicarious公司用的就是这套方法，他们预先告诉AI：物体之间有相互作用，一个物体的运动轨迹，会因为与其他物体相互作用而发生改变——这就相当于给AI预先植入了人类对运动规律的基本认识。

这种AI用很少的数据量就能学会新技能，而且还会变通。就拿“打砖块”来说，游戏规则改变之后，这么学习出来的AI竟然也能很快适应。它似乎和人类一样，抓到了这个游戏的本质。

但这种方法最大的短板，就是AI做判断时速度比较慢。而且预先要植入什么样的逻辑，依然离不开人类的仔细推敲。

听到这，你可能听出问题来了。是的，这两种方案表面上看似乎都能让人工智能掌握一些常识。但问题在于，它们都是“治标不治本”。单靠人工智能，还是没有办法像人类一样积累常识。

 **| 总结**

人工智能的发展如今触到了天花板，这个天花板，就是常识。常识体现的是人类的推理能力，也就是归纳和迁移知识的能力，而这恰恰是人工智能单靠深度学习掌握不了的。

如今的人工智能，或许在解决某些具体问题方面比人类更优秀，但它依然对这个世界没什么概念，它并不理解这个世界。

现在人们正在想办法让人工智能掌握常识，但现有的两种方案都有自己的局限。不过我们依然可以畅想，如果真有一天人工智能彻底掌握了常识，那会怎么样呢？

可能最直接的变化就是，这种AI在很多领域可以接手人类的工作。比如，它可以彻底让司机彻底“下岗”，可以完全取代人工客服，可以成为比人类更厉害的金融分析师，甚至我现在干的活，也就是写写专栏文章，或许，它也可以写。

那时候的人工智能，才算是真正获得了碾压人类的能力。

 *科技界也有一种声音认为，没必要让人工智能发展出人类的思考能力。人工智能，还是应该保留一些“人工”的部分。你是怎么想的呢？*

欢迎你在留言区写下自己的想法，也欢迎你把今天的内容转发给自己的朋友。

## 划重点

今日得到：
1.人类依靠推理能力，快速学习、积累常识，这种能够看透现象背后的逻辑的能力，不但帮人类认识世界，还能应对不断出现的新情况。
2.人工智能的深度学习，是建立一些算法的“神经元”，然后把这些神经元用叠层的方式连在一起，形成神经网络，再逐步建立一种层层识别的模式，再通过不断的反馈来形成识别机制，正因为这样，人工智能无法快速形成推理能力，也就学不会常识。

## 资料来源：

*The Miseducation of Artificial Intelligence,by Clive Thompson,Wired, December 2018
*Commonsense Understanding: The Big Apple of Our AI, insideBIGDATA, January 29, 2018
*Google's DeepMind Artificial Intelligence Taught Itself to Play Breakout，by William Usher,

## 下期预告：

明天将给你带来的议题是#面部识别技术会创造无隐私社会吗？#

近几年来，面部识别技术突然呈现出爆发式的增长，最新一期《纽约客》杂志发表了一篇长文，深入地探讨了面部识别技术的最新发展动态，你会发现，它在一些令人意想不到的领域内，衍生出了一些全新的应用，并且，可能会给我们的隐私安全，制造一种全面的危机。

![https://piccdn3.umiwi.com/img/201812/18/201812182000294341382803.jpg](https://piccdn3.umiwi.com/img/201812/18/201812182000294341382803.jpg)

---
