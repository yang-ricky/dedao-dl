# 《人工不智能》3:自动驾驶能有多难？

咱们继续说布鲁萨德的《人工不智能》。上一讲我们全程搞了一个狭义人工智能项目，我们知道它其实就是统计模型。所有这些模型，都有一个根本的弱点。

这个弱点就是它们高度依赖数据，都是对过去经验的总结，它们没有办法预测“没见过”的事情。

所以这种人工智能的应用非常有限。它最适合常见的、简单的、不变的应用场景，不能直接推广。一旦遭遇必须推广的场景，你就面临各种问题。今天咱们就说一个现在最流行的人工智能应用 —— 自动驾驶汽车。

公众对自动驾驶汽车这个话题已经欢呼了很多年，我一度以为像我儿子这一代人将来可能没有机会学开车，十年以后满大街都是自动驾驶汽车。我们可能都太乐观了。

现在自动驾驶技术是什么情况呢？ 国际汽车工程师学会（SAE International）弄了一个标准，把自动驾驶汽车一共分为五个级别 ——

零级代表完全没有自动化，就是人开车。

一级，是指计算机在某些时候、某种程度上可以给人提供一些辅助性的帮助。这个级别已经实现了，特别是一些高端的汽车，像自动刹车、保持车道、停靠辅助系统现在很流行。

二级，是有的时候汽车可以自己开，但是要求人一直盯着。特斯拉已经做到了这个级别。在空旷的高速公路上你可以暂时让车自己开一会儿。有很多人违反规定，不盯着车，干脆放手不管了，结果出了事儿都算是人、而不是特斯拉的责任。

三级，是说人可以不盯着了，就让车自己开 —— 但是如果车向你发出信号，你要随时接管驾驶。

四级，是指在某些环境和条件下，实现自动驾驶，人去睡觉都没问题。

五级，是完全的自动驾驶，不论什么天气和路况人都不用管车。

 **截止此时此刻，任何一家公司的自动驾驶技术都没有超过二级。**

而有些专家认为，五级自动驾驶是一个永远都达不到的目标。这是为什么呢？因为人工智能处理不了意外。

## 1.意外

其实你开车的时候并不是简单地把着方向盘控制着油门和刹车，你非常有智能。你要看交通信号，你要看各种路边的标志物，你要判断路上有什么东西。如果前面路上有一只小鸭子在慢慢走，你得踩刹车；但是如果是一只鸟，你可以想象车开过去它就会飞走，你就不用减速。如果路上有个塑料袋，你可以直接碾压过去；但如果那是个石头，你就必须绕着走。

你对路面状况有深刻的理解。这种理解和你的生活阅历、和你平时积累的经验有关。最起码你得知道塑料袋是什么，石头是什么 —— 而汽车并不知道。

大约在二十年前，还有很多人在搞*真正的*人工智能。这是一种基于“知识”的方案，让计算机理解事物之间的因果关系。比如警方在路上设一个锥标，计算机得知道这个东西的意思是这里不让过。哪怕锥标倒了、被别的车压扁了，你也得能看出来才行 —— 

![https://piccdn3.umiwi.com/img/201805/22/201805221046598801034128.jpg](https://piccdn3.umiwi.com/img/201805/22/201805221046598801034128.jpg)

可是这背后涉及的技术可就太难了。现有的图形识别能力是哪怕把障碍物换个角度，计算机都看不出来。更何况人的路面知识无穷无尽，你根本就没办法把每个知识都告诉计算机，而它自己根本没有思考能力。这个路线现在几乎已经被放弃了。

所以现在人们搞的都是狭义 AI，走的是机器学习的路线。计算机把路上的所有物体，包括建筑物、其他的车、行人都当成是三维模型，它不再试图理解这些物体。

![https://piccdn3.umiwi.com/img/201805/22/201805221048195327567975.jpg](https://piccdn3.umiwi.com/img/201805/22/201805221048195327567975.jpg)

计算机只关心这些物体的移动趋势。估算每个物体的速度，预测它的路线，看看跟车的路线会不会发生冲突 —— 如果有冲突就踩刹车或者绕着走。

上一讲我们在那个泰坦尼克号的项目中，是只看舱位、性别、年龄和票价这四个因素，而这里则是只看位置和速度。这两个算法都是抓住关键信息，忽略具体的细节，不需要任何理解。泰坦尼克项目有97%的准确率，我们说那是“不合理的有效性”，而自动驾驶技术也有不合理的有效性。这个方法非常、非常有效！

但问题就在于，因为你不理解，你就永远都做不到100%的准确度。开车别说97%，就是99.9999%的判断准确率也不够，因为一旦判断错误就可能是一条人命。

真实的路面上会有各种意外。Google 一直在训练自动驾驶技术，他们遇到过各种各样奇怪的情况。有一次有几个小孩在高速公路上在玩青蛙。还有一次，一个残疾人，坐着电动轮椅，在路中间追逐一只鸭子。鸭子绕圈跑，她也绕着圈追。那你说像这种情况你能一下子就准确预测这些人的行动路线吗？

自动驾驶汽车识别路边的物体，都是靠把激光打到各种东西上再反射回来。可如果在下雪或者下雨，激光可能打到雪花或者雨滴上反射，汽车就可能对周围物体有重大误判。

计算机能不能保证看懂路边标记限速、慢行的交通标志牌？图形识别技术非常难，别忘了Google 曾经把奥巴马夫人米歇尔给识别成一只猩猩。假如标志牌有损坏，或者上面被人贴了小广告，那汽车就很可能无法识别。

还有，现在自动驾驶汽车都高度依赖 GPS 定位。可是现在美国有一种50美元就能买到的装置，能在周围干扰 GPS 信号。那如果路上有人使用这个装置，自动驾驶汽车要怎么办？

2016年，开特斯拉的一个司机车违反规定，把车完全交给自动驾驶，结果因为汽车没有识别出来前面的一辆白色卡车 —— 它可能以为那是天上的白云或者别的什么东西 —— 导致死亡。当然这是司机犯了错误，但这恰恰也说明自动驾驶技术非常容易遭遇意外。

除了安全，自动驾驶还有道德问题。

## 2.AI 道德规范

比如说你正在以很快的速度开车，突然发现前边有一群小学生在马路上打闹。要避让这些小学生，你就会撞到路边的建筑物墙上。而如果撞墙，你的生命安全就面临危险。请问在这种情况下，你是选择撞墙还是选择撞向小学生呢？

![https://piccdn3.umiwi.com/img/201805/22/201805221049566609693787.jpg](https://piccdn3.umiwi.com/img/201805/22/201805221049566609693787.jpg)

有道德的人，比如我，肯定是宁可自己面对生命危险，也不能撞小学生。

好。那如果汽车厂商告诉你，我们这个车就是讲道德的，我们的自动驾驶系统在这种情况下一定会首先确保行人的安全 —— 请问这样的车你会买吗？

我牺牲我自己，是我自己的决定。我不能让汽车替我做决定！万一我临时不想死怎么办？万一汽车判断错了怎么办？我不想开一辆在某种情况下会牺牲我的车。

现在有很多公司正在研究自动驾驶的道德规范，Google 甚至还专门聘请了哲学家，但是没有研究出来什么令人满意的方案。奔驰公司已经宣布，他们对自动驾驶汽车的设定是优先保证自己车里司机和乘客的安全。在前面那种情况下，奔驰的车会果断撞向小学生。

那你说这不是杀手汽车吗？这种汽车怎么能让上路呢？！

所以这就出现了一个道德困境。人在现场不管做出怎样的临时反应，我们都认为是正常的。可是人工智能不管事先怎么设定，我们都觉得别扭。

自动驾驶技术还有一个经济学问题。

## 3.数据大亨

机器学习高度依赖数据。我们知道有个“二八法则”，说你花20%的时间就能解决80%的问题，剩下80%的时间解决20%的问题。对自动驾驶汽车来说，我看更可能是你用2%的数据就能训练一个能解决路面80%的情况的自动驾驶系统，但是剩下那20%的情况，你就是再用98%的数据也未必能解决。

美国50个州都有各自的交通法规，各地的气候条件和路况都不一样，这还不算美国和中国更不一样。这意味着什么呢？这意味着在一个地区训练出来的自动驾驶技术，换一个地方就可能不好使。

这个道理很简单。我们用泰坦尼克号一半乘客的数据训练出来的模型，能很好地预测另一半乘客的生死 —— 那只不过是因为这些乘客都在同一条船上。换一条船，换一次事故，泰坦尼克号训练出来的统计模型就没用。

所以人工智能模型不能推广，你必须在每一个地区都采集大量的数据才行。

那好，谁拥有这么多数据呢？现在冒出来很多搞自动驾驶技术的公司，我非常怀疑他们怎么跟 Google 竞争。Google 一直都在积累数据。算法都是现成的，真正值钱的是数据。

谁掌握了数据，谁的自动驾驶技术才有市场。人工智能时代的商业帝国一定是数据帝国，小创业公司将会越来越难以起步。

## | 由此得到

自动驾驶技术 ——

 *第一，它不安全。第二，它不道德。第三，它不能促进商业平等，它只会让强大的公司变得更加强大。*

布鲁萨德这本书的主题就是给技术沙文主义泼冷水。当然你可以说这些困难未来终究会被技术进步克服 —— “未来”这个词儿具有万能的科幻性质。

我们更关心 **可以预见的未来** 。在可以预见的未来，也许我们还是得自己开车。

![https://piccdn3.umiwi.com/img/201805/22/201805221051201865143501.jpg](https://piccdn3.umiwi.com/img/201805/22/201805221051201865143501.jpg)

## 划重点

1） 人工智能处理不了意外。
2） 人工智能可能面临道德困境。
3） 人工智能模型的推广仰赖数据采集，大部分数据掌握在大公司手上，不利于促进商业平等。


---
