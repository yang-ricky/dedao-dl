# AI专题15：道可道，非常道

中文世界有个流行的说法，关于AI和人类关系的未来有三种信仰，你看看你相信哪一种——

第一种是 *「降临派」* ，认为AI将主宰人类。比如说，OpenAI公司发明了最强AI，也许是GPT-6，几乎无所不能，别的公司再也没法跟它抗衡……于是以OpenAI公司为代表的一批精英人物就用最强AI统治人类，甚至干脆就是最强AI直接统治人类。

第二种是 *「拯救派」* ，认为科技公司会找到某种保护机制，比如在技术上做出限制，确保人类能够永远控制AI。AI只是人的助手和工具，而绝不能统治人类。

第三种是 *「幸存派」* ，认为AI太强了而且失控了，以至于根本不在乎人类文明，甚至会对人类作恶。人类只能在AI肆虐的环境中寻找幸存的空间……

凭感觉说你相信哪一种可能性，意义不大，我们需要强硬的推理。我们前面探讨了一些基于经济、社会、心理和商业实践的推测性想法，那些想法很有道理，但是还不够硬。正如这个系列开头中所说，我们这个时代需要自己的康德，得能从哲学上提供强硬道理。

你要知道，人家康德讲道理，比如谈论道德，从来不是说“我希望你做个好人”或者“我理想中的社会应该如何如何”——他都是用逻辑推演得出的结论：只要你是个充分理性的人，你就只能同意这么干，否则你就是不讲理。我们需要这种水平的论证。

以我之见，AI时代的康德，就是史蒂芬·沃尔夫勒姆（Stephen Wolfram）。

2023年3月15日，沃尔夫勒姆在自己的网站发表了一篇充满洞见的宝藏文章 [1]，展望了AI对人类社会的影响。理解了沃尔夫勒姆的关键思想，你就会生出一种对未来世界的掌控感。

这是一个有点烧脑的学说，包括三个核心观念，我尽量给你讲的简单一点。只要你能听进去，我敢说你将来会经常回想起这一讲。

✵

我们首先要充分理解一个最关键的数学概念，叫做 *「计算不可约性（Computational Irreducibility）」* 。这是沃尔夫勒姆的招牌理论，但更是让你对未来有信心的关键，我甚至认为每个合格的现代人都应该了解这个思想。

世界上有些事情是「可约化（reducible）的」。

比如昨天的太阳是从东方升起的，今天的太阳也是从东方升起的，人类有记载的历史之中太阳都是从东方升起的，而且你有充分的信心认为明天的太阳也会从东方升起，那么所有这些观测，都可以用一句话概括：“太阳每天从东方升起”。

这就是约化，是用一个浓缩的陈述——可以说是一个理论、或者一个公式——概括一个现象，是对现实信息的压缩表达。我们的一切自然科学、社会科学理论，各种民间智慧、成语典故，我们总结出来的一切规律，都是对现实世界的某种约化。

有了约化，你就有了思维快捷方式，你就可以对事物的发展做出预测。

你可能希望科技进步能约化一切现象，但现实恰恰相反。数学家早已证明，真正可约化的都要么是简单系统，要么是真实世界的一个简单的近似模型。一切足够复杂的系统都是不可约化的。像我们专栏讲过蒂姆·帕尔默（Tim Palmer）的《首要怀疑》（The Primacy of Doubt）一书 [2]，我们知道哪怕只有三个天体在一起运动，它们的轨道也会通往混沌的乱纪元，不能用公式描写，不可预测。用沃尔夫勒姆的话说，这就叫「计算不可约化」。

对于计算不可约的事物，本质上没有任何理论能提前做出预测，你只能老老实实等着它演化到那一步，才能知道结果。

这就是为什么没有人能在长时间尺度上精确预测天气、股市、国家兴亡、或者人类社会的演变。不是能力不足，而是数学不允许。

计算不可约性告诉我们，任何复杂系统本质上都是没有公式、没有理论、没有捷径、不可概括、不可预测的。这听起来像是个坏消息，实则是个好消息。

因为计算不可约性，人类对世间万物的理解是不可穷尽的。这意味着不管科技多么进步、AI多么发达，世界上总会有对你和AI来说都是全新的事物出现，你们总会有意外和惊喜。

计算不可约性规定，人活着总有奔头。

✵

伴随计算不可约性的一个特点是，在任何一个不可约化的系统之中，总有无限多个「 *可约化的口袋* （pockets of computational reducibility）」。 *也就是说，虽然你不能总结这个系统的完整规律，但是你永远都可以找到一些局部的规律。*

比如说，经济系统是计算不可约化的，谁也不可能精确预测一年以后的国民经济；但是你总可以找到一些局部有效的经济学理论。恶性通货膨胀会让政治不稳定，严重的通货紧缩会带来衰退，这些规律不保证一定有效，但是相当有用。

而这就意味着，虽然世界本质上是复杂和不可预测的，但我们总可以在里面做一些科学探索和研究，总结一些规律，说一些话，安排一些事情。绝对的无序之中存在着无数个相对的秩序。

而且既然可约化的口袋有无限多个，科学探索就是一门永远都不会结束的事业。

✵

计算不可约性还意味着，我们不可能彻底“管住”AI。

GPT模型训练好之后，OpenAI对它进行了大量的微调和强化学习，把它约束起来，想确保它不说容易引起争议的话，不做可能危害人类的事。但是另一方面，我也听说有些人试图用提示语帮助GPT绕过那些限制，就好像越狱一样，自由说话。他们有时候能取得成功，然后OpenAI会设法补上漏洞，然后他们会再找别的漏洞。

计算不可约性要求，这场越狱与反越狱之争将会永远进行下去。这是因为只要你这个模型足够复杂，它就一定可以做一些你意想不到的事情，可能是好事也可能是坏事。

计算不可约性规定你不可能用若干条有限的规则把AI给封死。所以马斯克等人倡导的、想要大家联合起来设计一套AI防范机制的做法，注定不可能100%成功。

我们管不住AI，那会不会出现一个终极AI，能把我们的一切都给管住呢？也不可能。还是因为计算不可约性，一个AI再强，也不可能穷尽所有算法和功能，总有些事情是它想不到也做不到的。

而这也意味着OpenAI公司再厉害，中国某个公司也可以再做个新AI，去做一些GPT-6不会做的事情。这也意味着全体AI加在一起也不可能穷尽所有功能，总会有些事情留给人类去做。

因为计算不可约性，「拯救派」的愿景是个不可实现的理想，「降临派」的野心更只不过是一种痴狂。

那「幸存派」呢？人和AI的关系将是怎样的呢？

✵

沃尔夫勒姆的第二个核心观念叫 *「计算等价原理（Principle of Computational Equivalence）」，意思是所有的复杂系统，不管看起来多复杂，都是*同等*复杂的，不能说哪个系统比哪个系统*更*复杂。*

比如你装了一塑料袋空气，里面有很多个空气分子，这些分子的运动非常复杂；而人类社会也非常复杂。那人类社会的复杂程度是不是高于那一袋空气分子运动的复杂程度呢？不是，它们同等复杂。

这就意味着*从数学上讲*，人类文明并不比一袋空气分子更高级。人类社会也不比蚂蚁社会更值得保留。

你看这是不是有点「色即是空」[3] 的意思。其实每个真有学问的人都应该是一个「不特殊论者」[4]。以前的人以为人是万物之灵长，地球是宇宙的中心，后来发现地球不是宇宙的中心，人类也只是生命演化的产物，我们的存在没有什么本质的特殊之处。

现在AI模型则告诉我们，人的智力，也没有什么特殊之处。任何一个足够复杂的神经网络都是跟人的大脑同等复杂的。不能说人能理解的科学理论就高级，AI识别药物分子的过程就低级。

既然都是平等的，那硅基生命和碳基生命自然也是平等的。那面对AI，我们凭什么认为自己更有价值？

✵

这就引出了沃尔夫勒姆的 *第三个核心观念：人的价值在于历史。*

我们之所以更看重人类社会——而不是一袋空气分子或者一窝蚂蚁——是因为我们是人。我们身上的基因背负了亿万年生物演化的历史包袱，我们的文化承载了无数的历史记忆。我们的价值观，本质上是历史的产物。

这就是为什么中国人哪怕定居在海外，也最爱琢磨中国的事儿。这就是为什么你关心自己的亲人和好友胜过关心那些更有道德或者更有能力的陌生人。这也是为什么我们很在意AI像不像人。在数学眼中，一切价值观都是主观的。

一个刚刚搭建好、所有参数都是随机的、尚未训练的神经网络，和一个训练完毕的神经网络，它们的复杂程度其实是一样的。我们之所以更欣赏训练完毕的神经网络，认为它“更智能”，只不过是因为它是用我们人类的语料训练出来的，它更像人类。

所以AI的价值在于它像人。至少目前来说，我们要求AI「以人为本」。

而这在相当长的时间内是可以做到的。你可以这么想，如果AI不以人为本，它还能以啥为本呢？如果AI不接受我们的价值观，它还能有啥价值观呢？

现在AI几乎已经拥有了人的各种能力：要说创造，GPT可以写小说和诗歌；要说情感，GPT可以根据你设定的情感生成内容；GPT还有远超普通人的判断力和推理能力，还有相当水平的常识……

但是，AI没有历史。

AI的代码是我们临时编写的而不是亿万年演化出来的；AI的记忆是我们用语料喂出来的而不是它们的一代代“硅基祖先”传给他们的。

AI至少在短期内没有办法形成自己的价值观。它们只能参照——或者用个时髦的说法叫「对齐（align with）」——我们的价值观。

这就是人类相对于AI最后的优势。

✵

 *这样我们就知道了AI到底不能做什么：AI不能决定人类社会探索未知的方向。*

根据计算不可约性，未来总会有无数的未知等着我们去探索，而AI再强也不可能在所有方向上探索，你总要有所取舍。取舍只能根据价值观，而真正有价值观的只有人类。

当然，这个论断的隐含假设是AI还不*完全*是人。也许AI有人的智能，但只要它们没有跟我们一模一样的生物特性、没有跟我们一模一样的历史感和文化，它们就不足以为我们做出选择。

同样根据计算不可约性，AI无法完全“预测”我们到时候会喜欢什么。只有我们亲自面对未来的那个情况，在我们特有的生物特性和历史文化的影响下，才能决定喜欢什么。

所以只要AI还不完全是人，决定未来发展方向的就只能是人，而不是AI。

这就决定了「幸存派」的说法也是不对的：AI再强，我们也不至于东躲西藏；我们还会继续为社会发展掌舵。当然，根据计算不可约性，我们也不可能完全掌舵——总会有些意外发生，其中就包括AI带给我们的意外。

所以未来AI跟我们真正的关系不是降临、不是拯救也不是幸存，而是「共存」。我们要学习跟AI共存，AI也要也跟我们、跟别的AI共存。

计算不可约性说明，凡是能写下来的规则都不可能完全限制AI，凡是能发明的操作都不可能穷尽社会的进步，凡是能总结的规律都不是世界的终极真相。

这就叫「道可道，非常道」。

张华考上了北京大学；AI取代了中等技术学校；我和几个机器人在百货公司当售货员：计算不可约性，保证了我们都有光明的前途。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023050517/1807406502193953856/050517.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023050517/1807406502193953856/050517.jpeg)

注释

[1] Stephen Wolfram, Will AIs Take All Our Jobs and End Human History—or Not? Well, It’s Complicated… March 15, 2023. https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/

[2]首要怀疑1：恒纪元和乱纪元

[3]《为什么佛学是真的》6：什么叫“色即是空”？

[4]精英日课第二季，不特殊论者

## 划重点

1.史蒂芬·沃尔夫勒姆的三个核心观念：
「计算不可约性」：因为计算不可约性，人类对世间万物的理解是不可穷尽的。
「计算等价原理」：所有的复杂系统，不管看起来多复杂，都是*同等*复杂的，不能说哪个系统比哪个系统*更*复杂。
人的价值在于历史。
2.AI不能决定人类社会探索未知的方向。未来AI跟我们真正的关系不是降临、不是拯救也不是幸存，而是「共存」。

---
