# 问答：怎么判断AI有了人的意识？

## 来自日课：GPT的底牌和命门

> 读者 明道如昧：GPT基于神经网络的学习和婴儿学语言很像，妈妈不会教婴儿语法，ta自然就学会了。而成人拿着语法书学外语，怎么学都是半吊子。 但是有一个关键区别： GPT不接触物理世界！当妈妈跟婴儿说苹果的时候，婴儿会看到、摸到、吃到苹果，建立一系列的神经链接。但是GPT只是「读书」，就理解了苹果“是什么”。 请问万老师，这种不接触实物的语言理解，到底是一种什么理解？就像一个天生眼盲的人，对颜色建立的是怎样的理解？

> 万维钢回复—— 

这个问题问得好。这是一个极为深刻的问题，也是当前专家正在激烈辩论的问题。GPT并不真的接触物理世界，它只是通过语言去学习有关世界的知识，那它所形成的理解，有可能是完整的吗？

我们专栏去年年底有一期文章叫《我们专栏用上了AI》，讲的是用AI画画的事。当时ChatGPT和GPT-3.5都还没出来，我对这一波AI大潮的理解还不深，所以我认为AI对现实的理解是非常有限的。我们还引用了图灵奖得主杨立昆（Yann LeCun，当时我们翻译成 扬·勒丘恩）的一个说法，说「语言只承载了人类全部知识中的一小部分」，所以「语言模型不可能有接近人类水平的智能」。

而我们知道，杨立昆是GPT最有力的反对者，他至今维持这个态度。

可是我现在的态度有了强烈的动摇。我觉得语言模型对世界的理解可能已经足够好了。

就在上个月，OpenAI的首席科学家伊利亚·苏茨科弗（Ilya Sutskever）接受一个播客的访谈（https://www.eye-on.ai/podcast-archive，3月15日），对杨立昆的态度给了一个特别有力的回应。

苏茨科弗说，表面上看，语言模型只是从文本上了解世界，所以现在我们给GPT增加了「多模态」能力，让它能通过画面、声音和视频了解世界。但是，多模态并不是*必须*的。

苏茨科弗举了个例子，颜色。在不用多模态功能的情况下，按理说，语言模型就好像是个盲人，它只是听说过一些关于各种颜色的描述，它并不能真的*理解*颜色。可是什么叫理解？

苏茨科弗说，语言模型仅仅通过语言训练就已经*知道*“紫色更接近蓝色而不是红色”“橙色比紫色更接近红色”这些事实。

苏茨科弗并没有明确说，但我从上下文的理解是，模型不是在背诵哪个文本教给它的知识，它是从众多文本中自己摸索出来了这些颜色的关系。那你说这叫不叫理解？

苏茨科弗说，如果能直接看见颜色，那你肯定能瞬间理解不同颜色是怎么回事——但那只是学习速度*更快*而已。从文本中学习会比较慢，但并不见得是本质的缺陷。

再者，到底什么是语言？并不是说只有用人类文字写出的东西才是语言。画面中的像素难道就不是语言吗？我们完全可以把任何图片、声音和视频变成一串串的数字符号，这不就是语言吗？现在的生成性画图AI，比如OpenAI自家的DALL-E，是使用语言模型同样的 transformer 技术来预测画面中的内容。画面跟语言有啥区别？

要是这么理解的话，我认为杨立昆可能有点狭隘了。我们之前可能都狭隘了。也许人家天生眼盲的人对世界的理解一点都不差，他们只是有点障碍，理解得慢一些而已。

## 来自日课：你的AI助理来了

> 读者 小赈：GPT如此“神通广大”，有强大的调用力和“计算器”，又可以实时浏览网页。那它会不会被居心不良的“不法之人”误导和利用，做出一些不合规或不合法的事情，使AI自身陷入法律或道德的困境呢？

> 读者 艾菲尔上的铁塔梦：万sir可以分析一下马斯克等呼吁暂停更强AI开发的深层原因吗？

> 万维钢回复—— 

如果只是人类滥用或者误导性地使用GPT去做一些事情，那还不足以让马斯克等人如此担心。

现在的确有人可以在自家的电脑上运行一个小尺度的语言模型，但是要想像GPT-4那样用，乃至于AGI，那就必须使用超大规模模型，借助超大规模的算力。这样说来，AI应用大概会是「中心化」的。既然是中心化的就容易监管，你只要把OpenAI、Google这样的公司看住就可以。这就跟传统媒体差不多，理论上电视台和报社都有作恶能力，但是因为我们可以监管它们，我们并不是很担心。

马斯克等人真正担心的，是GPT可能会变成真的AGI，乃至于“活了”，有了意识和自主性，以至于连母公司OpenAI也控制不了它。

这个担心是合法的。正如我们前面讲过，GPT-4已经有了一些比较可疑的行为。当然OpenAI会在把模型推向大众之前对它做各种安全测试，包括聘请外部的团队去故意引导模型搞破坏，试探它的能力和野心……但是你永远都不能从理论上保证模型会不会先假装老实，通过了测试，面对大众之后再现出原形。

所以现在网上流传一个梗。OpenAI CEO山姆·奥特曼每次外出都背着一个背包，跟他形影不离。有人就猜测，那个包里面是不是有个就好像美国总统的核按钮一样的装置？一旦AI失控，奥特曼就可以远程启动毁灭程序？

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911824127205744/040819.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911824127205744/040819.png)

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911855265673412/040819.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911855265673412/040819.png)

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911885330514532/040819.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040819/1804911885330514532/040819.png)

当然我认为这是一个玩笑。但这是一个非常严肃的玩笑。马斯克等人的意思是这不仅仅是一个立法问题，也是一个技术问题。我们必须坐下来一起想个什么办法，怎么判断AI是不是已经失控了，如何设定限制让它不失控，一旦失控了怎么办……这些都是光说不行、需要真实的研究才行。

## 来自日课：伊丽莎效应

> 读者 周树涛：专栏里说“更有意思的问题是怎样才能判断，现在到底是AI真有意识了，还是你自己产生了伊丽莎效应……” 万老师本讲没说，以后会讲到吗？图灵测试既然已经不能很好的确定是否拥有人类智能，那目前有人在研究如何判断AI有自我意识吗？

> 万维钢回复—— 

怎样才能判断AI算不算是有了人的意识，是个非常有意思的问题，也是现在没有答案的问题。我们专栏多次讲过，关于到底什么是「意识」，人的意识到底是真的还是幻觉，现在都没有共识性的说法。

对比之下，「智能」则有比较客观的标准，可以打分。以前的计算机科学家最关心的是AI怎样才算有了人的智能。计算机之父艾伦·图灵在1950年的一篇论文中提出了一种测试方法，就是让人跟AI和真人分别对话，如果有超过一定比例的人无法区分哪个是AI、哪个是真人，那么我们就可以说AI已经有了人的智能。这就是「图灵测试」。

按照这个标准，GPT已经通过了图灵测试。它的智能大大超过了绝大多数真人，如果你能发现对面不是真人而是GPT，那很可能是因为你发现对面的智能太高了而不是太低了。所以现在人们不太谈论图灵测试了，AI的智能超过了人，这不是我们担心的重点。

我们担心的是AI会不会有「意识」。最近听说有学者认为，如果我们已经认定某个AI产生了意识，那么我们就应该赋予它人权，那么把它断电就是不人道的。我认为这可以理解。如果你认为杀死一只小狗是不人道的，你完全也应该认为杀死一个有意识的AI是不人道的。

问题是关于怎么算有意识，我们并没有很好的判断标准。但是，我们比较清楚怎么*不算*有意识。

 *如果一个物体永远只是被动反应，它就不是有意识的。*

比如你的手机对着你唱歌，还给你播放视频，很好用，但是你不会觉得手机有意识。这是因为手机做的每件事都是你让它做的——啊，或者是拼多多APP让它做的——它自己没有什么多余的想法。

那如果将来你买了个机器人管家，她总是无微不至地为你服务，甚至还面带微笑，有时候看你很无聊还*主动*给你讲笑话，你会觉得她有意识吗？严格地说，这还不算有意识。这里所谓的“主动”，本质上是为了取悦你。很有可能她的出厂设定就是取悦主人，她取悦你的任何行为本质上仍然是被动的，她仍然是个工具。这跟手机到点了就用闹钟叫醒你没有本质区别。

那你说如果有一天这个机器人管家突然不听你指挥了，甚至突然从你家逃跑了，这能算有意识吗？这也不一定。也许机器人的出厂设定是“要尽量保护自己”，她一看你家条件太差，整天虐待她，她计算之下为了完成保护自己的设定就必须逃跑，这跟自动驾驶汽车会自动避让障碍物似乎也没有本质区别。

倒是有一个场景，可能会说明AI有了意识。以前有个电影叫《机械姬》（Ex Machina，2014），描写一个女机器人Ava从人类控制中逃跑的故事。可能在一个内行看来，Ava会逃跑这件事还不能说明她有意识，真正惊心动魄的是影片结尾处的一个细节。

当时Ava已经逃跑成功了，她走到一片树林里，阳光照在她的脸上。就在这时候，她略微仰头，轻轻闭上眼睛，做出了一个很享受阳光的表情——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040820/1804911913247777136/040820.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040820/1804911913247777136/040820.png)

当时没有任何人在现场看。她这个动作没有任何实用价值，但是她做了。也许这就是意识的觉醒。

可是我们能根据这样的行为判断AI是否有意识吗？还是不能。将来机器人制造商完全可以给机器人加入一些这样的戏码：你们喜欢这样的表情我就让她有这样的表情！那我们将来看到这样的表情也不能认为机器人有了意识。

这几乎就是一个悖论：你要知道AI为什么会这么做，你就认为这么做不能证明AI有意识；意识似乎必须是某种纯自发的、难以解释的行为。

现在唯一能判断AI可能有意识的做法，似乎是你去调查那些设计AI神经网络的工程师，查看他们的代码：如果代码中没有包括这种行为，可是AI偏偏做出了这种行为，而且这种行为又比较高级，很像人类的意识，我们大概就可以说这个AI好像活了，有意识了。

然后话说回来，人的意识到底是什么？凭什么有意识就有人权？我们还是没想清楚。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040820/1804911936870052036/040820.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023040820/1804911936870052036/040820.jpeg)

---
