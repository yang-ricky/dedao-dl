# 人要比AI凶

ChatGPT的月活用户数量已经超过了一亿，热潮仍在继续。最近微软又把它跟必应搜索结合到了一起，我拿到了测试账号，果然是十分厉害。这一讲我们介绍一点对ChatGPT和Bing Chat的最新认识，讲讲怎么强势地使用它们。

现在有两个流行的错误认识，分别让人高估和低估了ChatGPT的能力。

 **第一个错误认识是把它当成了一个聊天机器人。**

你直接用人类自然语言跟它聊，ChatGPT的确能在相当程度上准确理解你的意思。尤其Bing Chat，有时候表现出强烈的个性，会为自己的错误辩白，会与人争吵，还会生气。很多人以为AI是不是快要活了，是不是很快就会通过图灵测试——有人甚至说它已经通过了图灵测试……

有人拿各种脑筋急转弯的题目逗它玩：“树上十只鸟，开枪打死一只鸟，树上现在有几只鸟？”ChatGPT老老实实地回答“还剩下九只鸟”，人类说，哈！你还是不够聪明啊！

其实用这种方式战胜它没啥意思。要知道ChatGPT并不是一个聊天机器人——它不是一个以陪你聊天解闷为目的的机器人。

ChatGPT是一个以聊天为界面的信息处理工具。它这个界面做的是如此之好，以至于人们把界面当成了主体，这就如同称赞一部手机说“哎呀你这个手机真好看！”要知道聊天只是输入输出手段，处理信息才是目的。

那它处理信息的能力有多强呢？

✵

第二个错误认识是作为一个语言模型，ChatGPT和Bing Chat背后的人工智能——现在最新版本用的是GPT3.5——只会根据文本中各种词汇出现的频率，也就是盲目的经验——生成输出，它并不真的理解那些词的意思。

这个认识在原则上其实是绝对正确的，但是这么说会低估GPT的能力。

去年年底，ChatGPT刚刚出现的时候，卓克老师测试了它几个比较难的问题，它都答错了 [1]。比如问它：“霍布斯主张三权分立吗？”

当时的ChatGPT会回答“是的”，并且胡乱说一番似是而非的话。其实霍布斯主张强权统治，不可能支持三权分立。这显然是因为霍布斯和三权分立这两个关键词都是政治学常用词汇，经常一起出现，GPT搞不清楚它们之间是对立关系还是支持关系——毕竟很少有文章会直接说“霍布斯反对三权分立”这样关公战秦琼式的话。

这似乎都很合理，语言模型能力真的有限……但是，两个月之后，我再用同样的问题问ChatGPT，它的表现变了。

我先用中文问，它又是胡说八道了一番——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801539960193490452/030311.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801539960193490452/030311.png)

但我发现它之所以说错，是把霍布斯和詹姆斯·麦迪逊给搞混了，这可能是中英文互译过程中出了问题。于是我又用霍布斯的英文名问它，这回它答对了——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801539995626996252/030311.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801539995626996252/030311.png)

ChatGPT非常明确地答复，霍布斯不主张三权分立，而且给出了合理的判断理由。

我又进一步，问它霍布斯会怎样评价特朗普——这又是一个关公战秦琼式的问题，不会有人专门写文章讨论这个问题，ChatGPT很难抄作业，它必须非常理解霍布斯的主张和特朗普的执政特点才能回答好这个问题。而它答得很好——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540026765485648/030311.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540026765485648/030311.png)

短短三段话，理论正确，逻辑清晰，正反合滴水不漏。ChatGPT这段时间在不断升级，看来升级效果不错。

那么问题来了：GPT真的理解霍布斯吗？

我认为这取决于你如何理解「理解」。能灵活运用一个东西，算不算理解？如果不算，人类的理解又高在哪里，又如何观测？我们要求AI理解一个东西，除了灵活运用，还有什么别的意义吗？

现在的语言模型并不是简单地搞词汇匹配，它们使用了像「矢量表示（word vector representations）」「小样本学习（few-shot learning）」、尤其是「Transformer 架构」，它在乎的已经不仅仅是词的具体形式，更是词的意思，它对文本可以说有相当程度的理解 [2]。

这就是为什么ChatGPT可以模仿某一种特定风格写作，可以用一种观点解释一个现象，可以相当合理地回答以前没人问过的问题。你先输入一组规则给它，它还可以按照你的规则完成你接下来的指令。

GPT-3有1750 亿个参数，而我们大脑中的神经元才800亿个。AI和人脑的神经网络都是黑匣子，说不清其中的因果关系。人脑是怎么理解某个理论的？你真的需要知道吗？

✵

现在已经有好几百家小公司用API接入了GPT，可以让它读取特定环境下的文本，完成信息处理。你可以用GPT ——

* 编程（现在普遍认为ChatGPT的编程水平比文字处理水平高，这可能是因为编程是一种更规范的活动）；

* 以问答的形式学习一门知识；

* 在中英文之间高质量翻译；

* 把文章修改得更加地道；

* 根据你的意图直接写文章；

* 写诗；

* 帮你制定购物清单、旅行建议和健身计划；

* 提供书名、大纲、小说剧情、广告等等文案的创意构思；

* 按照你设定的规则和菜单，提供客户服务；

* 总结一篇文章的要点……

等等等等。

✵

作为一个语言模型，GPT受到训练素材的限制，像GPT-3的知识就截止到2021年。但现在一个突破性的进展是微软的必应搜索和GPT结合在了一起，也就是Bing Chat。它会直接读取和分析实时网页文章，给你生成一个综合性的答案，并且附带信息来源。

这绝对是有搜索引擎以来最大的一次进步。

举个例子，我听说有个「拓展-建构理论」认为积极情绪有利于创造性思维，而我正在写一篇跟教育有关的文章。我就问Bing Chat，根据拓展-建构理论，什么样的教育能培养创造性思维——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540087968767508/030311.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540087968767508/030311.png)

它搜索了相关的关键词，把结果整合成一段不长的答案：先介绍了“拓展-建构理论认为积极情绪有利于创造性，所以教育应该激发积极情绪”这个原理，然后列举了五项教育手段的建议，附带所有文献地址。

那五项建议是出自三篇不同的文章。Bing Chat生成这一切只用了几秒钟，而你想想，如果让我自己挖掘这些信息，得花多少工夫。

✵

而且GPT很快就可以做得更好。就在二月，Meta公司发布了一个新的语言模型架构，叫「Toolformer」[3]。它的功能是让语言模型直接调用外部的应用程序工具，比如计算器、日历、上网浏览等等。研究者不用教它怎么用，它通过自监督学习自己摸索着就能学会。有了Toolformer，下一个GPT就可以跟比如说Wolfram Alpha这样的专业数学工具对接，帮你算个数学题啥的就更不成问题了；它大概也可以去专门的网站帮你订票和购物。

对我来说这已经非常智能了。

✵

 *AI到底减弱了人的价值还是扩大了人的价值，取决于你怎么用它。*

把事情直接交给AI做，是软弱的而且是危险的。比如你想给人写封信，表达一个意思，你怕自己写的不够礼貌周到，就让ChatGPT替你写。它的确可以写得很好，写成诗都可以——但是，如果读信的人知道你是用ChatGPT写的，或者对方因为也用ChatGPT，根本懒得读全文，选择让ChatGPT给个摘要，那你这封信还有必要走AI这道程序吗？难道AI的普及不应该让大家更珍视坦诚相见吗？

正所谓「人要比车凶」，强势的用法，是把AI当做一个助手、一个副驾驶，你自己始终掌握控制权：AI的作用是帮你更快更好地做出判断。

简单说，如果你足够强势，当前AI对你的作用有三个。

 *第一是信息杠杆。*

想要了解任何方面的信息都能得到答案，这件事在有搜索引擎以前是不可能的；在有搜索引擎、没有GPT之前是费时费力的。而现在你可以在几秒钟之内完成。我的经验是对于非时效性的话题，ChatGPT最快最方便；对于时效性话题，用Bing Chat。

当然AI返回的结果不一定准确，它经常犯错，关键信息还是得亲自查看一下原始文档。但我这里要说的是，「快」，就不一样。当你每一个问题都能立即得到答案，你的思考方式是不一样的。你会开启追问模式，你会沿着几个方向追踪下去。

比如你问Bing Chat一个学者是谁，它会简单告诉你这个学者的观点和出版过的书。然后你问它其中一本书讲什么，它会告诉你这本书的内容摘要。然后你再问其中一个概念是什么意思，它再给你解释，并且附带文献。你这样一路追踪下去，能以最快的速度学到一些事情。

要不怎么OpenAI的CEO说他现在宁可让ChatGPT教他东西。这是真·个性化学习，这是字面意义上的「与君一席话，胜读十年书」。

 *第二是让你发现你究竟想要什么。*

科技播客Tinyfool（郝培强）在一个访谈 [4] 中描绘了这么一个场景。比如你想买房，你问AI哪有便宜房子。AI返回一些结果，你一看距离公司太远了，你意识到你想要的不只是便宜。于是你又让AI在一定区域内寻找便宜房子。AI又返回一些结果，你又想到面积和学区……

这种对话的方式能让你想清楚自己到底想要什么。这完全不平凡，因为我们做很多事情之前是不知道自己想干啥的——我们都是在外界反馈中发现自我。

 *第三是帮你形成自己的观点和决策。*

很多人说用AI写报告。可是如果报告里没有你自己的东西，这个报告有什么意义呢？如果报告里只有你自己的东西，AI有什么意义呢？AI的意义是帮助你生成更有你自身特色的报告。

主动权必须在你手里，你必须输出主动，但是你的主动需要AI帮你发现。

 *AI能让你更像「你」。*

它提供创意，你选择方案。它提供信息，你做出取舍。它提供参考意见，你拍板决策。

你这份作品的价值不在于信息量足，更不在于语法正确，而在于它体现了你的风格、你的视角、你的洞见、你选定的方向、你做出的判断、你愿意为此承担的责任。

如果学生的作业都能体现这样的个人特色，大学何必禁止ChatGPT呢？

✵

总而言之，AI的作用应该是放大你，而不是取代你。我们用ChatGPT和Bing Chat的根本套路是一放一收：

* 放，是让思绪在海量的信息里自由飞翔，寻找洞见；

* 收，是找到自我，决定方向，掌控输出。

我以为越是AI时代，普遍的信息越是不值钱。现在个人搞一个信息保存系统已经意义不大了，只要GPT训练过，一切唾手可得，整个互联网就是你的硬盘和第二大脑。

 *你真正需要保存的是*自己*每天冒出的新想法，是*你*对信息的主观整理和解读。*

一切落实到自己。

永远假定别人也会用ChatGPT。

感谢你阅读精英日课，我们专栏专门出品无法被ChatGPT总结的内容。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540121254789660/030311.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023030311/1801540121254789660/030311.jpeg)

注释

[1]卓克·科技参考2：311 | 高级麻烦，ChatGPT

[2]GPT-3：一个令人震惊的人工智能模型

[3] https://arstechnica.com/information-technology/2023/02/meta-develops-an-ai-language-bot-that-can-use-external-software-tools/

[4] Tinyfool：ChatGPT 会如何改变我们的生活，不明白播客，Feb 17, 2023 bit.ly/bmb-037-txt

## 划重点

1.AI到底减弱了人的价值还是扩大了人的价值，取决于你怎么用它。如果你足够强势，当前AI对你的作用有三个：
第一是信息杠杆。
第二是让你发现你究竟想要什么。
第三是帮你形成自己的观点和决策。
2.AI的作用应该是放大你，而不是取代你。

---
