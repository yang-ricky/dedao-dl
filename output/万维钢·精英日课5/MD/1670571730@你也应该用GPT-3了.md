# 你也应该用GPT-3了

我们专栏以前介绍过一个“好到令人震惊的人工智能模型” [1]，OpenAI公司的GPT-3。它的功能十分强大，比如可以根据你的一段描述给你写一段程序，可以帮你写段文章，可以相当智能地回答你的问题等等。之前GPT-3一直都是内测，需要申请账号，我一直没上手。现在OpenAI不但开放了普通用户注册，而且升级了应用模型，而且刚刚推出了一个对话应用，每个人都可以用了。

从此之后，每个人都可以随时跟AI对话，让AI帮着做些事情。

我这几天使用下来，感觉十分惊喜，如同得到一件称手的新兵器——甚至可以说得到一位很能干的助手。我甚至感到了一点他对我的挑战，不过不算严重。

这里说说我的使用心得。

✵

操作是非常简单的。首先你要去OpenAI网站（https://beta.openai.com/ ）注册一个账号，不用付费。每个新注册用户自动获得18美元的试用额度，因为它很便宜，这个额度就够用挺长时间了。Open提供能调用GPT模型做各种应用的API接口，这个非专业人士不用管。注册好账号，直接去网站中一个叫做 Playground (https://beta.openai.com/playground ) 的地方开练就可以。

你要做的就是在页面中直接打字，输入你想让AI干的事儿。

页面右侧选择模型（Model）、温度（Temperature）和最大输出长度。现在默认的模型就是11月刚刚升级的、基于GPT-3的 text-davinci-003，也是最好的一个。「温度」代表AI输出的自由度，也就是有多大的随机性：你要想让它更有创造性，就让温度高一点；你要想让它输出更确定的结果，就调低温度。

一个好消息是你可以直接输入中文，然后它用中文回答。我怀疑它是先把中文翻译成英文，用英文“思考”之后再把结果翻译成中文给你。不过我试用的感觉是中文输出不如英文质量高。

先来一条测试。我输入：「列举15件成功者会做而一般人不做的事情。」它给我的答复（图中绿色字）如下 ——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763025329670152/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763025329670152/120915.png)

它从关注自己的目标、勇于接受挑战、勇敢冒险、接受批评、自律、持续改进等等15个方面总结了成功者的工作特点。

这个回答可以说相当靠谱，你要到大街上随便找个人问，恐怕说不了这么好。如果一个中学生把这个输出当做作业交给老师，我估计老师不会想到这是出自AI之手。而且我还觉得，这个答案真能给人带来启发，可能其中有些条目你自己都没想到。

大概是11月30日，OpenAI又推出一个在线对话应用，叫ChatGPT，直接在网页上（https://chat.openai.com/chat ）输入即可。我用的感觉是ChatGPT输出的答案不如 Playground 的那个 text-davinci-003 模型好，但是它的排版效果、用户友好程度更好。

比如我让它写一个能自动生成一张乘法运算试卷的Python程序，它很完整地给做出来了 ——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763111229007320/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763111229007320/120915.png)

不但给你完整的程序，而且有注释，有讲解。

但是更复杂的要求，比如我让它给我写一段能根据邮政编码输出地址的命令行脚本，这个ChatGPT就做不到——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763185317119652/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763185317119652/120915.png)

但是，Playground 可以做到！GPT-3写的这个脚本，会自动前往一个邮政编码网站给你查询，然后把结果返回给你。

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763260479129608/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763260479129608/120915.png)

……而我自己，其实做不到。我没写过这样的脚本，我甚至都不知道有那样一个专门查询邮政编码的网站。

最近这次升级的一个新特色是GPT-3会作诗了，咱们先测试一段中文的。我让它作一首关于行为主义的诗，结果有点勉强——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763398991742628/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763398991742628/120915.png)

但是它做英文诗的水平，远远超过了我。我让它作一首关于电子和质子的诗，谈谈它们如何相互作用，以及对日常生活的影响，要求押韵。结果你体会一下 ——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763456973883400/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763456973883400/120915.png)

再来一个中文的。这回我让它写首歌，它真的写了一首歌——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763574011733464/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763574011733464/120915.png)

还是没有达到我的要求，也没啥内容。看来中文不是GPT-3的强项，能用英文还是应该尽量用英文。

现在是我最关心的测试：直接写文章。我让它写一篇关于中美芯片战的文章，重点关注2018以后的动作。它真的生成了一篇文章 ——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763693197002404/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763693197002404/120915.png)

文章不是很长，但是有点实质内容。开头有简介；中间有过程，有时间，有双方动作；结尾有总结、有评论、有展望。

如果你觉得这样的文章不够详细，你可以让它给你生成一个大纲，你自己照着大纲写。这回用中文，我让它提供一篇中国在芯片产业技术升级的策略分析文章的大纲——

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763838152230920/120915.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120915/1793763838152230920/120915.png)

这个大纲确实有点内容……只是有点太像领导讲话稿了。

GPT-3还可以帮你翻译，帮你修改一段文字的语法，帮你概括一段文字的简介，我女儿还用它解过填字谜题，等等等，你就自己慢慢探索吧。

✵

不知道你的观感如何。以我之见，直接用AI写文章是完全不现实的。GPT-3能给你生成一篇看起来很完整，也很有内容的文章，这篇文章应付老师的作文题应该也够用，但是这样的文章没有好到能发表的程度。

这里有个本质矛盾：要发表，你的文章必须有新意才行；而AI语言模型的本质就是从经验中挖掘内容，它的出厂设定就没新意。特别是像我们精英日课专栏需要的文章，我们要求每篇都要有个新东西告诉你，而你不会从AI那里得知新东西。

AI甚至不能判断一个事情的真假和一个知识的对错。马斯克很希望给Twitter提供一个AI自动辟谣功能，但是现在发现很难实现。这是因为AI的训练素材包括所有类型的文字——其中有的是科学事实，有的是谣言——AI不分青红皂白全盘吸收。它就如同一个整天泡在网上的人，你问他啥他都听说过，但是他没有思考和判断能力，他不知道自己学的哪个对哪个不对。有人甚至认为 [2]，要想让 AI 会辟谣，就得回归到以前的那种「专家系统」式的AI思路，让它专门学正确的、权威的、有结构的知识才行。

不过说到这里，我还真测试了一下GPT-3。我问它新冠疫苗是否对人体有害，他非常明确地回答：无害，疫苗已经被做过多项研究测试，证明了安全性和有效性！

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120916/1793763893986797016/120916.png](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120916/1793763893986797016/120916.png)

……看来并没有想的那么差。但不论如何，你不应该直接信任AI告诉你的事情。

✵

但是AI仍然很有用。你可以把它当成一个随时可以咨询的研究助理。

我常用的一个做法是让它给我提供例子。比如我最近写了篇文章，其中提到人们有时候会纯粹为了满足自己的情感需求，而做出各种的无效行为。我列举了几个行为，但是我觉得还不够，我就让GPT-3给我列举15种这样的行为。结果它真的提供了几个我完全没想到，而且特别好的例子。

接下来，我让GPT-3给我提供一个关于完美主义者的故事，结果它讲了一个叫莎拉的女性的故事：

> 莎拉事事追求完美，学习成绩特别好，但这是有代价的。她特别害怕自己犯错误，总是很焦虑。每次取得了好成绩，她也并不享受赞美，因为她总是关注自己要做的下一个事。后来因为压力太大，她休学了。

对我来说这个故事还不够酷，而且没有出处，所以我没有在文章里直接使用这个故事——但是，这个故事给我带来了启发，促进了我的思考。

以前这样的事情我都是用搜索引擎做的，我会查找真实案例，给出参考文献。但用GPT-3的好处是快！一问一答，非常方便。信息交换快，你思考就快，你能想的事儿就多。

我们专栏读者@章彦博，分享过一个他用GPT-3获得灵感的经历。他的学术报告的PPT需要一个封面，用来表达「寻找守恒量可以帮助我们研究复杂系统」。他问GPT-3如何用视觉方法表现这个意思，GPT-3给了他三个答案。他选中的答案是“用绳子连接的拼图”。GPT-3说，拼图代表研究的问题，串联其中的绳子就是「守恒量」。然后章彦博又用同是OpenAI出品的DALL-E2根据这个描述画了一张画，效果很好。

GPT-3能回答你的问题，能根据你的需要提供各种素材，能帮你出谋划策，对我来说这已经很有用了。

✵

我目前最大的抱怨是GPT-3是用旧文档、而不是像搜索引擎那样基于最新内容训练出来的。你问他一些最新发生的事情，他不太知道。试想如果Google弄一个基于实时网页的语言模型，也许会更有意思。

但不论如何， *GPT-3已经比苹果的Siri之类现有的流行AI应用强太多了……强到了真能给你帮忙的程度。*

而就在此时，有传闻说OpenAI将在三个月之内推出下一代语言模型，GPT-4。

我就问GPT-3，GPT-4会有什么不一样的地方？它表示它自己只是一个语言模型，它并不知道什么，它无可奉告。

![https://piccdn.umiwi.com/uploader/image/ddarticle/2022120916/1793763919756527268/120916.jpeg](https://piccdn.umiwi.com/uploader/image/ddarticle/2022120916/1793763919756527268/120916.jpeg)

注释

[1] 精英日课第四季，GPT-3：好到令人震惊的人工智能模型

[2] GARY MARCUS, AI Is Terrible at Detecting Misinformation. It Doesn’t Have to Be, Nautilus, November 27, 2022.

## 划重点

去OpenAI网站（https://beta.openai.com/ ）注册一个账号，不用付费。注册好账号，直接去网站中一个叫做 Playground (https://beta.openai.com/playground ) 的地方开练就可以。
它真能帮上你的忙。

---
