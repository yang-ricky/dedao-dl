# 日用而不知的难题

现在 AI 是越来越厉害了……而要不是跟 AI 比，人都不知道自己原来有多厉害。先请你看一张照片 ——

![https://piccdn3.umiwi.com/img/202102/23/202102232012586712905773.jpg](https://piccdn3.umiwi.com/img/202102/23/202102232012586712905773.jpg)

照片中是几个穿着西装的男子，其中一个是美国前总统奥巴马。有个人在体重秤上站着称体重，其他人都微笑地看着他。

你用不了一秒钟就能理解那些人为什么笑。称体重的那位老兄不知道，站在他身后的奥巴马正在用脚压那个体重秤 —— 这样会让他称到一个更重的重量。你能看出来所有人的笑都是友善的。你设想，可能大家觉得这个玩笑很好玩，也可能是大家觉得奥巴马以总统之尊开这个玩笑、这件事儿更有意思。

现在我们的问题是， **AI，得发展到什么程度，才能看出来这张照片的“有意思”？**

计算机视觉专家安德烈·卡帕蒂（Andrej Karpathy）在他的一篇博客文章 [1] 中使用了这个图。他的结论是我们距离那一天非常、非常遥远。这张图只是一组很短的二维颜色数列而已，可是它代表的是人类知识的冰山一角。

为了看懂这张照片，你得知道体重秤是干什么用的，你得知道施加压力能增大体重秤的读数，你得知道为什么这个可以笑，你得知道奥巴马是谁，等等等。一个还没上小学的人类儿童都能看明白这张照片，而她的知识就已经太多了，多到计算机科学家不知道怎么才能让 AI 掌握的程度。

这种我们都有，而 AI 都还没有的，很多是「隐性知识（tacit knowledge）」，也叫做「常识」。

＊

深度学习也好、强化学习也罢，AI 的知识都是基于经验的，都是来自数据。我们讲《为什么》的时候说过，朱迪亚·珀尔有句名言叫「数据是深度愚蠢的」[2]。我们经常赞叹现在 AI 有多厉害，但是现在 AI 的武功都有很简单的命门。

比如说图像识别。我们知道现在基于卷积网络和深度学习的图像识别已经非常强大了 [3]。现在有些智能监控摄像头，会自动识别人脸，而为了识别人脸，它必须知道图像中哪个东西是“人”，对吧？2019 年，比利时鲁汶大学的几个人发明了一种彩色图形，可以骗过 AI 识别。你只要把这个图形打印到一张纸上 —— 不用太大，差不多是一张 A4 纸的大小 —— 然后把这张纸挂在身上 —— 不用蒙住脸，挂在肚子上就行 —— AI 就不会把你当做“人” [4]。

![https://piccdn3.umiwi.com/img/202102/23/202102232013596129065668.gif](https://piccdn3.umiwi.com/img/202102/23/202102232013596129065668.gif)

![https://piccdn3.umiwi.com/img/202102/23/202102232014278123385287.gif](https://piccdn3.umiwi.com/img/202102/23/202102232014278123385287.gif)

![https://piccdn3.umiwi.com/img/202102/23/202102232015018657793122.gif](https://piccdn3.umiwi.com/img/202102/23/202102232015018657793122.gif)

这可不是个例。事实上比利时这项研究是现在很流行的一种“运动”的一部分，叫做「对抗攻击（adversarial attack）」：专门寻找 AI 图像识别的命门，用一招破解它。

侯世达的学生、波特兰州立大学计算机科学家梅拉妮·米歇尔（Melanie Mitchell）2019 年出了本书叫《AI 3.0》（得到有湛庐文化出的中文版，英文书名是Artificial Intelligence: A Guide for Thinking Humans）[5]，这本书一定程度上代表了学界对 AI 的能力的当前科学理解。米歇尔在书中列举了好几个对抗攻击的例子，你体会一下 ——

下面这两张图，左边是原始照片，AI 正确地识别到是一辆校车。右边这张图，研究者做了一些调整，你用肉眼恐怕难以看出来跟左边有什么区别，可是 AI 却把它识别成了“鸵鸟”。

![https://piccdn3.umiwi.com/img/202102/23/202102232015339134123272.png](https://piccdn3.umiwi.com/img/202102/23/202102232015339134123272.png)

下面这几张图，在我们眼中只是一些雪花点，可是 AI 却把它们识别成了“欧洲知更鸟”“猎豹”“蜈蚣”和“雄孔雀”。

![https://piccdn3.umiwi.com/img/202102/23/202102232016069117826285.png](https://piccdn3.umiwi.com/img/202102/23/202102232016069117826285.png)

一个男性研究者戴上一副特殊的眼镜，AI 就把他识别成了一个著名女演员。

![https://piccdn3.umiwi.com/img/202102/23/202102232016393621245194.png](https://piccdn3.umiwi.com/img/202102/23/202102232016393621245194.png)

这些都是怎么回事儿呢？可能是因为 AI 的图像识别都是从细节入手的。AI 并不是像人眼这样看图先看个大概轮廓，它不知道物体占图像面积的比例是多少，它必须注意图中哪怕是很小的物体，否则如果图中有只小虫子它就发现不了。而人眼忽略掉的一些细节，在它眼中却是至关重要的特征结构。

这里面的深层原因是 AI 不知道各个细节元素之间的逻辑关系。

＊

“经验”可以有各种角度。如果只是观察而不懂得原理，你可能会总结一个错误的经验。米歇尔组里有个研究生，自己用现成的图形库训练了一个能判断“这张照片中有没有动物”的深度神经网络。这个网络的准确度非常高，但是研究生仔细研究之后，发现一个大问题。

那个网络是通过“照片中有没有虚化的背景”来判断其中有没有动物的。如同下面这两张图 —— 

![https://piccdn3.umiwi.com/img/202102/23/202102232017247142448397.png](https://piccdn3.umiwi.com/img/202102/23/202102232017247142448397.png)

（A）中有动物，摄影师拍摄的时候聚焦在动物身上，所以背景是虚化模糊的；（B）中没有动物，就是一张自然景观照，所以没有虚化的部分。这只是摄影师的拍摄习惯而已！而那个深度神经网络恰恰把这个，当做了判断有没有动物的标准。它并没有真的学会识别动物。

所有 AI 识别系统都有命门，你绕不过去。归根结底，经验是由训练素材决定的。有研究发现只要换做机器人去房间里各个地方随机地拍照片 —— 而不像人类摄影师那样选择合适的角度拍 —— AI 就很难识别这些照片中的东西：因为它们没见过这么拍照片的。

这就是统计经验不可避免的命门。AI 非常不善于处理不常出现的情况，它们带有各种偏见。如果一个男人站在厨房里，他就很有可能被识别为女人 —— 毕竟对大数据来说，女人在厨房出现的可能性更大。快下雪了，市政当局在公路上预先洒下了盐，形成“盐线”，特斯拉汽车的自动驾驶系统没见过这样的线，结果就发生了功能紊乱。

![https://piccdn3.umiwi.com/img/202102/23/202102232018220653678051.png](https://piccdn3.umiwi.com/img/202102/23/202102232018220653678051.png)

其实我也是第一次看到盐线。但是如果我开车遇到盐线，我就能看出来它们和正常交通标志线的区别，我很可能还可以猜出来它们是干什么用的。

因为我有常识。

＊

米歇尔说，当今学界基本上达成了一个共识，也是现阶段的研究热点，就是让 AI 学习人类的常识。Cycorp 公司有个项目叫 Cyc，就是一个专门针对 AI 的人类常识系统。Cyc 中的一些常识是下面这样的 ——

*一个实体不能同时身处多个地点。

*一个对象每过一年会老一岁。

*每个人都有一个女性人类母亲。

然后 Cyc 还会基于这些常识做逻辑推理。比如如果你告诉它现在你在北京，它就知道你不在哈尔滨。可是这里面有个大问题。

像这样的常识，都是我们都知道 —— 可是我们*不知道*我们知道 —— 的知识。你知道你会多少条常识吗？你能把它们一条条地都写出来吗？你不知道。Cyc 系统中像这样的常识已经有了 1500 万条 —— 我都不知道那些研究者是怎么列举出来这么多的 —— 而据 Cycorp 公司判断，这些还只是最终所需要的常识总数的 5%。

你能想象吗？你有那么多条知识。这还不算有很多知识是你能随时生成、而 AI 却很难看出来的。米歇尔列举了俄罗斯计算机科学家米哈伊尔·邦加德（Mikhail Bongard）发明的一类问题，叫「邦加德问题（Bongard problems）」，你体会一下。下面这些问题中，每组左边的六张图跟右边的六张图有个区别，你能说出来是什么区别吗？

![https://piccdn3.umiwi.com/img/202102/23/202102232019227116599876.png](https://piccdn3.umiwi.com/img/202102/23/202102232019227116599876.png)

对你来说这一点都不难。比如第2题，左边的图形都比较大，右边的都比较小；第3题，左边都是空心的，右边都是实心的……你一定能做出来下面这道题：测试样本中那个图形，应该归类于类别 1，还是类别 2 呢？

![https://piccdn3.umiwi.com/img/202102/23/202102232019562159415196.png](https://piccdn3.umiwi.com/img/202102/23/202102232019562159415196.png)

答案当然是类别 1，因为图中两个物体的形状和大小都一样。这些题目中每道题的规律都不一样，可是我们都能轻松看出来。我们做每道题只用了六个样本！有人用两万个样本训练一个卷积网络做上边这道题，结果 AI 的表现只比随机猜测好一点点。

如果你感兴趣的话还可以尝试一下下面这几道更难一点的邦加德问题，AI 绝对无能为力 ——

![https://piccdn3.umiwi.com/img/202102/23/202102232020534139648052.png](https://piccdn3.umiwi.com/img/202102/23/202102232020534139648052.png)

对 AI 来说，这些题可比下围棋难多了。你是怎么找到那些关键区别的？计算机科学家肯定说不清楚。我们人类有迅速感知新概念的能力，这个能力的背后可能是「类比」。但这句话说了等于没说，因为我们很难说清「类比」到底是怎样一个过程。不论如何，这是我们目前为止绝对的特长。

＊

经过跟 AI 的对比，我们似乎也加深了对自己的理解。原来我们知道这么多说不清道不明的知识。其实哪怕你抛开 AI 不论，单纯研究人类的这些隐性知识也很有意思。

有些常识，你意识不到也就意识不到，但是一旦意识到，会发现其中有个很妙的逻辑。我给你举个例子。

有一个婴儿和一个机器人都快要掉下悬崖了，你正好在旁边，你会救谁呢？肯定是救婴儿，毕竟那是一个活生生的人，而机器人只是机器。可为什么人就比机器该被救呢？

有一位县长，公然用拳头猛打一个五岁小女孩的脸，你肯定会谴责这个县长。可是如果反过来，如果是这个小女孩用拳头打这位县长，你肯定觉得无所谓。那这又是为什么呢？

你不一定仔细想过为什么，可是你的直觉已经告诉你该怎么判断了。那人类的道德判断，有什么客观标准吗？

有本书叫《人心的本质》（2020，得到电子书有）作者是两位加拿大心理学家，丹尼尔·韦格纳和库尔特·格雷。这本书中对此提出了一个“统一理论”。这本书说人有两种心智能力。一种叫 *「感受性（experience）」* ，意思是你能感觉到痛苦。一种叫 *「能动性（agency）」* ，意思是你的行动力。这个理论说，

 **道德程度的高低 ＝ 主体的能动性 ＋ 受体的感受性**

什么意思呢？小婴儿是人，他有充分的感受性，而机器人没有，所以我们应该救小婴儿。县长大人打人的能动性很强，他挨小女孩打的感受性很弱，而小女孩正好相反，所以小女孩打县长可以，县长打小女孩不行。

就这么简单。两位作者据此推导出一系列有意思的结论。

所以你看，这就是人类常识的有意思之处：我们日用而不知。你遇到各种情况都知道该怎么办，可是如果没遇到那些情况，你说不清你知道多少个“怎么办”。你从来没刻意学习过，甚至从来都没想过你知道那些，但你就是知道。这是人工智能远远不如人的地方，也可能是目前所知人类最重要的特长。这些常识有可能像「能动性」和「感受性」那样进一步简化，但也有可能是语言所无法穷尽的。

这个局面很奇妙。 *生而为人，你都不知道你有多厉害。*

## 划重点

你遇到各种情况都知道该怎么办，可是如果没遇到那些情况，你说不清你知道多少个“怎么办”。你从来没刻意学习过，甚至从来都没想过你知道那些，但你就是知道。这是人工智能远远不如人的地方，也可能是目前所知人类最重要的特长。

![https://piccdn3.umiwi.com/img/202102/23/202102232022266123578324.jpg](https://piccdn3.umiwi.com/img/202102/23/202102232022266123578324.jpg)

---
