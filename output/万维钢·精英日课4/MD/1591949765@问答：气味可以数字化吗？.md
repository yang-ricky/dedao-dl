# 问答：气味可以数字化吗？

## 来自日课：购物和广告

> 读者 行舟：
> 
> 我喜欢吃海底捞，但是今天偏偏要尝尝隔壁那家潮汕牛肉火锅，对此 AI 是怎么知道的呢？或许我这次买衣服想要换一种风格，我不能为了图方便放弃自己选择的权利吧，这类问题能被 AI 解决吗？

> 读者 不认识@2017：
> 
> AI 助理帮我选个产品的话，我的风格会不会被逐步统一化，然后越来越强化，只变成了一种模式呢？像我现在虽然买东西有一定的风格，但我也有不少时候是很随机买的，会尝试很多新的东西，那这个会不会也被作为风格的一种呢？

> 万维钢

 *每一个新事物都有利有弊，但我们考虑未来一定得注意，这只是提供了多一种可能性，一种可选项，而不是一个要求。* 我们*可以*把这些事情交给 AI 助理，但不是*应该*这么做，更不是*必须*这么做。

一个新技术要想流行开来，肯定是给人提供了更多的自由，而不是更多的限制。AI 助理替我们做选择，是为了把我们从日常琐碎的选择中解放出来，去思考你更感兴趣的事情。心理学家证明，做选择，是一个消耗脑力的活动。

扎克伯格为了不琢磨穿什么衣服就干脆每天都穿一样的衣服；王安石跟谁吃饭都只吃自己面前的一盘菜。AI 助理可以让他们既不用琢磨吃穿，又能在吃穿方面有一定的水平。事实上这样的服务已经有了。有个公司提供“订阅”衣服服务：你把自己的尺码告诉他们，回答几个测试题让他们大致了解你的喜好，然后就不用管了。他们每个月给你寄一套服装。这些服装未必你都喜欢，但是肯定能体现当前的流行水平。

AI 助理并不仅仅代表你，而且还代表所有人对当前世界的最新理解，它懂你而且懂行。选择水平很大程度上取决于你知道有多少个可选项。AI 助理会比我们更了解现在有什么东西可以选，它除了知道海底捞和潮汕牛肉火锅还知道几家你没听说过的餐馆，就好像是一位美食家，那你说交给它安排是不是更好，提供更多意外。

而且其实我们买到的所有产品都已经被定制过了。你并没有选择一件衣服所有的细节，你不能控制它的纽扣是什么样的，你看看差不多就用了。摩托罗拉手机曾经提供深度定制，但是效果并不好。现在你买个手机、甚至买新辆车，都不是可选配置越多越受欢迎。大多数人的态度是相信设计师。

而这些我们无法自己定制、都做成了固定的成品的产品，实际上是拉高了这个世界的设计水平。我们买个什么东西经常发现其中有个设计是惊喜。现在满大街人穿的衣服都是商店里买的，出自专业服装设计师之手 —— 那你要非得说我有个性，我不接受别人的设计，可以！但是你自己设计的这件衣服必须比专业水平高，你才值得这么做。

> 读者 小白要上楼：
> 
> 无论是忘记商业还是商业无处不在，购物都显得更加便捷，或者说我们可以从挑选商品中解放出来了，人类仿佛变得越来越“闲”了，这个时候我们的情感需求、人文关怀会变得更强烈还是更淡漠呢？

> 万维钢

情感和人文关怀的强烈和淡漠跟技术的关系不算大。你读《红楼梦》也好，或者看《权力的游戏》《唐顿庄园》这些电视剧也好，一定会注意到，过去那些所谓“贵族”的情感，比我们现代人要细腻得多。他们非常注意说话的措辞，很善于照顾别人的感受，一点点事情都要考虑细致。他们习惯于用比较微妙的方式表达一个意思，而对方也都能领会。我们看古代诗词描写的情感比现代人也丰富和精妙得多。

这一方面的确是“闲”出来的，但也是“惯”出来的。人与人之间的互动多、关系复杂，每种情感表达出来有人回应，情感才会越来越丰富和细致。反过来说如果关系简单，每天大部分时候是跟物品打交道、甚至都不怎么跟人接触，那就没什么情感。

以前技术一直在减少人和人之间的接触，都是让人越来越多地跟机器接触。这一代人的情感好像不如上一代人丰富。但是未来 AI 会不会增加人与人的接触，未来的工作会不会更多的是跟人而不是跟机器打交道，甚至 AI 能不能给人提供一些情感反馈，现在好像很难说。

## 来自日课：娱乐和教育

> 读者 龙鱼凤：
> 
> 用脑电波玩游戏的头盔会在多短的时间内出现？

> 万维钢

用大脑直接控制屏幕上的东西，包括让人的大脑和大脑联网，现在都已经做到了。但你要说用脑电波玩游戏，这个应该不是*能不能*的问题，而是*好不好*的问题。能肯定是能，问题是它不好，游戏体验不好。游戏玩家特别讲究反应时间和控制的精确性，总是要把信号延迟降低到最低，把信号的精确度提高到最高。

通过大脑的意念信号直接对外控制，这个信号必须足够强才行，而信号强度大就意味着时间慢，生成比较费力，分辨率比较低，对注意力要求比较高。想要表达复杂的意思，还不如直接用手操控。而我们现在用手打字几乎就是无意识在操作键盘。大脑通过训练已经把打字行为在神经元层面编码了，并不需要想得很清楚就能打字很清楚。等于是你的“手”，替大脑分担了一部分思考 —— 脑机接口要做到这个程度恐怕是非常困难的。

> 读者 潘辉：
> 
> 有的时候学生自己都不知道自己的思维障碍在哪里。他可能以为自己不懂问题 A，但实际上是因为他不懂前提条件 B。就像我们有时候耳朵疼，但病根子不在耳朵，而是在喉咙里。往往要很有经验的老师才能够通过不断排查找出学生真正的思维障碍。这一点可能跟 AI 医生有相似之处，但 AI 医生能够拿到患者身体的各项数据，AI 讲解员能够“读脑”吗？

> 万维钢

我们确实不能指望 AI 完全替代老师，AI 的作用应该是扮演一个助教的角色，帮助老师。而正如 AI 对医生很有用，AI 能给老师提供强有力的帮助。

以前丹尼尔·卡尼曼在《思考，快与慢》这本书里讲到，仅仅通过观察一个人眼睛瞳孔收缩的情况，就能判断他是否仍然在费力思考。我不知道有没有人做这个观测，但是现有的技术已经能跟踪一个班级所有学生的注意力集中情况。我们不应该用这个技术去惩罚那些注意力不集中的学生，但是 AI 可以随时让老师知道你现在讲的东西有多少学生没跟进。

AI 医疗诊断还给我们一个启示。如果有充分多的数据，AI 就是最有经验的老师，代表全体教师对知识点、对学生的最新理解。如果一个学生不懂问题 A ，AI 很可能会在老师之前，猜测到他是因为什么没懂，并且给老师提示。

而要做到这一点，就要求老师像医生一样，给每个学生做病历，收集学生的数据和案例，还得经常写论文跟其他老师交流。有了这样的输入，我们就可以给所有的知识点建立数据库，知道每个知识的难点和易错点在哪里，不同类型的学生学会大概需要多长时间，列举几种讲解方式，什么方式适合什么水平的学生等等。

这对老师提出了更高的要求 —— AI 一方面把老师从繁重没意思的工作中解放出来，一方面创造了新的工作。也许未来会出现专门的研究型老师、讲课型老师、互动型老师这样的分工。

## 来自日课：长生不老是个技术问题

> 读者 aohan：
> 
> 嗅觉和触觉可以数字化吗？

> 万维钢

触觉很简单咱们就不用说了，单说嗅觉。味道，怎么数字化的呢？

颜色和声音都可以用某种东西的振动频率表示，颜色是光波的频率，声音是声波的频率。频率本身就是数字。对声音来说，不管什么复杂的声音都可以写成一系列单纯声音的叠加，你做个傅里叶变换就知道这个声音是哪几个频率之和，你就可以用一组数字表达任意一个声音。

颜色的数字化跟声音不一样。我们不能用屏幕上“震动”某种东西来显示颜色，但是我们可以用三种颜色合成任意的颜色。这是因为人眼对红、绿、蓝这三种颜色的感受最强烈，我们在神经意义上只有这三种颜色的受体！对人眼来说，拿这三种颜色的不同强度去配其他所有颜色就够了。

但是气味是什么呢？它是各种分子跟鼻子里的神经相互作用的产物。气味不是简单的震动，所以不能像声音那样用频率分解。

原则上气味可以像颜色一样，通过几种标准的气味合成 —— 那是几种呢？我们只有三个颜色受体，却有 400 个气味受体！原则上你把这 400 个标准气味弄明白了就可以合成一切气味，但是我们现在根本没研究明白哪个受体对应什么气味 —— 你说怎么研究？你得试验无数种气味，还得让受试者精确描述他闻到了什么，然后求解一个有 400 个未知数的方程才行。

所以现在的数字化气味设备都是只用很有限的若干种气味混合，它不可能百分之一百重现比如说一朵鲜花、烤羊肉或者大海的气味，只能把常用的集中编码。这种设备需要“打印机墨盒”一样的东西，里面存着各种化学药品，通过吹风散发。对看电视来说其中一个问题是气味散发出来有个时间延迟，可能镜头都过去了，你才闻到味道。

不过有些应用不需要这么精确的控制。现在有一种设备把音乐跟气味编码在一起，你可以一边欣赏音乐一边闻到某种令人愉快的气味，不必精确，但已经可以用了。

还有个办法是不用化学物质，用电信号直接刺激人鼻孔中的神经受体 ——

![https://piccdn3.umiwi.com/img/202006/12/202006121621239559498841.jpg](https://piccdn3.umiwi.com/img/202006/12/202006121621239559498841.jpg)

这个可以用在 VR 头盔上。但是这个也还在实验之中，毕竟我们仍然不知道那 400 个受体各自对应着什么气味。

![https://piccdn3.umiwi.com/img/202006/12/202006121621534110169958.jpg](https://piccdn3.umiwi.com/img/202006/12/202006121621534110169958.jpg)

---
