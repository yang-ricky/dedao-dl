# 第194封信 | 合作智能——我的导师库旦普教授对人工智能的看法

几周前我回到约翰∙霍普金斯大学开董事会，按照惯例，作为会议议程的一部分，我们都会请一位教授介绍某个学科最前沿的研究成果。这一次做报告的恰巧是我的论文导师库旦普教授。他现在是大学里一个国家实验室人类语言技术卓越中心HLTCOE（Human Language Technology Center of Excellence）的主任，该中心是美国大学里规模最大的语音识别和自然语言处理的实验室，也是全球在相应研究上水平最高的中心之一。

作为中心主任，库旦普教授是今天美国公认的机器学习专家。在报告中，库旦普教授谈了他对当今和未来人工智能发展的看法。我把它们总结为下面五个要点。

 **1. 目前人工智能是设计者的智能。**

我之前讲过，“人工智能”这个词更准确地讲应该是机器智能，也就是说今天计算机所体现出来的某种智能。那么机器的智能是怎么来的呢？当然不是它们本身进化、思考的结果，而是某些人赋予的，具体讲，谁设计了人工智能的程序，谁就赋予了机器智能。在这种情况下，哪一家的人工智能更强，只取决于两个要素：

 *a）它的设计者的智能水平；*

 *b）它使用的硬件的水平和数据量的多寡。*

比如AlphaGo团队的水平很高，它设计的智能程序就很厉害，但是如果你只给它一台手机，让它去下围棋，这个胜率就要大打折扣。相反，如果像Google那样使用了大量的资源，就占便宜了。

因此，今天要论人工智能的绝对水平，包括像约翰∙霍普金斯大学这样的学术界研究机构，都无法和Google、微软、亚马逊和Facebook等公司竞争，至于只有几个人的小公司，或者只有几个人的大学研究小组，更是无法做出绝对水平很高的研究成果。

一些人（特别是小公司里的人）讲，我的水平高，超过Google的研究员，这是毫无意义的事情，因为那一点水平的差异（即使存在），也会被大公司的体量抵消掉，更何况很多人自以为自己水平高，是因为不清楚Google、微软这样的公司里面藏龙卧虎。

因此，库旦普教授将约翰∙霍普金斯大学人工智能的研究定位在Google、微软等大公司研究机构有兴趣却不值得做的课题，具体讲就是更深入、更前瞻、短期未必见效的项目。事实上，Google、Facebook等公司也和它的中心有战略合作，寄希望于大学做更长远的研究。

至于小公司，包括非IT的公司，库旦普教授认为，它们的出路就是利用大学和大公司的研究成果解决实际问题，具体说就是搞开发不要搞研究。这当然对初创公司和小公司有些残忍，但这是今天的现实。

接下来，库旦普教授又讲，既然人工智能是设计者赋予的，那么它们在某种程度上就是设计者们想法和意志的体现。机器学习的普及，使得大量信息的所有者，和提炼信息比别人更有效率的人，占据全方面的优势。

比如高盛设计的股票交易程序，使高盛的利益最大化，而根本不需要考虑其他人的利益，这是当下人工智能的特点之一。甚至，在人工智能研究的内部，各个领域也是有竞争的，比如自然语言处理技术发展快了，相应的机器学习算法就丰富，而那些算法未必直接对无人驾驶汽车技术的进步有帮助。

也就是说，即使看似通用的机器学习算法，也不过是那些最初设计它们解决实际问题的研究者们智力的延伸。

 **2. 今天的人工智能其实是昨天世界的某种再现，只不过从昨天到今天的变化是连续性的。**

库旦普教授讲，由于人工智能技术主要依靠数据和所谓的智能算法，即数学模型。因此，它其实是再现昨天的世界，只不过昨天的世界和今天的世界之间是连续变化的。

比如说，人脸识别软件，使用你过去的照片进行训练，识别今天的你，之所以能识别得准，是因为昨天的你，去年的你，甚至10年前的你，和今天的你之间是渐变的、连续变化的，而不是跳变的。

再比如在语音识别中，一个人一辈子的发音，很多人对同一个语音的发音，都是相对稳定的。如果遇到不连续的情况，人工智能就失灵了。比如Google的无人驾驶汽车，遇到路上的沙袋就不认识了，这就是非连续性变化，它就要躲闪，而不是压过去，结果就撞了旁边的车。

每次到了金融危机时，由于次次情况都不太相同，因此交易股票的程序总要出错，触发股灾。而人的特点是，人们可以处理不连续性，因为他们不是重现昨天的世界。比如陪审团遇到过去没见过的案子，照样能够根据经验和常识作出较为合理的判断，一个人在荒野里没有了手机信号，没有了汽油，一样能想办法自救，而不需要经历第二次才学会处理。

但是另一点，由于人不是重现昨日的世界，因此人类的行为具有随意性。昨天和今天，你就同一件事分别询问他的看法，得到的回答可能是不同的。但是人工智能就不会出现这种状态，它们由同样输入得到的输出是稳定的。这是优点也是缺点。优点是它们很忠诚，很好地执行设计者的意图，缺点是缺乏多样性，以至于难以进化。

 **3. 今天的人工智能是交互但是没有合作。**

交互这件事无论是对人，还是对计算机都很重要。在人工智能出现之前，人使用计算机，就需要交互。那时的交互，是事先设定好的，对人给出的要求作出反应。比如在计算机上发一个命令，打印一个文件，它就照着做了，这就是一种反应。

在今天的人工智能应用中，计算机和人的交互从事先设定好，进步为按照事先设定的学习程序学习。比如Google搜索就是一种交互，结果固然是事先的算法设定好的，但是当你开始对输出的结果提供反馈后，比如点击结果或者翻到下页之后，它就进行学习了，下一次的交互结果会不同。

再进一步，当你坐在无人驾驶汽车中，这辆汽车就会进行双重交互，一方面是和你（乘客）通过语音进行交互，另一方面是和其他车辆进行交互，比如躲避、超车、减速等等。

但是，到目前为止，所有的人工智能还只有交互。即使我们觉得它很贴心，也不过是因为机器学习，使得交互做得更好了，它还远没有开始和人进行合作，这一点和人不同。

还是拿自动驾驶为例。库旦普教授讲，Google的无人驾驶汽车比特斯拉的好得多，因为前者几乎不可能自己撞到隔离墩上，或者开出车道，而后者如果人不监控，会经常如此。但是库旦普教授说，这只是和环境交互得好，Google的无人驾驶汽车，依然无法和周围有人驾驶的汽车合作。今天，它几乎全部的交通事故（虽然大多是被动的），都源于它对周围司机行为的误判，比如速度过缓。

人在开车的时候，如果堵了后面的车，会主动躲到旁边（pull over），这就是一种合作。在遇到红绿灯时，会根据后面车子的速度决定是快速过去，还是停下来，以最安全的原则为准。这些常常是人之间的默契。但是今天的无人驾驶汽车是没有的。合作这件事，不是事先程序能够设计好的，甚至不是简单的机器学习能办到的。

 **4. 今天的人工智能，会放大个人意志。**

由于人工智能从本质上讲是设计者意志的体现，它越强大，其实就是将个人意志放得越大。以Facebook为例，它在美国中期选举前删了很多自认为不好的帖子，并且关掉了一些公众号。但是，大家质疑它，你凭什么删？Facebook讲，那些帖子是政治谩骂、恶意攻击。就算Facebook的判断没有错误，但是Facebook不是执法者，它没有权利执法。

在现实生活中，你要对一个你不喜欢，甚至犯罪的人采取行动，对方是有权利反抗的。但是在Facebook上，对方做不到。更何况它觉得妥还是不妥的东西，完全是公司内部一些人的看法，那些人通过人工智能，对不符合自己价值观的事情直接执法了。

造成这个结果的原因，库旦普教授认为，是因为我们作为用户，无法和Facebook的人工智能程序合作。最后，个人（人工智能的设计者）可以随意放大自己的意志。

在讲座中，库旦普教授还谈到了隐私、数据安全等问题。

 **5. 对于人工智能的未来，库旦普教授认为最关键的是建立与人合作的人工智能。**

他认为，今天的人工智能其实并不和使用者合作，它只是设计者意图的表现，设计者要想和你合作，你就觉得它显现出合作的特点。反之当设计者想利用它占你的便宜，你也无能为力。但是，人做事不是这样，一个独裁者给下面的人下命令去害人，下面的人未必会遵从，因为人和人之间是趋于合作，而不是对抗的。

今后人工智能必须解决的三个问题是： *与人的合作，隐私和数据安全问题，以及对非连续性情况的处理。*

希望他的想法对你了解人工智能有参考意义。

 **思考题：**

对于今天的人工智能会放大个人意志，谈谈你的观点。

![https://piccdn3.umiwi.com/img/201810/28/201810282232516987098929.png](https://piccdn3.umiwi.com/img/201810/28/201810282232516987098929.png)

## 划重点

1. 目前人工智能是设计者的智能。

2. 今天的人工智能其实是昨天世界的某种再现，只不过从昨天到今天的变化是连续性的。

3. 今天的人工智能是交互但是没有合作。

4. 今天的人工智能，会放大个人意志。

5. 对于人工智能的未来，库旦普教授认为最关键的是建立与人合作的人工智能。

![https://piccdn3.umiwi.com/img/201810/28/201810282233220285979129.jpg](https://piccdn3.umiwi.com/img/201810/28/201810282233220285979129.jpg)

---
