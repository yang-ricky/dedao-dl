# Facebook不想让你知道的大数据算法

提起“大数据”，你首先想到的是什么呢？我想到的是现在大数据对人的判断之准。先讲一个真实的故事，我不记得在哪里看到的了，但这个故事你听一遍就很难忘记 —— 

话说有个父亲，发现美国的连锁超市塔吉特（Target）经常给他女儿寄孕妇用品的广告，非常恼火，因为他女儿还在上高中！他高调抗议，塔吉特公司马上郑重道歉，连高层都出面了。结果过了一个多月，这位父亲找到塔吉特公司，向他们道歉，因为他发现女儿真的怀孕了。

塔吉特公司是通过对这个女孩购物记录的分析，做出了怀孕的判断 —— 而显然女孩并没有告诉家人。

所以这个时代的主题似乎就是，大数据比人更了解人。

 *又或者……是吗？*

今天我要说的是最新一期《纽约书评》上的一篇文章，They Have, Right Now, Another You （现在，他们有一个不同的你），作者是女作家休·哈尔彭（Sue Halpern）。

文章说的这个“他们”，主要是指Facebook。 *而Facebook，现在基本上是个数据公司。*

哈尔彭说，Facebook对每个用户搜集98项数据 —— 你的种族、年收入、房产的价值、是否是一个母亲、是一个什么类型的母亲、是否已婚、信用额度如何，等等等等。有些数据是你主动填写的，有些数据是它自己分析出来的 —— 你贴张毕业照，它就知道你毕业了；你贴张晒娃照，它就知道你有孩子了。Facebook甚至能从你朋友发布的合影照片里，通过人脸识别技术，找到你，把数据记在你身上。

Facebook还直接从5000家数据交易商那里购买数据，它还能拿到地方政府机构的公共数据，比如说你的汽车注册情况，破产声明，以及成立公司的注册信息。

不过最厉害的，还是各大网站上的那个Facebook按钮 —— 不论你是否点了这个按钮，Facebook都能知道你浏览了这个网页 —— 这个按钮本来就是Facebook搜集数据的工具。Facebook时刻跟踪你的浏览情况，就算你在浏览器设了禁止追踪都没用。 

![https://piccdn3.umiwi.com/img/201612/08/201612081302112417379436.png](https://piccdn3.umiwi.com/img/201612/08/201612081302112417379436.png)

搜集了我这么多数据，你应该能精确地了解我，对我投放一些精准的广告了吧？

哈尔彭说， *并没有* 。

哈尔彭收到的广告包括日本某知名乐队新出的唱片，和有关恐龙的玩意儿，可是她对那些东西根本没兴趣。

更关键的是，她浏览过的网页，也跟Facebook推送的广告没关系 —— 是，她看过一个女拳击手的相关信息，这个女拳击手的外号叫“霸王龙”，她给点了个赞……然后Facebook就开始向她推送有关恐龙页面的广告？

Facebook对判断个人喜好和广告推送的算法是严格保密的，哈尔彭只能推测这些推送的逻辑。

一种可能性，是Facebook故意把她包装成那个日本乐队的粉丝和喜欢恐龙的人 —— 因为这样的你，对Facebook更值钱。你喜欢著名乐队，广告商就能卖给你有关这个乐队的东西；你如果只喜欢本地的一个小乐队，广告商就拿你没办法。也许Facebook千方百计地从你的浏览记录里找出蛛丝马迹，故意勉强地把你包装成对它来说更有价值的人，然后把你的信息卖给广告商。

 *这样说来，也许Facebook的算法并不怎么在乎判断是否“准确”，它在乎的是“有联系”。*

另一种可能性，就是现在的大数据判断能力确实还不行。

剑桥大学有一个精神计量学（Psychometrics）中心 —— 精神计量学就是通过大数据分析对你进行人格测验，判断你是个什么人……然后把结论卖给广告商。这个中心吹嘘自己能通过你在Facebook上的点赞来对你进行性格分析，还号称做了一个“人格预测引擎”，能帮助商家根据你的性格精准推送广告。

哈尔彭就试用了一下这个引擎，结果哭笑不得。她是个女人，但引擎认为她是个“有女性化倾向的男人”，而且有可能是个同性恋。这个看似接近事实的结果是怎么得出来的呢？她经常给《纽约书评》上的网页点赞，引擎就认为她有女性化倾向；她经常阅读《纽约时报》，引擎就认为她有可能是个男同性恋。

看纽约时报怎么就成同性恋了呢？我们无从得知。反正大数据的逻辑，你也知道，就是只问相关性，不问因果性，也许爱看纽约时报跟身为同性恋之间有比较强的相关性吧。

不过哈尔彭认为，大数据的很多判断其实是有人为痕迹的。比如我们要搞个网上的选美比赛，使用大数据方法从世界各地寄来的美女照片中选择最美的一个，那你几乎可以肯定，最后选出来的会是一个白人。这是因为程序员训练算法用的数据都是白女照片。这不就是偏见吗？

 *有商业偏见，有能力偏见，有人为偏见，总之你不能对商业化大数据的判断水平有太高的期待。*

还有更坏的消息。哈尔彭综合两本新书的内容，告诉我们，Facebook和Google这些公司的商业化大数据应用已经到了有点离谱的境界了。

这两本书是Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy ，by Cathy O’Neil （数学杀伤性武器：大数据如何增加不平等和民主的威胁）和 Virtual Competition: The Promise and Perils of the Algorithm-Driven Economy ，by Ariel Ezrachi and Maurice E. Stucke（虚拟竞争：算法驱动经济的承诺和风险）。

现在的大数据推送广告，有三个境界：

* *从你的言行判断你是什么人。* * 这是传统的做法，也就是分析你在网上的浏览记录，乃至窥探你的邮件内容，来定向推送广告。

* *从你的周围环境判断你是什么人。* * Facebook知道你的住址，就知道了你是穷人还是富人。它甚至有一个通过你的交往圈来评定你的信用等级的体系！如果你的交往圈子都是来自于金融公司或者高端行业人群，Facebook就会给你很高的信用评级。如果你交往圈子中的人都不怎么样，甚至有很多穷人，它对你的评级就低。

* *从你的种族判断你是什么人。* * 哈佛大学有人做过实验，说如果你在Google搜索一个黑人常用的人名，Google就会有更高的概率向你推送那种……刑满释放人员最需要的服务的广告，比如信用分数低怎么申请信用卡之类。

 *这不是赤裸裸的歧视吗？ *

## ｜我的评论

以我之见，就算不是出于盈利目的故意把你包装成另一个人，所谓大数据的判断结果，也没必要搞得特别准确。

比如Facebook向一万个人推送某个广告，如果其中能有2000人对广告有兴趣，有100个人有购买意愿，这就已经是很好的成绩了。也许传统广告播放几十万次才能产生100个购买。广告只要稍微有点针对性，商家就能省下一大笔钱，个人也可以少看一些不感兴趣的内容，这岂不是双赢吗？

更何况，推送不准， *也许一个遥远的联系还能带来惊喜！*

唯一问题是这个广告可能冒犯，甚至可能歧视了8000人。但这根本无所谓。这8000个人对广告商来说，只是分母而已，他们更关注的是那100个人。

也许你是个中产阶级，Facebook一不小心向你推荐了一个只有穷人才需要的高利贷服务，你稍微感到了一点点冒犯，可这又算得了什么呢？

你只是Facebook的 **用户** 而已，你不是 **客户** 。 *别忘了Facebook对我们的“服务”可都是免费的。*

现在的Facebook是个盈利能力极强的公司。仅仅2016年第三季度，它的利润就达到了23亿美元 —— 而这23亿美元中，没有你的一分钱，都是广告公司出的钱。

如果Facebook是个牧羊的畜牧公司，你可不是花钱来买羊毛和羊肉的客户。

 *你、我，我们这些高高兴兴地、乐此不疲地、甚至已经上瘾地分享照片、发状态、点赞的人，都是*  **羊**  *。 *

## 划重点

1. 也许Facebook的算法并不怎么在乎判断是否“准确”，它在乎的是“有联系”。
2. 大数据的很多判断其实是有人为痕迹的。有商业偏见，有能力偏见，有人为偏见，总之你不能对商业化大数据的判断水平有太高的期待。

![https://piccdn3.umiwi.com/img/201612/08/201612081303494290305713.jpg](https://piccdn3.umiwi.com/img/201612/08/201612081303494290305713.jpg)

---
