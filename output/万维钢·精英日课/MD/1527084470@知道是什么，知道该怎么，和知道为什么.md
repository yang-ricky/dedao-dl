# 知道是什么，知道该怎么，和知道为什么

咱们这几天连载解读麦兹伯格的《意会》这本书，最根本的主题，是在算法越来越厉害的这个时代，我们应该怎么发挥人类思维的特长……如果人类思维还有特长的话。

四月3日这期《纽约客》杂志有篇文章正好说的也是这个话题。这篇文章的作者是个名人，悉达多·穆克吉（Siddhartha Mukherjee），他是个肿瘤学家，写过一本在中国也有很大影响力的书叫《众病之王：癌症传》。他这篇文章的题目是“现在算法要来看你”（ The algorithm will see you now ），讲的是用深度学习算法进行医疗诊断的事情。 

![https://piccdn3.umiwi.com/img/201704/11/201704111834172522159729.jpg](https://piccdn3.umiwi.com/img/201704/11/201704111834172522159729.jpg)

就算不看穆克吉这篇文章，你大概也已经知道，现在人工智能在医疗诊断方面的水平即将超过人类专家。比如说从一张CT扫描照片中发现病变，现在就是算法做的更好。所以好几年以前就有人说，“放射科医生”这个职业，恐怕很快就要过时了。

美国放射科医生的年薪超过30万美元，是多年艰苦训练出来、优中选优的人才，难道说被淘汰就被淘汰了吗？

穆克吉这篇文章可以给我们有两个收获。 **第一，算法的准确度和效率的确比人强。第二，人还是比算法厉害。 **

## 1.怎样诊断黑色素瘤

咱们都看过一个电影叫《非诚勿扰2》，里面有个情节是孙红雷扮演的那个角色最后是死于黑色素瘤。这是一种癌症，但是病变初期的表现，就好像是皮肤上一个普通的“色素痣”一样。

![https://piccdn3.umiwi.com/img/201704/11/201704111836313903661277.png](https://piccdn3.umiwi.com/img/201704/11/201704111836313903661277.png)

那你怎么知道，到底是长了一个无伤大雅的痣，还是长了黑色素瘤呢？

最稳妥的办法，是做活组织切片检查，但是你显然不想每长个痣就动刀。好在医学家发现黑色素瘤和普通色素痣的外观还是有区别的，总结来说，黑色素瘤的外观具备所谓“ABCD”四个特征 —— A 非对称（asymmetry）；B 边缘不规则（border irregularity）；C 颜色改变（color variation）；D 直径（diameter）更大。

如果你是一个皮肤科的医生，就要学习上面这四个规则。患者来找你诊断，你就要根据这些规则作出判断。那算法也可以学习这些规则啊？你甚至可以弄个手机App，用户拍张照片就自动判断是不是黑色素瘤，岂不是很好吗？

但问题远远没有这么简单。首先这个ABCD只是一个大致的说法。很多黑色素瘤并不符合ABCD特征；看似符合ABCD特征的也未必是黑色素瘤。一个训练有素的医生必须能看出来那些“不合规则”的黑色素瘤。

另一方面，基于明确规则的诊断算法，现在已经基本上被科学家抛弃了。规则写得再明确，也总有照顾不到的地方。更何况把上面那四条人类很容易理解的规则翻译成算法语言，本身就不太容易 —— 到底多不对称才叫“不对称”？怎么不规则才算“不规则”？最后算下来算法的准确度还是不如人类专家。

这里面的关键在于思维方式。 *人类专家做判断，并不是完全基于运用规则。 *

## 2.“什么”和“怎么”

穆克吉打了个比方。比如你给一个小孩讲解“自行车”是什么东西。你可以告诉她，这里是车轮，这里是把手，你骑车要用脚蹬……但是不管你讲得多细，她也仅仅是“知道是什么”，她还是不会骑车。

而另一方面，如果你一句废话没有，直接把自行车交给这个小孩，她坐上去胡乱尝试一番，可能很快就学会了。 **这种状态，叫做“知道该怎么”。**

 *但是请注意，“知道该怎么”可不一定“知道是什么”。* 你让一个会骑车的小孩讲解一番他是怎么骑车的，他根本说不出来。

这个道理是，人的技能之中，有些东西似乎是*无法言传*的。比如一个放射科医生在一张头部CT照片上发现一个轻微中风的病变，你要问他到底是怎么发现的，他有时候也没法把一步一步的全部思路明确告诉你，最后总有些“直觉”之类的东西。

但是别着急，有一种算法恰恰就是专门干这种无法言传的事情的，这就是所谓“深度学习”。其实“深度学习”是近年才开始流行的一个词，有点商业包装的意思，在计算机科学家那里，所谓“深度学习”其实就是“神经网络”算法。

神经网络算法是用数学方法模拟人脑的神经突触网络。用小孩来打比方，这就好比说让一个小孩学习“什么样的东西是狗”。你给他看大量的狗和不是狗的照片，他一开始纯属猜测哪个是狗哪个不是狗，但是每次你都告诉他正确答案。时间长了，他的判断准确度就会越来越高，最后尽管你从来没有向他描述“狗的定义”是什么，他自己就能学会判断狗。

“深度学习”就是这样。事先并不需要输入任何决策规则，让系统自己学着判断。系统内部有各种神经突触连接，如果这一次猜对了，相关的连接就会增强；如果猜错了就会减弱。这样用海量的例子训练，系统自己就能学会判断。

穆克吉介绍的一个系统，是用十三万张相关的皮肤照片“喂”出来的。其中有几千张照片是活组织切片明确认定的黑色素瘤，训练效果就特别好。最后这个神经网络系统的识别准确度达到了77%，显著高于人类专家66%的成绩。

但是神经网络系统有个大问题。它只知道“该怎么”，但是不知道“是什么”。 

## 3.“怎么”和“为什么”

穆克吉采访了几位在第一线研究深度学习的专家，现在所有这些神经网络算法，都有这个问题 —— 你基本上只能把它当成一个“黑箱”。你输入一张照片，黑箱可以告诉你其中是不是有黑色素瘤。但是它是根据什么做出判断的？你一无所知。神经网络怎么生长，生长好了之后怎么解读，我们都不能控制。

有个计算机专家跟穆克吉说，这个系统这么厉害，所以放射科专家和皮肤病诊断专家应该失业。但是穆克吉走访了真正的诊断医生，他们说我们根本没有失业的理由！

因为你这个算法系统根本不理解病变。人类医生并不仅仅告诉你这里有一个病变，他还会告诉你用药时要注意的周围的危险区域，他还会发现没有症状、但是已经产生的肿瘤……因为他*理解*病变。

更关键的是，人类专家除了知道是什么、知道该怎么之外，还会问一个“为什么”。

为什么会有这个病变？为什么黑色素瘤周围是不规则的？为什么会变颜色？这些“为什么”非常宝贵，正因为你问了为什么，你才会进行深入研究，收获新知识，也许就能找到新疗法。

而现在所谓的“深度学习”算法，没有任何理解能力，没有任何解释能力，更不用说什么新发现的能力。

 *是什么、该怎么、为什么，算法只知道该怎么。能把三个问题合在一起全盘考虑的，目前只有人类。 *

## 丨我的评论

我们平时爱说“人工智能”，其实落实到最后，还没有哪个“人工智能”是真的模拟了人的智能 —— 任何人工智能都是一些简单的算法组成的，并不神秘。我们知道人工智能很厉害，但是我们也应该知道，现在所有算法都有局限性，而且是很大的局限性。

不久之后，世界排名第一的围棋棋手柯洁将会代表人类最后一次挑战AlphaGo，所有人都对此很不乐观。估计输是肯定输了，只是希望能下出新的内容。那么AlphaGo这么厉害，作为人类应该作何感想呢？

今天这篇文章，就对我们很有启发。AlphaGo也是深度学习算法的产物，知道“该怎么”而不知道“是什么”，更不会说“为什么”。它的工程师根本就不需要懂围棋，可是AlphaGo已经是绝顶围棋高手，还能经常下出前所未有的创新下法。

那是不是说AlphaGo穷尽了人的智能呢？当然不是。真实世界里的真实问题，不是围棋。围棋的规则是固定的，棋盘只有那么大，理论上所有可能的下法，也只有那么多 —— 这些条件特别适合算法。

而真实世界具有几乎无限的自由度，根本没有明确规则，你沿着任何一个方向深入进去都会遇到各种各样事先没想到的可能性。这些，才是真正的“新”东西。

所以我给柯洁的建议是为什么非得下一盘“正规”围棋呢？如果当场把围棋棋盘从19x19改为21x21 —— 假设事先柯洁和AlphaGo都没在这个尺寸的棋盘上下过棋 —— **你看看谁厉害，谁更会举一反三，谁更能适应新形势，谁，更“会”下棋！ **

## 丨由此得到

人类解决问题，需要从“是什么”、“该怎么”和“为什么”三个角度全盘考虑。而现在人工智能诊断所用的“深度学习”算法，特别善于“该怎么”，但在“是什么”和“为什么”上没有能力。 *人工智能的缺陷，就是人类智能的机会。*

那么至少短期判断，至少在放射科医生这种高端职位上，人工智能也许仅仅是解放了人类，而不是取代了人类。

再跟我们这几天正在说的《意会》这本书联系起来，现在人对事物的“  *理解 * ”，真是越来越重要了。

![https://piccdn3.umiwi.com/img/201704/11/201704111838436844557081.jpg](https://piccdn3.umiwi.com/img/201704/11/201704111838436844557081.jpg)

---
