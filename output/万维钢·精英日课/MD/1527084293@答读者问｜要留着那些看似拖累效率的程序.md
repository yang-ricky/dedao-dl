## 来自日课049:心理学家的心流和中国的道

> 读者问奇迹.Munger.坨坨：找到比自己大的东西，是指那个东西要比自己更重要么？就像我一般跟人相处，要是我的价值观是考虑别人感受第一，那我按照这样做，人家是不是就会觉得，嗯这是个好人，跟她相处真舒心。要是我的价值观是考虑我自己的利益，那么我对别人好其实就是刻意的，这样别人也会察觉得出来，并觉得别扭。按照您对无为的定义，请问上述的两种价值观对于特定的人来说都是比自己大的东西吗？

> 万维钢“考虑别人的感受第一”和“考虑自己的利益”，都不是价值观！这些其实是理性计算，由冷认知负责。这就和我们周五说的墨家学派是一样的，属于效用主义。只不过墨家的效用是针对“有利于国家和社会”，你说的这两种情况是“有利于他人”和“有利于自己”。具体做事的时候，每个动作都要先计算一番是否符合这个“有利于”，完全是理性主导，不可能自然无为。
> 
> “价值观”是融入到热认知的自动倾向，虽然未必是天生的倾向。所谓找到比自己更大的东西，是说我们活在一个故事，一个自我叙事之中。比如很多人有了孩子那一刻，价值观就发生了巨变，给自己讲的故事是我现在是个母亲/父亲了，我要不惜一切代价保护孩子 —— 这就找到了比自己更大的东西。她跟孩子对视的时候，真情流露，有时候就感觉不到时间的流逝，瞬间进入了无为的状态。
> 
> 我无法想象一个人怎么会对身边所有人实行“考虑别人的感受第一”的政策，除非他认为自己是上帝，视身边所有人为孩子。有些特别不愿意伤害别人感情的人，很可能是出于胆小怕事的算计，那么就也是刻意为之，不是无为，别人也不会觉得跟她相处很舒心。
> 
> 那么什么人才能做到每个人跟她相处都很舒心呢？当然是进入了无为状态。就好像前面说的那个对她自己的孩子真情流露的母亲，也许我跟她非亲非故，但我站在旁边看着，也感到特别舒心。
> 
> 这就是“德”的意义。一个无为的人根本没必要考虑别人的感受，别人自动就乐意亲近他。

> 读者问冰河刺客：通过看专栏文章，我了解到人类的价值体系多种多样，并且还在不断变化。价值体系的改变，道也就跟着不同。此文中无为讲究符合天道，那么价值体系的演进又靠什么呢？

> 万维钢我们前面说过《未来简史》。这里说的“价值观体系”，就是《未来简史》里说的“宗教”，也就是人们想象中的“故事”。故事的改变可能跟经济发展、人口结构变化、自然环境变化这些硬条件有关，但也可能是少数几个人想象出来一个新的故事，并且能让别人相信这个故事，那么价值观体系就可以突然变化。赫拉利在《人类简史》中举了个例子：法国大革命。几乎是一夜之间，法国人就从相信“天赋君权”变成相信“人民做主”。
> 
> 每个人都是生活在自我叙事之中，也就是活在自己给自己编的故事里。而这些故事也是随时可变的，也许经历一个事件，甚至看了一本书就能发生价值观的巨变，正所谓“三观俱毁”。

## 来自日课051:伪君子和嬉皮士

> 读者问果条崽：既然无为像宗教信仰，是一个人类共识，那么不同信仰的人应该会认为无为的概念会不一样。这个概念一定能区别出它本来的意思吗？还是它本来针对不同人就是不同的意思呢？对于运动来讲无为是一种庖丁解牛般的状态，但是相对于静止来讲呢？是不是不动就是无为呢？

> 万维钢我理解不同信仰的人达到无为的方法不一样，但是一旦处在无为状态，不论在外人还是在自己看来的感受应该是一样的 —— 你自己觉得特别自在，外人觉得你特别真诚。
> 
> 静止不动不见得是无为。人的天性是想要时不时动一下的，强迫自己不动，显然不是无为。但一个在公园里假装塑像的演员，如果能找到一个什么心法，或者经过长期的训练，能做到保持一动不动的姿势还特别自在，天天表演也没得什么颈椎病，那么他就达到了无为 —— 跟庖丁解牛完全一样。

## 来自日课052:听大脑说话和给大脑编程

> 读者问芦苇：人类有对自己提问的能力，计算机有吗？

> 万维钢如果你说的是对自身状况有一个“认识”，从而产生了一个“真诚的疑问”，那就等于有了“意识”，这个，目前计算机没有。
> 
> 如果你说的是根据事先设定好的程序，自检的时候遇到问题，并且自动着手解决、或者汇报问题 —— 就好像很多程序崩溃以后会弹出个对话框问你是否把这次崩溃报告给开发者 —— 这种是机械化过程，不涉及自我意识，也不是“真诚的”疑问。
> 
> 问题在于！你在理论上，如果只从外面观测的话，可能无法区分这两种情况。一台计算机完全可以因为程序设定*假装*自己有意识，而你在原则上没有办法判断它是不是一台没有意识但是通过了图灵测试的计算机。
> 
> ……就好像你在原则上无法判断写下这条回答的我到底是人还是计算机一样。

> 读者问学而时习之：既然人脑每时每刻都有数不清的程序在运行，那么我的问题是——会不会像我们的手机上那样，有一些预装软件总在后台占用空间，可对于我来说根本没什么毛用，删掉之后系统运行更快，更省电？也就是说，人脑里是否也有很多不仅没用而且拖累效率的程序？

> 万维钢我们重点要说的，就是你应该留着那些看似拖累效率的程序！人脑是个通用设备，不是专门为某一类特殊环境，也不是专门为我们熟悉的日常环境而设计的，它必须尽可能地适应各种不一样的、甚至是非常不常见的环境，所以它才会天生带有很多看似多余的程序。留下这些程序，说不定什么时候就能用到。

> 读者问苏伟：看今日专栏，对人脑恢复一点信心。尤其在面对新情况，悄无声息调出经验、方法论，作出判断，目前人脑还不会被替代。有例证，Google无人驾驶。走的路必须是扫描过的，数据化的，路中间出现个沙袋，它就不知道怎么办了，选择绕过去，结果出了点事故。如果是人，直接压过去就行，这个判断我们看着简单，计算机却还没演进到“冷认知”的地步。这个冷认知处理的是不是“不确定性”，越是不确定，模糊的状况，精准的计算机越是做不到即时判断？而这正是人脑目前的优势所在？

> 万维钢无人驾驶汽车遭遇路上沙袋这个例子说的非常精准！但这里“冷认知”和“不确定性”的说法是值得商榷的。“冷认知、热认知”是说人脑的不同思维方式，对应于计算机就不能这么说了。但是我明白你的意思，你是说计算机有没有这个处理沙袋这个“新”信息的能力。
> 
> 但关键在于，这个“新”信息，是相对于汽车自动驾驶程序已经预先设定和学习过的各种路况而言。凡是程序实现没有设定过的信息—— 可能根本就没有这个变量作为输入项 —— 都是它处理不好的“新”信息。对程序而言这是一个“意外”，但未必是“不确定性”。
> 
> 比如明天是否下雨，这是“不确定性”，但对自动驾驶程序来说，不论是否下雨它都知道怎么应对，所以不算“意外”。

![https://piccdn3.umiwi.com/img/201610/28/201610282232452151987577.jpg](https://piccdn3.umiwi.com/img/201610/28/201610282232452151987577.jpg)

---
