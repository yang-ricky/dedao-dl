# 蝴蝶无效应，安全有小事

“蝴蝶效应”是人们经常谈论的一个科学典故，说巴西的一只蝴蝶震动翅膀，有可能在几周之后，在美国德克萨斯州，导致一场飓风。人们经常用蝴蝶效应形容微小的事情可能带来很大的影响。

而这一讲我想说的是，当人们谈论蝴蝶效应的时候，基本上都说错了。而这个认知错误更体现了一个重要的观念错误。

*

咱们先说说“蝴蝶效应”是怎么来的。

1961年，美国数学家爱德华·洛伦兹（Edward Lorenz）在用计算机模拟天气变化的时候，发现一个有意思的现象。我们知道计算机模拟都有输入的参数和输出的结果。本来有个输入参数的数值应该是 0.506127，有一次模拟中洛伦兹为了省事，就把它给来了个四舍五入，用 0.506 代替。其实我们平时工作中经常这么干，误差不到万分之二，对吧？

可是洛伦兹发现，计算机输出的结果，不是相差万分之二，也不是相差百分之二，也不是相差百分之二十 —— 而是变成了一个完全不同的天气状况。

这就相当于说，你测量某地大气压数值如果有万分之二的误差，你预测出来的天气就从晴天变成下雨了。

这是一个令人绝望的发现。如果是这样的话，请问谁能保证测量的参数都无比准确呢？那所谓的天气预测还有什么意义呢？

不过数学家们可不是第一次遇到这种情况。数学家早就知道，对于“非线性系统”，结果有时候就是会对初始值非常敏感 —— 初始值差一点点，结果就会相差很大。这也是“混沌”这个概念的起源。比如著名的“三体问题”就是一个非线性系统。三个临近的星球在引力作用下会如何运动？开始的位置差一点点，后面的结果就会很不一样。反过来说，“线性系统”就简单了，输入差一点，输出也差一点。

洛伦兹有感于非线性系统这个性质实在太不好对付，就打了个夸张的比方，说这简直就是说巴西的蝴蝶震动翅膀，带来了德克萨斯的一场飓风啊……

*

请注意，洛伦兹说的只是一个夸张的比喻而已。蝴蝶不会导致飓风。

非线性系统并不是完全不可控的系统。今天我们的天气预报是相当准确的，气象局能够很好地预测下雨、下雪、飓风和台风。气象局是通过卫星云图和地面气象数据的观测来预测天气，他们并不需要关注地球上所有的蝴蝶 —— 事实上他们根本就不考虑蝴蝶的事儿。

洛伦兹当初可能正好用了一个特别敏感的模型。事实上并不是所有的非线性系统对所有的输入参数都那么敏感。天气系统并不是一个特别夸张的变化多端的系统。人们经常把股市描写成混沌系统，有些看起来很无害的小波动也有可能带来股市比较大的波动，但是小波动不会导致股灾之类的大事件。

 *人们经常用蝴蝶效应形容小事导致了大事，但这个观念是错误的。如果你对“导致”这个动词的理解跟我一样，我就要说服你，小事不会*导致*大事。*

咱们先看看什么叫“导致”。

*

下面这张图，大概是人心目中蝴蝶效应的一个形象写照 —— 

![https://piccdn3.umiwi.com/img/201906/20/201906201842305640939567.jpg](https://piccdn3.umiwi.com/img/201906/20/201906201842305640939567.jpg)

从小到大的一堆多米诺骨牌排在一起，最大的一块有一个人那么大，最小的一块比指甲盖还小，只能用镊子拿。放倒最小的一块，骨牌就会连锁反应，最终把最大的一块也推倒。

这不就是蝴蝶效应吗？这不就是小骨牌导致了大骨牌的倒下吗？

不是。

 *是这些骨牌的排列方式，导致了大骨牌的倒下。这是一个极其危险的系统。就算最小的骨牌不倒，中间任何一个骨牌倒下，都会导致后面所有的骨牌倒下。*

如果要追责的话，你要问的不是谁推倒了最小的骨牌 —— 最小的骨牌有权做它想做的事情 — 而是谁把骨牌排列成这个样子！这就好比说如果你把一堆炸药堆放在一起，只要一个火星就能引起爆炸，那如果真的爆炸了，你不应该埋怨那个火星，你应该反思的是为什么炸药这么危险的东西不好好管理。

 **火星总会来的。小骨牌总要倒下。蝴蝶总要震动翅膀。你应该怪罪的是系统，而不是导火索。**

*

那什么样的系统容易出危险呢？1979 年，美国宾夕法尼亚州的三里岛核电站，发生了一次严重的反应堆融毁事故。事故没有造成直接或者间接的人员伤亡，但是光是清理费用就超过了 10 亿美元。当时美国政府请了一位叫查尔斯·佩罗（Charles Perrow）的社会学家帮着分析事故原因。佩罗的研究，从此改变了人们对大事故的看法 [1]。

跟一般公众的观点相反，核电站，其实是一种非常不容易出毛病的东西。切尔诺贝利核电站是完全没经验的设计，才出了那么大的灾难。三里岛核电站是老式的设计，安全性能跟今天的新型核电站不能比，但就是这样，它也没那么容易出问题。佩罗发现，三里岛事故，是由三个原因同时起作用导致的 ——

第一，反应堆有个给水系统，正常情况下应该供水，但是出现故障没用供水。本来这个可能性在设计方案中就考虑到了，还有两个备用系统可以自动供水 —— 但不巧的是，备用系统在之前维护的时候被关闭了，没有按规定打开。

第二，因为没有水，反应堆温度就上升，这时候有个泄压阀就自动开启降低温度。等到温度降下来，按理说泄压阀应该自动关闭，可是因为故障它没有关上，于是导致反应堆的冷却剂往外流。

第三，如果工作人员能正确判断发生了什么，也能立即采取有效措施。可是工作人员看到的指示灯显示泄压阀已经关闭了。这是因为指示灯的设计是显示是否已经*命令*泄压阀关闭，而不是显示泄压阀的真实状态。工作人员被误导了。

这三件事只要有一件不发生，大事故就不会发生。英文中有个词叫“完美风暴（perfect storm）”，意思是几个因素恰好一起发生了，导致一个剧烈的后果 —— 三里岛核事故，就是一场完美风暴。

那请问，这个事故里谁是蝴蝶呢？应该指责谁呢？人们本能反应是指责当时负责操作的工作人员，可是三件事是在 13 秒内发生的！工作人员根本来不及反应！

 *佩罗说，我们真正应该指责的是系统。*

*

从三里岛事故出发，佩罗总结，现代几乎所有重大事故 —— 包括飞机坠毁、化工厂爆炸等等 —— 都有两个共同特征。

 **第一个特征是“复杂”。** 中文的“复杂”对应到英文有两个词，一个是 complex，一个是 complicated。后者的意思差不多是“很麻烦、不容易理解”，而前者的意思是系统的各个部分互相关联，不是简单的连接。我们说的这个复杂是 complex。

以前我们专栏说过“系统思维”，我们知道系统里有正反馈和负反馈回路 [2]。正反馈回路会让系统不稳定，负反馈回路会让系统回归稳定。核电站这种系统实在太复杂了，其中有各种反馈回路，有些部分之间的关联还是隐藏的，可能设计者都想不到。那么如果有一个正反馈关联回路是你没想到的，在事故中开启了，就会很麻烦。

 **第二个特征是“紧致耦合（tight coupling）”** 。所谓紧致耦合，就是这个系统缺少缓冲地带 [3]，错一点都不行，没有余闲 [4]。

出现这个情况往往是系统过于追求效率，搞得什么东西都一环套一环可丁可卯，结果错一步就导致后面全错。

比如大桥就是一个不复杂、耦合也不紧的系统。哪个桥墩有问题，不至于马上波及别的桥墩，大桥对付着还能用上一段时间。道路交通也不复杂，但是耦合比较紧，一条路上任何一个地方出事故，整条路都得堵车。大学系统很复杂，但是耦合不紧，教授们就算搞搞政治斗争也翻不了天。可是像核电站和化工厂这种东西，如果又复杂耦合又紧，那就容易出大事故。

*

当人们强调“安全”的时候，总爱说什么要狠抓“安全意识”，什么“年年讲月月讲天天讲”，什么“警钟长鸣”。可是安全意识有用吗？

 *安全意识关注的是蝴蝶。* 如果飓风真的是由蝴蝶引起的，那你就应该好好教育蝴蝶们，不要随便震动翅膀。如果事故真的是因为工作人员疏忽，那你就应该给员工天天讲。

其实“天天讲”是个不好的教育方法，重复的信息会被人脑自动忽略。如果一个烟雾报警器有事儿没事儿动不动就叫，你会直接关掉它了事。

更重要的是，真正的大事故不是蝴蝶引起的。 *我们需要的不是安全意识，而是安全系统。*

*

经常与蝴蝶效应共同出现的一句话是“XX无小事”，这也是一个错误的观念。 *无小事 = 无大事。*

如果一个领导只会笼统地说什么“这很复杂啊！这很重要啊！千里之堤毁于蚁穴啊！核电站无小事！”，我认为这领导啥也不懂。做事得善于分清轻重缓急。敢于忽略小事，你才能做好大事。

把系统搞好了，有缓冲区有余闲有稳定回路，我们就可以有恃无恐。反过来说如果系统不行，人就算整天战战兢兢也难保不出事儿。

 **凡夫畏果，菩萨畏因，我们有现代化管理知识的人还要再加一句：佛畏系统。**

![https://piccdn3.umiwi.com/img/201906/20/201906201844302630238167.jpg](https://piccdn3.umiwi.com/img/201906/20/201906201844302630238167.jpg)

---
