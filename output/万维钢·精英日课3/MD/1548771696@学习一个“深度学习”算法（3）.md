# 学习一个“深度学习”算法（3）

今天是深度学习算法的最后一讲，我们要学习“卷积网络”。上一讲我们说了如何使用一个最简单的神经网络识别手写阿拉伯数字。在理论上，这个方法可以用来学习识别一切图像。你只要把一张张的图片喂给神经网络，告诉它图上有什么，它终将自己发现各个东西的像素规律……但是在实践上，这个方法非常不可行。

计算机不怕“笨办法”，但是哪怕你能让它稍微变聪明一点，你的收获都是巨大的。

## 1.“笨办法”和人的办法

下面这张图（图1）是我随便在网上找的，图中有一只猫、一只狗、绿色的草地和蓝天白云。它的分辨率是350×263，总共92050个像素点。考虑到这是一张彩色照片，每个像素点必须用三个数来代表颜色，这张图要用27万个数来描写。

![https://piccdn3.umiwi.com/img/201901/29/201901292224033459031606.jpg](https://piccdn3.umiwi.com/img/201901/29/201901292224033459031606.jpg)

要想用一个上一讲说的那种误差反向传播神经网络识别这样的图，它第二层每一个神经元都得有27万个权重参数才行。要想能够识别包括猫、狗、草地、蓝天白云这种水平的常见物体，它的输出层必须有上千个神经元才行。这样训练一次的计算量将是巨大的 —— 但这还不是最大的难点。

最大的难点是神经网络中的参数越多，它需要的训练素材就越多。并不是任何照片都能用作训练素材，你必须事先靠*人工*标记照片上都有什么东西作为标准答案，才能给神经网络提供有效反馈。这么多训练素材上哪找呢？

我听罗胖跨年演讲学到一个词叫“回到母体”，意思大约是从新技术后退一步，返回基本常识，也许能发现新的创新点。现在我们回到人脑，想想为什么简单神经网络是个笨办法。

人脑并不是每次都把一张图中所有的像素都放在一起考虑。我们有一个“看什么”，和一个“往哪看”的思路。

让你找猫，你会先大概想象一下猫是什么样子，然后从一张大图上一块一块地找。也许猫在一个角落里，那你只要一个角落一个角落找就行，你没必要同时考虑图片的左上角和右下角。这是“往哪看”。

还有，当你想象猫的时候，虽然不能完全说清，但你毕竟还是按照一定的规律去找。比如猫身上有毛，它有两个眼睛和一条尾巴，等等。你看的不是单个的像素点，你看的是一片一片的像素群的模式变化。这是“看什么”。

我理解“卷积网络”，就是这两个思路的产物。

## 2.竞赛

斯坦福大学有个华裔计算机科学家叫李飞飞，你想必听说过她的名字。李飞飞组织了一个叫做 ImageNet 的机器学习图形识别比赛，从2010年开始每年举行一次。这个比赛的厉害之处在于它每年都给参赛者提供一百万张图片作为训练素材！其中每一张图（图2，图3）都由人工标记了图中有什么物体 ——

![https://piccdn3.umiwi.com/img/201901/29/201901292227340712309697.png](https://piccdn3.umiwi.com/img/201901/29/201901292227340712309697.png)

![https://piccdn3.umiwi.com/img/201901/29/201901292227019104133477.png](https://piccdn3.umiwi.com/img/201901/29/201901292227019104133477.png)

总共有大约一千个物体分类。这就意味着，对每一种物体，人工智能都有大约一千次训练机会。

比赛规则是你用这一百万张训练图片练好自己的程序，然后让程序识别一些新的图片。每张新图片有一个事先设定的标准答案，而你的程序可以猜五个答案，只要其中有一个判断跟标准答案相符合，就算你把这张图判断正确。

下面（图4）是历届比赛冠军的成绩 —— 

![https://piccdn3.umiwi.com/img/201901/29/201901292229459890211558.png](https://piccdn3.umiwi.com/img/201901/29/201901292229459890211558.png)

我们看到2010和2011年，最好成绩的判断错误率都在26%以上，但是2012年，错误率一下子下降到了16%，从此之后就是直线下降。2017年的成绩是2.3%，这个水平已经超过人类 —— 等会儿你会看到，有些图像里的东西连你都不一定能认出来。

那2012年到底发生了什么呢？发生了“卷积网络”。

## 3.卷积网络

2012年的冠军是多伦多大学的一个研究组，他们使用的方法就是卷积网络。正是因为这个方法太成功了，“深度学习”才流行起来，现在搞图形识别几乎全都是用这个方法。获奖团队描述卷积网络的论文的第一作者叫艾利克斯·克里泽夫斯基（Alex Krizhevsky），当时只是一个研究生，这篇论文现在被人称为“AlexNet” [1]。

简单来说，AlexNet 的方法是在最基本的像素到最终识别的物体之间加入了几个逻辑层 —— 也就是“卷积层”。“卷积”是一种数学操作，可以理解成“过滤”，或者叫“滤波”，意思是从细致的信号中识别尺度更大一点的结构。每一个卷积层识别一种特定规模的图形模式，然后后面一层只要在前面一层的基础上进行识别，这就解决了“看什么”和“往哪看”的问题。

我先说一个最直观的例子 [2]（图5，图6）。比如说我们要搞人脸识别，卷积网络方法把问题分解为三个卷积层。

![https://piccdn3.umiwi.com/img/201901/29/201901292230566392812357.png](https://piccdn3.umiwi.com/img/201901/29/201901292230566392812357.png)

![https://piccdn3.umiwi.com/img/201901/29/201901292231302065567044.jpg](https://piccdn3.umiwi.com/img/201901/29/201901292231302065567044.jpg)

第一层，是先从像素点中识别一些小尺度的线条结构。第二层，是根据第一层识别出来的小尺度结构识别像眼睛、耳朵、嘴之类的局部器官。第三层，才是根据这些局部器官识别人脸。其中每一层的神经网络从前面一层获得输入，经过深度学习之后再输出到后面一层。基本思想就是这样。

在细节上，咱们回到 AlexNet 的原始论文，其中足足分了五个卷积层，每一层都由很多个“特征探测器”组成。第一层有96个特征探测器，各自负责探测整个图形中哪些地方有下面这96种特征中的一种 （图7）—— 

![https://piccdn3.umiwi.com/img/201901/29/201901292232000258858110.png](https://piccdn3.umiwi.com/img/201901/29/201901292232000258858110.png)

比如说，第一层的第一个特征探测器，专门负责判断图中哪里有像下面这样，从左下到右上的线条结构（图8） —— 

![https://piccdn3.umiwi.com/img/201901/29/201901292232323061504480.png](https://piccdn3.umiwi.com/img/201901/29/201901292232323061504480.png)

这个特征探测器本身也是一个神经网络，有自己的神经元 —— 而这里的妙处在于，它的每一个神经元只负责原始图像中一个 11×11 小区块 —— 考虑到三种颜色，输入值只有 11×11×3 = 363 个 —— 而且因为这个探测器只负责探测一种结构，每个神经元的参数都是一样的！这就大大降低了运算量。

第一层的其他探测器则负责判断像垂直条纹、斑点、颜色从亮到暗等等各种小结构，一共是96种。

也就是说，卷积网络的第一层先把整个图像分解成11×11的区块，看看每个区块里都是什么结构。为了避免结构被区块拆散，相邻的区块之间还要有相当大的重叠。经过第一层的过滤，我们看到的就不再是一个一个的像素点，而是一张小结构的逻辑图。

然后第二卷积层再从这些小结构上看出更大、更复杂也更多的结构来。以此类推，一直到第五层。下面这张图（图9）表现了从第一层到第三层识别的模块（灰色）和对应的实例（彩色） —— 

![https://piccdn3.umiwi.com/img/201901/29/201901292233049540215205.png](https://piccdn3.umiwi.com/img/201901/29/201901292233049540215205.png)

我们看到，第二个卷积层已经能识别圆形之类的结构，第三层已经能识别车轮和小的人脸。五个卷积层之外，AlexNet 还设置了三个全局层，用于识别更大的物体。整个分层的结构是下面这样 （图10）—— 

![https://piccdn3.umiwi.com/img/201901/29/201901292233549197311061.png](https://piccdn3.umiwi.com/img/201901/29/201901292233549197311061.png)

具体的技术细节我们这里没法讨论，但是你能体会到这样分层的好处： **第一，卷积层中的神经元只要处理一个小区域的数据，而且参数可以重复使用，这就大大减少了运算量。第二，因为可以一个区域一个区域地搜索，就可以发现小尺度的物体。**

意识到图形识别有多难，你就能体会到 AlexNet 的识别水平有多神奇。咱们看看 AlexNet 的识别结果。下面这张图中有个红色的螨虫，它出现在图像的边缘，但是被正确识别出来了 （图11）— 

![https://piccdn3.umiwi.com/img/201901/29/201901292234432354538548.png](https://piccdn3.umiwi.com/img/201901/29/201901292234432354538548.png)

AlexNet 还猜测它可能是蜘蛛、蟑螂、虱子或者海星，但是认为它是螨虫的可能性最高。这个判断水平已经超过了我，我都不知道那是个螨虫。

再比如下面这张图 （图12）—— 

![https://piccdn3.umiwi.com/img/201901/29/201901292235139804219689.png](https://piccdn3.umiwi.com/img/201901/29/201901292235139804219689.png)

标准答案是“蘑菇”，但 AlexNet 给的第一判断是更精确的“伞菌”，“蘑菇”是它的第二选项！

下面这张图是AlexNet判断错误的一个例子。图中（图13）有一只小狗和一堆樱桃，标准答案是“樱桃” —— 

![https://piccdn3.umiwi.com/img/201901/29/201901292235458313664778.png](https://piccdn3.umiwi.com/img/201901/29/201901292235458313664778.png)

AlexNet 首先注意到了那是一只达尔马提亚狗，它判断狗前面是某种水果，但是可能因为颜色太深，没有看出来是樱桃。这道题是不是有点故意难为人了？

而现在基于类似的卷积网络方法的深度学习程序，水平已经远远超过了 AlexNet。

## 4.深度学习（不）能干什么

AlexNet 那篇论文的几个作者成立了一家创业公司，然后这家公司马上就在2013年被 Google 收购了。半年之后，Google 相册就有了搜索能力。紧接着，Google 就可以从自家拍摄的街景图像中识别每家每户的门牌号码了。Google 还夺得了2014年的 ImageNet 竞赛冠军。

所以千万别低估工程师迭代新技术的能力。他们举一反三，一旦发现这个技术好，马上就能给用到极致。2012年之前深度学习还是机器学习中的“非主流”，现在是绝对主流。

深度学习能做一些令人赞叹的事情。比如说对于一个不太容易判断的物体，如果网络知道图中有草地，那么它就会自动判断这应该是一个经常放在户外的东西 —— 而不太可能是一件家具。这完全是基于经验的判断，你不需要告诉他家具一般不放户外。看的图多了，它仿佛获得了一些智慧！一个生活经验少的人可做不到这一点。

但是 arstechnica 那篇文章的作者蒂莫西·李也提醒了我们深度学习不能做什么。比如说，你把一个物体放大一点、或者旋转一个角度、或者调整一下光线，卷积网络就不知道那是同一个东西，它必须得重新判断。深度学习完全是基于经验的判断，它没有任何逻辑推理能力。

 *在我看来，这种学习方法，就如同在数学考试前夜背诵习题集。你能猜对答案是因为你背诵过类似的题，但是你并不真的理解数学。*

这样的算法会有创造力吗？深度学习能发现图像中从来没有被人命名过的“怪异”物体吗？我们见识了光凭经验的操作能强大到什么程度，但是我们也能看出来，它距离真正的智能还非常遥远。

![https://piccdn3.umiwi.com/img/201901/29/201901292241008861111933.jpg](https://piccdn3.umiwi.com/img/201901/29/201901292241008861111933.jpg)

---
