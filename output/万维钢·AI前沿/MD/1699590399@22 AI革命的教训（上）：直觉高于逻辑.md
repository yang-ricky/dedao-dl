# AI革命的教训（上）：直觉高于逻辑

你好，这里是《万维钢·AI前沿》课的加餐内容。

列宁有句话说：「有时候几十年过去了什么都没发生；有时候几个星期就发生了几十年的事。」

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921362720963184/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921362720963184/111012.png)

从2022年年底以来，确实是有恍如隔世之感。我们被AI的突飞猛进给震惊了，我们的一些观念发生了巨变。现在可能我们对一些问题会想的更清楚一些。我觉得这一番AI革命带给我们三个教训，同时我还有两个展望……这一讲先说第一个教训：直觉高于逻辑。

✵

我先说一个最基本的认识。到底什么是AI？以我之见 ——

AI = 基于经验，使用直觉，进行预测。

你用以往的经验数据训练一个模型。这个模型只关心输入和输出。训练完成之后，再给它新的输入，它将给你提供相当不错的输出，你可以把这个动作视为预测。你要问模型是怎么从这个输入算出来那个输出的？回答就是说不清怎么，这是直觉。

在2022年发表的一项研究 [1] 中，DeepMind的科学家做成了一件对物理学家有点降维打击的事儿：用AI控制受控核聚变装置中的等离子体形状。

下面这个装置就是用来搞磁约束核聚变的，叫托卡马克，它是一个面包圈的形状。面包圈里面那些描写成淡黄色的气体就是要参与核聚变的等离子体。在外面一道一道围着面包圈的那些黄色的线圈一通电就会在面包圈内部产生一个磁场，这个磁场将会约束住等离子体保持悬空状态，让这个气体不要撞到墙上。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921387417043816/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921387417043816/111012.png)

你的任务是通过控制那些线圈，来调整那个磁场，从而给等离子体一个理想的形状。可是怎么控制呢？

从线圈的参数到等离子体的形状之间，隔着十万八千里复杂的计算。以前物理学家要么就直接做实验，要么就从物理学基本原理出发，老老实实做数值模拟 —— 而这两种方法都是给定线圈参数，求形状是什么。

可是你真正想要的是指定一个等离子体形状，能不能告诉我线圈得有什么样的参数才能产生这个形状。但既然从参数到形状的「正推」都那么难，这个「逆推」就更是难上加难了。

然而DeepMind使用强化学习的方法，把逆推的问题给解决了。他们能让AI非常精准地操控那些线圈，你想要个什么形状就能给你个什么形状 [2]。这个工作非常漂亮，已经得到了真实实验的证实。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921404596842612/111012.gif](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921404596842612/111012.gif)

……我讲这么多只是为了引用DeepMind论文里的一句话：

「强化学习方法……将重点转移到应该实现什么目标上，而不是如何实现。」

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921421776763504/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921421776763504/111012.png)

这句话有多霸气呢？它的意思是说，你只说想要什么就好，不必问如何得到。

对AI来说，你只需要关心输入和输出。

✵

AI这种做事方法听起来很神奇，但其实这是世界上最自然的思维方式，因为这就是包括人脑在内，各种生物的感知方式。咱们还是回到本系列之前用过的这张图 ——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921437882909544/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921437882909544/111012.png)

因为这个世界是有秩序的，它讲理，什么事情都不会无缘无故发生 [3]，所以我们可以采纳沃尔夫勒姆的哲学，认为世间的一切演化和运动 —— 不论是行星绕着恒星转、一草一木的生长还是一块石头从高处掉下来 —— 都是计算。而我们人类为了认识世界和预测世界，就必须通过某种更简化、更快捷的计算，提前知道真实世界的计算结果。

为此我们使用了两种计算方法，一个是神经网络，一个是形式逻辑。

所谓形式逻辑，就是把问题变成数学问题进行推导。你写下方程，其中每个参数都有特定的意义，每一步推演都有明确的因果关系，你非常清楚每个中间步骤为什么要这样做，你有一个清晰的理论。形式逻辑是人类智慧的伟大发明，也是启蒙运动以来唯一正统的分析问题方法。我们所有的科学理论都是基于形式逻辑的。对任何问题、任何操作，能用形式逻辑表述清楚，你才算是真「懂」。形式逻辑代表「理性」。

从最简单的加减乘除到最复杂的计算机程序和物理学家的数值模拟，人们通常所说的“计算”的都是形式逻辑。形式逻辑要求你严格按照某些规则操作，这对人脑来说其实是很费力的。这就是为什么我们发明了计算机去代替我们执行形式逻辑的算法。

人类原本擅长的、天生就会的计算，其实是神经计算。从大脑到身体，人体是由几个神经网络组成的，它们给你提供各种感知，神经计算就是这些感知的过程。你感到饿了、认出一位朋友的脸、害怕蛇，这些都是大脑对一组身体或者外部信号的解读，解读的过程就是神经计算。神经计算没有可言说的规则，你自己无法把它分解成若干个中间步骤，也说不清都有哪些参数 —— 但你就是能感觉到，而且是快速感觉。这是跟形式逻辑截然不同的计算路线，以至于我们平时都不会把它称为计算。

神经计算和形式逻辑之间有个交集，这是因为人脑也会算些简单的数学题……但算数学题不是我们最擅长的。我们更擅长的是用神经网络直接感知一个复杂的东西。

比如说，当你看见一只猫的时候，你知道那是一只猫 —— 这个能力看似平常，却是几乎无法用形式逻辑描写的。到底是这个物体中的哪些参数让你看出来它是一只猫的？没有方程。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921455062708340/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921455062708340/111012.png)

你只能说因为我见过一些猫，我知道猫是什么样的，所以当我看见一只猫的时候，我知道那是一只猫。

✵

这种说不清的神经感知，正是AI做的事情。AI的本质，就是跟人脑一样的神经计算。

每个AI都有一个模型，这个模型是个神经网络，它有从几百万到几千亿个参数。当我们用已知的经验去训练AI的时候，每一个案例进来，从输入到输出的反馈，都会把这些参数更新一遍，但是每次更新的幅度都非常小。训练过程中你说不清为什么这个案例会让这个参数的数值变大或者变小了那么一点点，训练完毕你也说不清每个参数的意义是什么。然后你使用AI的时候，它每一次的预测推理，都是无数个参数共同参与的过程。

这正如大脑每次想问题，都是无数个神经元共同参与的过程。这个过程之所以说不清，只是因为有太多参数参与，而不是因为它有什么内在的神秘性。

很多人抱怨AI是个黑盒子，从输入直接生成输出，说不清中间发生了什么 —— 可是人脑不也是个黑盒子吗？

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921478685098856/111012.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921478685098856/111012.png)

你开车的时候精心计算过方向盘的角度吗？你打篮球的时候会使用公式描写出手的力度吗？这些判断其实全是神经网络感知。当你走路的时候，当你试图用手拿东西的时候，你都是根据说不清道不明的感觉做一个差不多的动作，这都是我们日用而不知的神经计算。更不用说艺术家的美感和灵感也都是如此。

只是有些时候，神经计算会让我们感到惊奇。比如一个经常抓小偷的老警察，到火车站随便扫两眼，就知道在场谁有可能是小偷。人们问他，你是怎么看出来的？我怎么就看不出来？你这个直觉真神奇！警察说无他，但手熟尔：我只不过看得多了 —— 他的神经网络在抓小偷方面受过很多次训练，而你没有。

对比之下，麻省理工学院在2020年用AI从六万多个化学分子式中找出了一种可用的抗生素，跟警察抓小偷其实没有本质区别。AI只是在训练中见多了分子式而已。

非要说区别，AI跟人脑的区别就在于人脑只适合拿我们在演化环境中熟悉的东西训练，而AI的神经网络可以用任何东西训练 —— 包括分子式、基因序列、磁场线圈参数等等等。

✵

*我们在这个系列的第一讲介绍了基辛格等人对AI的赞叹。他们说AI之所以厉害不在于它“像人” —— 意思是它能做像人一样的事情 —— 而在于它*不像人，它能感知人类既不能用理性认知，也感受不到的规律……我们说这是启蒙运动以来未有之大变局。

*现在回头看，我觉得更准确的说法还是AI*像人。AI的感知方法跟人的感知方法别无二致，只不过比人的范围更广、速度更快、而且可以无限升级而已。

AI，比人更像人。

要这么说的话，也许启蒙运动以来形式逻辑方法的流行，人类学者对「理性」的推崇，只不过是漫长的智能演化史中的一段短暂的插曲。用神经网络直接从输入感知输出，才是更根本、更普遍、更厉害的智能。AI的出现只是让智能回归了本性。

我们意识到，形式逻辑只能用于解决简单的、参数少的、最好是线性的问题；对于真实世界中充斥的像如何控制磁场线圈才能得到特定形状的等离子体这种复杂的、参数多的、非线性的问题，你终究只能依靠神经计算。

所以我们得到的第一个教训是，直觉高于逻辑。

✵

如果AI从此大行其道，以至于神经计算在各个领域取代了形式逻辑，这对社会会有深远的影响。关键是用形式逻辑描写的知识可以一步步写下来，能被人理解，这就意味着它是可传播和可推广的。这位医生发明了一个新疗法，别的医生把他的论文找过来读一读，看看操作步骤，立即就可以在本地复现。这就叫学知识。

但神经计算却是难以推广的。这个AI发现了一种新的抗生素，你问它你是怎么做到的？我能不能用你的操作步骤发现一种消炎药呢？你不能，因为AI说不清它是怎么发现的，这里没有可以用言说的操作步骤。你唯一的办法就是用消炎药的案例重新训练一个AI。

这就意味着除了像GPT那样的语言模型，各种专用AI都是「一事一议」，是本地的，是针对每一个具体应用专门训练的。用美国数据训练出来的自动驾驶AI不能直接拿到中国用，用于操控这个托卡马克装置的AI不能操控另一个装置。

而这又意味着世界上将会有无数个AI。它们为具体的任务而生，有不同的特性，就好像一个个生命体一样。而且它们不是千篇一律的工人，他们是各有性格的工匠。

*你的确不需要问这个活儿是怎么做的 —— 但是你会问是*谁做的。每个AI都不一样，哪怕做的是同样的事，因为经历的训练不一样，它们产出也会各不相同。它们会在自己的作品上签名。

世界将从工业复制时代重归匠人定制时代。AI会像传说中的神奇中医大夫一样给每个病人提供不同的治疗方案，而且全凭感觉治疗，而且各有各的风格。

而那样一个世界，原本是我们熟悉的。

> [1] Degrave, J., Felici, F., Buchli, J. et al. Magnetic control of tokamak plasmas through deep reinforcement learning. Nature 602, 414–419 (2022).
> 
> 
> 
> [2] 图片来自 https://www.wired.com/story/deepmind-ai-nuclear-fusion/
> 
> 
> 
> [3] 当然，量子力学现象在某种意义上可以是“无缘无故”发生的，但这不是重点，而且按照沃尔夫勒姆的观点，可以用多世界理论避开。

## 划重点

1.AI = 基于经验，使用直觉，进行预测。
2.说不清的神经感知，正是AI做的事情。AI的本质，就是跟人脑一样的神经计算。
3.世界将从工业复制时代重归匠人定制时代。AI会像传说中的神奇中医大夫一样给每个病人提供不同的治疗方案，而且全凭感觉治疗，而且各有各的风格。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921565658116212/111012.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023111012/1824921565658116212/111012.jpeg)

---
