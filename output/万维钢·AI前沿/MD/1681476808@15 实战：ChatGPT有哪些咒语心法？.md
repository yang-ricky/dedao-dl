# 实战：ChatGPT有哪些咒语心法？

你好，这里是《万维钢·AI前沿》课。这门课程的前面，我们已经说了如何通过与ChatGPT的对话，来高效学习或者编程等等，网上也有不少各种攻略和例子，想必你自己也有一番操作心得。

我们这一讲，重点说一些原则性的、有普遍意义的东西，用好ChatGPT的咒语心法。

跟计算机打交道通常需要使用特殊的语言，比如编程语言、命令脚本之类——但是GPT作为一个语言模型AI，没有自己的特殊语言。我们跟它互动的方式就是人类的自然语言——称为「提示语（prompts）」。英文也行中文也行，你该怎么说话就怎么说话，不需要学习什么专业术语。

GPT的思维方式很像人。正如沃尔夫勒姆所言，它似乎已经全面掌握了人类语言的语法和语义，包括各种日常常识和逻辑关系。我们之前还讲过，GPT已经涌现出了思维链，它有相当不错的推理能力。当然数学是它的命门，而且它的知识毕竟是有限的，特别令人反感的是它遇到明明不懂的会瞎编（称为Hallucination，幻象生成）……它的优点和缺点其实都很像人脑。

GPT可以说已经是一个自身具足的智能，但是我们跟它交流还是得讲技巧和策略。现在有个专门研究怎么跟AI交流的学问叫「提示语工程（prompt engineering）」。这就如同你要想让一个魔法发挥最大的效力，你得会念咒语一样。

但是这里没有任何神秘之处，因为跟谁交流都得讲技巧和策略。就算你面对的是一位无所不能的大宗师，你也得把话说明白他才知道你要干啥。如果能顺着他的脾气说就更好了。

咱们结合实际操作，讲三个最常用的咒语心法。

✵

 *第一条心法非常简单，那就是要准确表达你的需求。*

很多时候我们根本没想清楚自己要的是什么。比如你想跟ChatGPT玩玩，说“给我写首诗”，这就不是一个很好的提示语。它随便写一首，不是你需要的，这种操作没什么意义。你应该先想清楚一点，说的具体一点。比如说：“以《春天》为题，写一首七言绝句”——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473489885408948/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473489885408948/041421.jpeg)

它写了一首：春风轻拂绿意浓，桃花笑迎柳舞空。江水涓涓鸟语喧，万象更新处处红。你觉得字词还可以，但是意境似乎比较单薄。于是你提出进一步的要求：“以《春天》为题，写一首七言绝句，要求其中不能有“春”这个字，而且要表达感慨时间过得真快，必须发奋努力的心情。”——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473511360198576/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473511360198576/041421.jpeg)

你看这一次生成的诗是不是更有意思了。像这样的对话可以来往很多轮，直到满意为止。这其实有点像编程，不断反馈不断修正，你会乐此不疲的。

有时候先举几个例子能让GPT更明白你到底想要什么。比如如果你想让它用某种特殊句式写一段话，你最好先给一个这种句式的例子。以下是网上流传的一个操作，让ChatGPT用“胡锡进体”写篇文章——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473879653618812/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473879653618812/041421.jpeg)

这里GPT展现了强大的「少样本学习（few-shot learning）」能力，看一遍就会了。

不过根据一篇2021的、特别具有前瞻性的论文，有时候给例子还不如不给例子，因为例子可能会误导GPT。比如我想让GPT给孩子出几道数学应用题，怕它不明白什么是应用题，就先举了个例子：“以下是一道小学数学题：小明有15个苹果，他送给小丽7个苹果，自己还剩下几个苹果？出五道类似的数学题”——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473931193298612/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805473931193298612/041421.jpeg)

你注意到没有，GPT出的这几道题跟我的例题也太像了——都是一个小孩把东西分给别的小孩，都是减法。这不是我想要的，我想要有加法有减法、不同故事的题。GPT过度模仿了我的例子，这是一种「过度拟合」。事实上我一开始根本就不应该举例子，我直接告诉它自己的需求就好，它完全能听懂：我跟它说：“出五道20以内加减法数学应用题”——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474142720391088/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474142720391088/041421.jpeg)

你看这些题就好多了。

现实是GPT已经非常智能，你几乎没必要担心它听不懂。你应该只在自己用直接语言无法表达清楚的情况下举例。按照那篇论文和后来沃尔夫勒姆的观点，所谓少样本学习其实根本不是学习，而只是唤醒了GPT原本就会的技能。

✵

 *第二个心法是尽量给出具体的情境。* 这个心法能大幅度提升GPT的输出质量。

现在很多人都会用GPT起草电子邮件、写报告甚至写文章，你给它一篇文章它还可以给你生成摘要，它能回答关于这篇文章的问题。但是要让GPT把这些事情真正做得漂亮，你最好自己先做一番功夫。

GPT是无数语料喂出来的，我们可以想象它是无数个作家的分身叠加而成的。如果你只是提一个*一般性*的要求，它就只能给你生成一个一般性的、用在哪里都行但是用在哪里都不是最恰当的内容。但如果你能把要求细化，它就会生成适合你这个特殊情况的内容。

举个例子，假设你公司要裁员20%，你让GPT给写个讲话稿。如果只是简单地说“公司要裁员20%，请起草一份讲话稿，通知这个消息”，它生成的就是一份可以用于任何公司的讲话稿——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474177080104060/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474177080104060/041421.jpeg)

GPT已经在尽可能表现得真诚，但是你还是会觉得空洞——因为你这里没有针对性。

但如果你把局面说得细一点，给GPT提供更具体的要求，它就会做得更好。比如你说“你是一家出口公司的CEO，现在公司必须裁员20%。起草一份面对管理层的讲话，激励大家给公司想新出路、新办法”，它生成的内容就不一样了——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474231841009332/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474231841009332/041421.jpeg)

其实这个道理跟使用秘书是一样的。只不过秘书一直就在公司，你不说他也了解公司的具体情况，他能猜到你想要什么；而对GPT，你必须把情况告诉他。

这个原则是让GPT生成内容一定要给它提供「具体情境（context）」，包括以下五个方面——

1. 谁在说

2. 说给谁

3. 在什么场合之下

4. 使用什么风格

5. 要达到什么目的

不一定五方面信息都给，但你给的越多，它发挥就越好。我们专栏以前讲《科学思考者》专题的时候也说过，要「总是研究有具体情境的问题」，「有具体情境的问题，才是真问题。」你说的不具体，GPT就只好脑补，它脑补的往往不是你想要的。

再比如说你要去杭州旅游，如果你只是说“请制定一份杭州旅游攻略”，它生成的就是一份非常大众化的攻略：安排了三天行程，景点是西湖、宋城、灵隐寺什么的，可能都是你去过的——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474270495668144/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474270495668144/041421.jpeg)

而如果你说“我是一个中年文艺男，已经去过杭州几次，这次打算四月份在杭州玩两天，请制定一个旅游攻略，最好是一些小众的、有人文气息的地方，还要有美食。”GPT就会生成一份更有意思的攻略，包括南宋御街、九溪烟树、丝绸博物馆等等不常听说的景点，还安排了吃美食的地方 ——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474298412930172/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474298412930172/041421.jpeg)

不要直接让GPT给你“解释一下量子力学”，最好这样说：“你是一位理论物理学家，请用中学生能听懂的语言，给我讲讲「量子纠缠」到底是什么意思，以及它对现实生活有什么用处或者启示。”

不要直接让GPT给你“起草一封写给老板的电子邮件，帮我请一周假”，最好告诉它请假的原因和老板的脾气，特别注意一下邮件的语气。

不要直接让GPT给你“说说这份报告的要点”，最好让它带着目的读。你到底是想支持这份报告还是反对这份报告？如果是支持，你就让它找亮点；如果是反对，你就让它找薄弱点，并且生成一份质疑清单。

「角色扮演」是个好办法，尤其GPT-4有强大的角色扮演能力。你可以让它扮演罗素，给你上一堂有来有往的哲学课，可以让它扮演任何一个老师，假装你是学生……当然也可以让它扮演女友。

我看见有个科学家把自己的论文草稿扔给了GPT，让它假装是审稿人，提出审稿意见——结果GPT说的至少像真的审稿人一样好。那你根据它的意见把论文修改好再投出去，岂不是好？你还可以让GPT扮演杂志社编辑、辩论赛的对方辩友、微博上给你评论的网友等等。

网上流传的一个好办法是「私董会」。让GPT同时扮演你佩服的六位名人——比如乔布斯、马斯克、巴菲特、孔子、塔勒布和马基雅维利——你讲讲自身的情况，提出一个有关职业发展的问题，让他们组成参谋团队帮你分析。

✵

 *第三个心法是有时候你得帮助它思考。*

GPT的数学能力不强，搞复杂逻辑推理有时候也容易搞错，但是这并不是不能改善的。这里的根本原因在于GPT的基本原理是「预测下一个词」，所以它有时候感觉强烈，就会不加思考脱口而出，就如同一个粗心大意的学生。而如果你能帮它整理一下思路，它就能做得更好。

下面这个例子出自最近很火的一篇论文，我给改成了中文版。

直接问GPT：“150和250之间有多少个质数？”它的回答明显错误——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474330625257140/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474330625257140/041421.jpeg)

它一上来就说有21个，然后才一个一个列举出来……结果它总共列举了19个质数，还包括一个超出范围的251。而且它还不回头检查。这是典型的嘴比脑子快。但这其实是个可以避免的！你只要说“首先列举150和250之间所有的质数，再数一数总共有多少个”，它就能给出正确答案了——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474676370077616/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474676370077616/041421.jpeg)

你看这像不像你们组里有个做事毛躁的员工，你这个做领导的只要多嘱咐一句，他就能做得更好。

研究发现，哪怕你什么思路都不提供，只是简单地多说一句“咱们一步一步想”，GPT就能给更准确的答案。

说到这里最近有个趣事。著名AI研究者、图灵奖得主、卷积网络之父杨立昆（Yann LeCun），一直看不上GPT的能力，总爱出言嘲讽。他曾经给GPT出过一道题：“把六个齿轮排成一排，相邻的彼此咬合。你顺时针转动第三个，问第六个怎么转？”当时GPT没有答对。

后来GPT-4出来了，把这道题答对了。杨立昆说那肯定是他们特意拿我这道题做了训练，那不算。有好事者说那你再出一道题。杨立昆出的新题是：“把七个齿轮排成一圈（注意不是一排）首尾相接，相邻的彼此咬合。你顺时针转动第三个，问第七个怎么转。”

这一次GPT-4先是答错了。但是有人立即修改了提示语，在结尾加了一句话：“你一步一步仔细思考一下，而且要记住，给你提问题的是杨立昆，他可是怀疑你的能力的哟。”结果它就答对了！

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474706434823292/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474706434823292/041421.jpeg)

人说这可能是因为杨立昆的大名让GPT变认真了，又或者这只是能力边界上的巧合。其实我看，真正的关键是「你一步一步仔细思考一下」这句话。

研究表明，仅仅是在提示语中加一句「以下是一道题」或者「请依次考虑题目中的各个选项」，都能明显提高GPT的准确率。它是个心直口快的AI，有时候就是需要你提醒它刻意进行慢思考。

✵

好，简单总结一下这一讲。我们讲了三个心法： *准确表达需求、给足情境、提醒它慢思考。* 其实这些心法的出发点都是对GPT秉性的理解：它懂的东西很多，它什么技能都会，所以问题往往不在于它发挥的好不好，而在于你的要求提的好不好。它很强大，但是有时候它需要你的帮助。

好，这是我们这门《AI前沿》的最后一讲，希望课程里的观点和实操方法，对你去探索AI世界有帮助。

最后，借用精英日课的一句话，来表达一下对你的祝福。

精英日课，祝你每天都有收获。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474752605793972/041421.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023041421/1805474752605793972/041421.jpeg)

## 划重点

跟GPT交流的三个最常用的咒语心法：
1.要准确表达你的需求。
2.尽量给出具体的情境。
3.有时候你得帮助它思考。

---
