## `精英日课5同学@洪亮：`

> 万sir，现在的AIGC（AI生成内容）还是有门槛的，你要知道问什么以及怎么问，才能获得有效的答案。但是随着时间推移，傻瓜化的操作方式会大大降低使用难度，如果使用者连如何调节温度都不需要掌握，人类是否就会确定地往低智商的道路上一直走下去了？

> 万维钢回复——

像GPT这样的生成性大型语言模型，的确是大大降低了用户编程、写文章等做各种事情的难度，可以说是傻瓜化的操作。目前它们还不是完美的，比如ChatGPT生成的程序中可能会有错误，使用者必须真懂行才能用好。但是那不是根本问题。

根本问题是GPT允许我们纯粹用自然语言描述的方式，实现某种自动化操作。今天的GPT可以帮你写程序，也许明天的GPT还可以帮你运行程序，那么我们还要程序干啥？有事儿直接让GPT全面操作岂不是更好。

但即便到了那一步，操纵计算机做事，也不是没有门槛的。就拿编程来说，人还是得先把自己想要实现的功能、输入输出、中间的流程都想清楚，并且以有条理的语言告诉GPT。GPT做的其实是翻译工作：它把自然语言翻译成了程序语言。有了GPT，可能我们再也不需要记住某个编程语言的语法，但是我们还是得知道自己要做的这件事的数学结构。

至少在目前，数学没有过时，审美没有过时，创意没有过时。要这么说的话，GPT不是取代了我们，而是解放了我们。语言模型允许我们忽略语法上的细节，直达事物的本质。

而这也是自从有自动化以来人类社会演进的方向。我记得我小时候，八十年代末，人们非常在意字写得好不好看，小孩被要求天天练字，什么《庞中华硬笔书法》十分流行。那是有道理的，因为文书往来的确字很重要。哪想到现在的人都打字了，人们被从练字中解放出来了。

再比如心算四则运算这一块，什么各种速算法，以前也是个值得夸耀的硬功夫，可是现在人人都有计算器。

那我们可以想见，将来的人，语法能力、编程中严谨不出错的能力，也会下降。但是他们得到的可能更多，他们腾出手来可以去做更高级的事情。

事实上，ChatGPT和各种用AI画画的应用才推出几个月，现在对AI说提示词——也叫「念咒」——已经成了一门手艺，叫「生成提示工程（Prompt engineering）」，或者可以叫「咒语工程」。相应的人员被称为「魔法师」，已经是一个正式工种。

## `精英日课5同学@自然丛林：`

> 我的孩子上初中，以后打算从事人工智能行业，请教现在重点应当学好哪些学科？

> 万维钢回复——

人工智能行业选人，大学专业是很重要的。一般需要计算机科学、自然语言处理、统计学、数据处理、计算机图形等等方面的人才，有的大学直接就有AI专业。对大学生来说，最好是以上面中的一门为主专业，再辅修一个像认知科学、脑科学、心理学、哲学之类的专业，那简直就是定制的AI人才。

对初中生来说，一方面是确保自己能考进一所提供这些专业的好大学，另一方面也应该提前做些准备。最重要的就是数学。有过硬的数学肌肉，才能迅速理解和掌握各种抽象概念，理解比如说程序的逻辑结构。其次是广泛阅读，对世界是怎么回事儿有个合格的了解。

有了ChatGPT，英语和编程现在处于很微妙的境地。一方面AI已经几乎消除了外语障碍，而且还可以帮人编程。我相信您的孩子长大以后，人们会普遍使用自然语言编程。但是另一方面，学习外语和编程并不仅仅是为了这些技能本身，也是对大脑的开拓。但好消息是AI让外语和编程学习都变容易了，现在是事半功倍，那何乐不为呢？

反过来说，像书法、音乐那些流行的课外项目，费时费力费钱，相对于别的项目性价比越来越低。如果不是孩子真有兴趣，应该放弃。

## `精英日课5同学@Charles：`

> 移动网络的兴起让google和baidu们的市场空间变小了，ChatGPT的兴起会不会改变人们获取信息的来源，从而改变商业机构的推广手段呢？

> 万维钢回复——

像ChatGPT和Bing Chat 这种对话模式的信息处理方式，已经对Google搜索产生强烈威胁。Bing Chat 出来以后，Google的股价应声而落，搜索流量也每天都在下降。当然目前下降还没有超过10%，但是趋势是非常可怕的。

Google搜索的广告收入是每年1620亿美元，是它的命脉所在。在搜索页面上加广告是比较自然的，反正你的眼睛也要把整个页面的结果都过一遍，顺带看几个广告没啥不方便。但是如果要在聊天中插播广告，那就太影响使用体验了。前者如同在电视剧播出之前看段广告，后者如同把电视剧剧情用广告给改编了。

Bing Chat 出来以后，Google 迅速推出了自己的聊天机器人 Bard。这还没插广告呢，仅仅是因为Bard在回复中说错了一个有关韦布太空望远镜的事实，都引起了人们强烈的不满。可见人们对聊天体验的要求是很高的。

我用 Bing Chat 这段时间以来，曾经遇到过几次，它把广告插入到对话框外层，这可能是个办法，但是效果有待检验。

目前来说，不论是Google 还是微软，都还没有找到很好的广告解决方案。

现在市面上已经有若干个新型搜索引擎，比如 Neeva，是以不带广告为卖点。也许搜索引擎下一步的出路是付费订阅搜索服务，无广告。

值得一提的是基于GPT的搜索对算力的要求是传统搜索的十倍以上。我们平时总爱说软件服务的边际成本是零——其实不绝对是零，需要很大的算力，很多的芯片和服务器，尤其现在AI芯片那么贵。这个成本也是一个考虑。

我们可以想见，现在Google感到很难受。

## `精英日课5同学@用户73119051：`

> 既然AGI像人的大脑一样学习，是否可以让AGI反过来训练人的大脑呢？一个小孩从小是在人的知识环境中学习的，长大了的认知也是难以理解理性范围外的东西。那如果在AGI的环境中长大会不会也会拥有超级大脑？人的大脑有极限吗？

> 万维钢回复——

大脑的存储能力是海量的，远远谈不上触及极限。大脑这个设备的主要瓶颈在于输入输出和逻辑运算的速度都太慢了。计算机用不了1秒钟就能读一本书，人脑再怎么努力也不可能做到。但是我们有两个安慰，我认为人不用太纠结于自己大脑不够用。

一个是虽然知识是无限的，但是观念是有限的。我在《精英日课》中我们专栏讲过「全覆盖级的读书」「文化自觉」「调用力」，只要一个人对世界大概是怎么回事儿，自己领域大概的逻辑是什么有一定的掌控感，他就可以很好地做事了。

另一个是AI是我们的朋友，可以说是第二大脑。如果你随时都能找到正确答案，又何必非得把答案带在身上呢？

AGI反向训练人的大脑是个好主意，而事实上我们已经在使用新技术训练大脑了。今天的人能接触到的知识，能参与的训练，是过去根本无法想象的，应该好好利用这些条件。

## `精英日课5同学@海绵宝宝：`

> 有两个问题请问万sir。
> 
> （1）像网上那些付费项目比如付费课程，得到的付费课程是不是不在ChatGPT的搜索范围？如果说这些付费项目相比于网上其他资讯质量更高的话，是不是可以说ChatGPT的input其实质量不高？
> 
> （2）我对《人要比AI凶》那一讲的这句话感到有点不可思议：“作为一个语言模型，GPT受到训练素材的限制，像GPT-3的知识就截止到2021年。” 为什么强大如ChatGPT不能实时更新训练素材？尤其是现在世界变化这么大，不敢相信ChatGPT的知识还是2021。

> 万维钢回复——

这两个问题都值得专门回答。付费课程因为没上公网，不在搜索引擎的搜索范围之内。其实不仅是付费课程，包括淘宝的商品之类的信息，现在都对搜索引擎屏蔽了，所以搜索引擎的价值本来就在降低。

但语言模型是另一个故事。根据分析，美国目前还没有一个关于是否可以使用受版权保护的语料训练语言模型的法律规定，也没有判例。版权法的规定是直接把人家的内容复制过来，大段大段地输出，那肯定不行。但训练模型不是复制，是消化之后的转换。OpenAI已经应邀给美国专利版权局发去了一份文件，解释自己对此的理解，它认为使用版权内容训练模型是合法的。但是，官方目前的确还没有一个明确的说法。

最近的一个引人注目的案子是有人对微软和它旗下的Github网站发起了集体诉讼，说Github的AI辅助编程产品，Copilot，侵犯了一些开源代码的版权。那些程序代码本身是开源的，但是也有版权，版权要求你分享和使用都可以，但必须保留原作者的署名——而Copilot直接把一些代码交给别的程序员使用，却没有保留原作者署名。

最近也有艺术家对AI图片生成网站发起诉讼，说你们使用我们的作品训练AI，但是没给我们补偿。也有新闻机构起诉OpenAI，说不应该用他们的文章做训练。

所有这些案子都还没有明确的判决结果，我们先观望。我希望全都允许，让AI的知识最大化有利于人类进步。

第二个问题，我们必须理解训练一个大型语言模型是非常困难的，需要消耗很多的算力，喂很多的语料。所以你不可能每周都训练一遍。好不容易训练一次，模型中几千亿个参数就固定了，法宝就炼制完成了，剩下的就是推理了。ChatGPT背后的模型是GPT-3.5，它应该是去年炼成的，用的语料截止到2021年，非常合理。

让GPT处理新知识有两个办法。一个办法是在模型的基础上再多喂一些料，继续训练，就如同我们上一讲说的训练哲学家丹内特的机器人那样。这个叫做 fine tune （微调），比较费时费力。

另一个办法是让模型临时“学习”新的知识，这就是 Bing Chat 和现在网上很多调用API读书的小工具所做的。这本质上不是训练，而是小样本学习。这个方法的缺点是能输入的信息总量有限。

## `精英日课5同学@菜菜：`

> 当未来AI替代我们做出最佳决定的时候，我们的生活更有秩序更有确定性。但永远不犯错误的生活，是不是也减少了一些刺激和乐趣呢？毕竟有时候错误带给我们的是糟糕的结果，而有时候带来的却是意想不到的惊喜。当我们不再有这些惊喜的时候，人类的无厘头想法、错误、娱乐、幽默……是不是该在虚拟世界中释放了呢？元宇宙是不是也会蓬勃发展？

> 万维钢回复——

你说的很对，生活需要错误和惊喜。但是AI并没有取消我们的错误和惊喜。首先AI输出中有随机变量，你可以让它专门出一些不靠谱但是很有意思的主意。再者，更重要的是，AI只是提供建议，决定权还是掌握在人的手里。

我们下周会讲到，《权力与预测》这本书的一个关键思想是把决策分成「预测」和「判断」两个部分，AI只负责预测，而人负责根据AI的预测进行判断。简单说，就是AI可以精确地告诉你明天下不下雨——但至于带不带伞，还是你自己的判断。我觉得这有可能成为将来AI的一种行为规范。

人总可以不听AI建议自己特立独行，就如同《我，机器人》电影中主人公关闭汽车的自动驾驶，自己驾驶汽车连续超车一样。

不过，保险公司对此会有话说的。不听AI建议，可能会导致保费升高。但是，很多人会认为那是值得的。而且，AI还能算出来保费应该为此升高多少——并不是惩罚，只是为了让系统更公平合理：毕竟不应该让人家老实开车的人为你的任性买单。

所以，人仍然是自由的，只是人会更经常感觉到自己每个选择背后的责任和代价。

## `精英日课5同学@赵二龙：`

> 万Sir，突然想到个问题，如果AI可以预测一切，那么我们体育彩票之类的是不是都可以预测了，那谁都可以得一等奖，到时候也就没有意义了？这会不会为了维护市场秩序对AI做限制呢？

> 万维钢回复——

不会的！AI并不能预测一切，尤其不可能预测彩票号码。AI再厉害也是数学的产物，它不会取消混沌现象，它对乱纪元也是束手无策。即便对于天气，AI也最多能提供更精准的概率——而不是百分之百告诉你五天之后会不会下雨。对股市这样乱的领域，AI已经只能在极短的时间区域中做点工作，还不一定有效。对彩票，因为它的设计机制就是尽可能随机，AI本质上无法预测。

## `精英日课5同学@身斗小民：`

> 这一次ChatGPT的大火，让很多人都在反思为什么颠覆式的创新总发生在美国。我们从小接受的一个观念就是落后就要挨打，遗憾的是这一次我们又慢了一拍。前事不忘后事之师。在科技创新的道路上，我们该如何避免这样的事情再次发生呢？

> 万维钢回复——

如果你把国家想象成一个人，你会猜测他到底做对了或者做错了什么，才带来这样的结果。但一个国家不是一个人，很多事情不是出于意愿，而是出于演化。

中美创新的差异很多。其中有制度上的因素，比如说像OpenAI这种资本密集型的创业公司需要极多的风险投资，那么这里就必须有制度保障，别好不容易把公司做出来你一道禁令就让人家不能变现……

但是就GPT这次突破而言，我觉得最主要的因素不是制度上的。可能更多地是文化和发展阶段。咱们单说一个小侧面。

GPT最让人震撼的一个能力是它会根据你的描述给你编程。特别GPT-4出来以后，可以说现在人人都可以编程，以后编程这件事可以主要依靠自然语言完成。那为什么GPT有那么强的编程能力呢？因为OpenAI从Github网站给它获取了大量的优质训练素材。是微软公司先收购了Github，又把Github的代码数据交给OpenAI。

Github是个程序员社区，号称是“全世界最大的同性交友平台”，程序员们在上面分享代码，互相回答问题，围观高手做项目，切磋编程技艺。

请注意，程序员们在Github上做这些事情不会获得任何收入，分享是自由和免费的。程序员们也没有想什么“我要为将来美国拥有全世界最厉害的AI做贡献”。他们只是出于兴趣。

Github不是特例。在它之前还有GNU，有Linux这样的自由软件社区，也是大家无私分享。而且这些人还特别强调“版权”，但他们说的版权不是为了保证自己赚钱，而是为了保证软件一直是自由的：你用我代码可以，但是你必须继承我的版权——也就是确保这些代码继续是自由的。

这种自由文化不是从天上掉到硅谷的，它来自更早的嬉皮士文化。嬉皮士文化则起源于上世纪六十年代美国风起云涌的社会运动……

简单说，这些人写程序既不仅仅是为了谋生，也不是为了什么建设美国，而是像画画和音乐一样，把它当做一门艺术，一种精神追求。甚至早在上世纪七十年代，就有很多程序员信奉“计算机是有生命的”这样的精神信条。

其实现在国内也有很多程序员在Github上，不过大多数人可能是为了使用，为了查找一段代码，而不是分享和切磋。

咱们这种实用主义文化是可以理解的。如果你整天996，你丈母娘整天担心你还不上房贷，你妻子命令你下班必须赶紧回家，回家必须好好陪孩子，你老板整天盯着你要这要那，你搞个科研项目一小半时间都在写报告和做差旅费报销……你哪有心思琢磨什么编程艺术？

有些人搞技术更多地是享受技术本身的魅力，有些人搞技术是谋生。那你说谁更有可能做出突破性的、意料之外的发现。伟大的科技突破是余闲和余钱的产物，中国房价那么贵、生活那么累，能有多少余闲和余钱。

这不全是金钱激励的问题，也不是愿不愿意奉献的问题，这是社会发展阶段的问题。

## `周毅：`

> ChatGPT在国内无法直接使用，如果长时间没有一个同样强大的国内的语言模型填补空白，那么国内的AI元年是否就推迟了，而按照AI的进化速度，会不会造成全面的落后，并且被AI形成的网络边缘化？会不会导致在AI的未来竞争中被全面压制？

> 万维钢回复——

OpenAI前几天刚刚向印度用户开放了ChatGPT，但是还没有向中国用户开放。企业用户调用GPT都是通过API接口，这个OpenAI自身没有限制，OpenAI甚至可以专门给你家公司开个服务器。但是因为众所周知的原因，中国公司目前并不能合法地使用OpenAI的API。

这只对百度是好事，对中国是坏事。

百度刚刚发布了自家的大型语言模型，叫文心一言。它没有编程功能，没有API，对话能力也远远不如GPT-3。如果非得等百度做好了再用AI，中国的AI应用就会落后。

今年年底，GPT-5就可能出来；再过两年可能就是AGI。到时候国外各行各业已经全面AI化，难道中国这边还要苦等百度吗？挽弓当挽强用箭当用长，我认为中国人民配得上最好的AI。

但我并不认为中国会在AI竞争中被全面压制。我给你看看咱们上周讲「语言模型的开悟时刻」时提到的几篇关键论文的截图——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711058781707840/051918.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711058781707840/051918.png)

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711110321273920/051918.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711110321273920/051918.png)

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711142533528148/051918.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711142533528148/051918.png)

你看看这上面有多少中国人的名字。可以说当今GPT人才的半壁江山是中国人。GPT出来以后网上各种流行应用也有很多是中国人做的。只不过他们都就职于微软、谷歌和斯坦福大学。

所以如果中国在AI上落后，绝对不是因为中国人不行。既然中国人很行，那我们就相信，我们在AI上不会永远落后。

## `精英日课5同学@馮焯林`

> 问万sir，对于data science(数据科学)或者AI之间有什么看法，如果目前你的儿子就要选修硕士的话，你怎么建议？

> 万维钢回复——

我大概会建议他选数据科学。我想给你讲一个正在进行中的故事。

这一波以GPT-4为代表的大型语言模型浪潮，有一个副产品。

它杀死了一门叫做「自然语言处理（Natural Language Processing，简称 NLP）」的学科。

很多大学都有NLP这个专业，很多大公司有专门的NLP研发团队。NLP是计算机科学、AI和人类语言学的交叉学科，此前一直被认为是实现通用人工智能的指望。NLP研究的是如何让机器理解人的语言，它的应用范围包括机器翻译、语音识别、搜索引擎、智能助手等等。这么多年以来，NLP领域在无数人的努力之下，取得了很多成就……

但是，现在那些都已经没有意义了。GPT用的是完全不同的解决思路——无监督学习。Transformer架构和2022年前后发生的「开悟」「涌现」已经自动把NLP想要解决而未能完美解决的问题都给完美解决了。原来AI根本就不需要按照人类帮它寻找的语言规则去学习语言，原来机器自动就能找到各种我们知道——包括我们不知道——的语言规律。翻译也好、语音识别也好、搜索引擎和智能助手也好，都是GPT原生就有的功能。而且它还自动掌握了一大堆包括逻辑推理、少量本学习、自动分类等等功能，还有我们没意识到的功能。

GPT对比于自然语言处理，就如同AlphaZero对比于人类棋手总结的围棋套路。事实证明先靠人类总结规律再教给计算机是个笨办法，是让人的思维拖累了计算机的思维。原来让计算机直接暴力破解才是最根本、最快、最好的办法。

人类棋手还可以继续学围棋套路，毕竟围棋这个游戏本身就很有意思。可是NLP研发人员、教授和学生们该何去何从呢？网络社区里已经在弥漫悲观情绪——

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711284267490880/051918.png](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023051918/1808711284267490880/051918.png)

有些从业者最初的态度是否认——就如同绝症患者最初的反应一样……可是本周GPT-4一出来，局面已经非常明显了。

前两天我刚看到一个消息，“第二十二届中国计算语言学大会”将在2023年8月3日在哈尔滨举行，现在正在征集论文。论文主题包括机器翻译和多语言信息处理、问答系统、机器阅读理解、文本生成、文本摘要、人机对话等等等等……全都是GPT已经用更好的方法给解决完了的。这个大会已经有三十多年的历史，也许今年是他们最后一年。也许会议主题应该改为“GPT已经来了，我们如何重新找工作”。

你的安身立命之法，你钻研了十几年甚至几十年的技术，一夜之间都没有意义了，这是何等的难过。其实被颠覆的不仅仅是NLP这一个学科，其他AI学科，比如贝叶斯分析学派，也都面临危机。著名语言学家乔姆斯基几周前在《纽约时报》发表文章抨击ChatGPT，结果评论区全是骂他的。

朋友们，新时代来了，很多东西都过时了。最荒诞的是GPT并不是故意要淘汰那些学科的，它可能根本都没想过那些学科，只是一次幸运的技术突变导致了这一切。毁灭你，与你何干？

所以赌一门过于狭窄的技术是危险的。回到刚才的问题，数据科学的应用范围更广，不仅限于AI。就算将来AI接管数据分析，你还可以用相关的知识帮助别人理解数据和根据数据做决策，所以也许相对更安全。

好，以上就是这一次加餐的全部内容。希望这些观点能够激发你探索AI的潜力。

此外，关于AI的议题仍在变化中，日后有什么新观点、新看法，我也会更新在这里。也希望你持续关注，我们未来加餐再见。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2024010919/1830515231206449564/010919.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2024010919/1830515231206449564/010919.jpeg)

---
