# 考验：AI来了人有什么用处？

你好，这里是《万维钢·AI前沿》课。这是咱们课程的第二次加餐。我会跟你讲讲AI时代人的作用；再用一讲课程跟你分享几个我平时对AI的用法。

好，我们正式进入这一讲的内容，题目是人有人的用处。

在自动化机器的时代，人到底还有啥用，这个问题其实很早以前就有人思考过，而且得出了经得起时间考验的答案。

早在1950年，控制论之父诺伯特·维纳（Norbert Wiener，1894—1964）就出了本书叫《人有人的用处》，认为生命的本质，其实是信息：我们的使命是给系统提供额外的信息。维纳这个观点直接影响了克劳德·香农（Claude Shannon，1916—2001）。香农后来发明了信息论，指出信息含量的数值，就是在多大的不确定性中做出了选择。我根据香农的信息论写过一篇文章叫《一个基于信息论的人生观》，讲在信息意义上，人生的价值在于争取选择权、多样性、不确定性和自由度。

别人交给你一个任务，你按照规定程序一步步操作就完成了，那你跟机器没有区别。只有这个过程中发生了某种意外，你必须以自己的方式、甚至以自己的价值观解决问题，在这件事情上留下你的印记，才能证明你是一个人，而不是一个工具。

你看，这些思想跟上一讲中沃尔夫勒姆用计算不可约性推导出来的道理是相通的： *人的最根本作用，是选择未来发展的方向。如果让我补充一句，那就是人必须确保自己有足够多的选项和足够大的选择权。*

怎么做到这些呢？

✵

首先是约束AI。科幻小说家艾萨克·阿西莫夫（Isaac Asimov）有个著名的「机器人三定律」，规定——

第一，机器人不得伤害人类，或坐视人类受到伤害；

第二，机器人必须服从人类的命令，除非该命令与第一定律有冲突；

第三，在不违背第一或第二定律的前提下，机器人可以保护自己。

这三条定律好像挺合理，先确保了人类的安全，又确保了机器人有用，还允许机器人自我保护……那你说我们能不能就用这三条定律约束AI呢？阿西莫夫想的挺美，但是可操作性太低了。

首先，什么叫“不伤害”人类？如果AI认为暴力电影会伤害人的情感，它是不是有权不参与拍摄？为了救更多好人，把一个犯罪分子抓起来，算不算是伤害？现实是很多道德难题连人都没搞清楚，你怎么可能指望AI搞清楚呢？

机器人三定律更大的问题是把判断权交给了AI。现实中不会有任何公司会这么做。事实上，各国研发AI，优先级最高的应用就是武器，比如攻击型无人机或者战场机器人——开什么玩笑，这可是国防部的项目，伤害不伤害是你一个AI能说了算的吗？

而最根本的问题，还是沃尔夫勒姆的计算不可约性。凡是能写下来的规则都不可能真正限制住AI，这里面肯定有漏洞，将来肯定有意外。

那你说，就算道可道非常道，可我们人类社会还是有各种法律啊。没错，比如我们有宪法，我们承认宪法不可能穷尽国家未来发展会遇到的所有情况，所以我们保留了修改宪法的程序。理想情况下，对AI的约束也应当如此：我们先制定一套临时的、基本上可操作的规矩让AI遵守，将来遇到什么新情况再随时修改补充，大家商量着办。

但这么做的前提是将来你告诉AI规则修改了，AI得真能听你的才行。

计算不可约性意味着我们对AI的掌控最多只能是动态的，你无法一劳永逸地给它规定死，只能随时遇到新情况随时调整。可是我们前面讲了，AI有它自己的思维方式，如果我们都不能理解AI，又怎么能确保掌控AI呢？

沃尔夫勒姆的判断是，认命吧。人根本不可能永远掌控AI。正确的态度是认可AI有自己的发展规律，你就把AI当成大自然：大自然是我们至今不能完全理解的，大自然偶尔还会降一些灾害给人类，像什么地震、火山爆发，也是我们所无法控制也无法预测的，但是这么多年来，我们也适应了跟大自然相处……

这就是共存。AI将来肯定会对人类造成一定的伤害，正如有汽车就有交通事故，我们认了。

虽然大自然经常肆虐，但人类文明还是存活下来了。沃尔夫勒姆说，其中的根本原因是大自然的各种力量之间、我们跟大自然之间，达成了某种平衡。那么我们将来跟AI的关系也是这样。我们希望人的力量和AI的力量能始终保持大体上的平衡，AI和AI之间也能互相制衡。

而计算不可约性定理支持这个局面。将来不会有什么超强AI一统江湖的，正如历史上从未有过万世不易的独裁政权。可能在某些短期内，会出局部的失衡，带来一些灾祸，但总体上大家的日子总能过下去……这就是我们所能预期的最好结果。

从数学上，AI一定会有别的AI来制衡。但是从实践上，如果人类太弱而AI太强，就好像神话世界一样，各个派系的AI成了大地上行走的神灵，人只能乞求这些神灵帮忙做事，那也不是我们想要的。

为了保证力量平衡，人必须继续参与社会上的关键工作。

✵

AI会逐渐抢走我们的工作吗？至少从工业革命以来的历史经验来说，不会。历史经验是自动化技术创造出来的新职业总是比消灭的职业多。

比如说，以前每打一次电话都需要有个人类接线员帮你接线，那是一份很体面的工作，给高层次女性提供了就业机会。那后来有了自动的电话交换机，不需要接线员了，电话行业的就业人数是不是就减少了呢？恰恰没有。

自动交换机让打电话变得更方便、也更便宜了，于是电话服务的需求量大大增加，这个行业整体变大了，马上又多出了各种岗位，尤其是出现了一些以前不存在的岗位，总的结果是电话行业的就业人数不但没减少，反而还大大增加了。

类似的事情在各个行业反复发生。再比如说有了计算机之后，会计师的工作在一定程度上自动化了，那会计师人数是不是减少了呢？也没有。计算机让金融服务更为普及，使用金融服务的人多了，金融业务变得越来越复杂，各种新法规、新业务模式层出不穷，现在需要更多的会计。

每个行业都是这样。经济学家已经总结出一套规律——

自动化程度越高，生产力就越高，产品就越便宜，市场份额就越大，消费者就越多，生产规模就必须不成比例地扩大，结果是你需要雇佣更多的员工。自动化的确会取代一部分岗位，但是它也会制造出更多的新岗位。

统计研究表明，哪怕对非熟练的制造业工人——他们被认为是最容易被自动化淘汰的人——也是如此，他们也能找到新岗位。美国自动化程度最高的行业也是就业增加最多的行业。反倒是没有充分实现自动化的公司不得不缩小就业规模，要么把生产外包，要么干脆倒闭。

这也就是说，如果哪个国家的政府说我怕AI抢人的工作，所以我要限制AI发展，拒绝自动化，那就太愚蠢了。你保护哪个行业，哪个行业就会落后，就会产品越来越贵消费者越来越少……

现在ChatGPT让编程和公文写作变容易了，Midjourney之类的AI画图工具甚至已经使得有些公司裁掉了一些插画师。但是根据历史规律，它们会创造更多的工作。

比如「提示语工程师」，也就是所谓“魔法师”，就是这几个月刚刚出现的新工种。再比如AI画作如此容易，人们就会要求在生活中各个地方使用视觉艺术。以前家家墙上挂世界名画，未来可能都挂绝无仅有的新画，而且每半小时换一幅。那么可以想见，我们会需要更多善于用AI画画的人。

既然编程变容易了，那每个公司、甚至每个小组都可以要求定制属于自己的软件。既然机器人那么能干，那我们为什么不根据家里人口变动情况，每过一段时间就把房子拆了重建，改改格局呢？

计算不可约性确保了总会有新的工作等着人去干。

✵

而我们必须确保人做的都是高端工作，把低端的留给AI。要做到这一点，我们的教育就必须保证人始终是强势的——而这恰恰不是目前为止大众教育的培养目标。大众教育的培养目标一直都是工具人。

根据沃尔夫勒姆的观点，最高级的工作，是发现新的可能性。搞科学也好搞艺术也好，能给人类创造新的可能性，你就是最先进的。

而其余的人类职业，则应该尽可能利用自动化。说白了就是AI能做好的事儿，你就不要学着做了，你的任务是驾驭AI。这在思想上其实不太容易转过弯来，比如计算器和计算机已经把人从计算中解放出来了，但我们总觉得如果一个人不会心算一位数乘两位数、不会手动算积分，就缺了点什么……其实现在的学生应该把大脑解放出来去学习更高级的技能。

更高级的是什么呢？我结合沃尔夫勒姆的说法，大约有以下这些——

 *一个是「调用力」。* 各种自动化工具都是现成的但是太多了，你得有点学识，才知道干什么事情最适合调用什么工具。就如同ChatGPT知道调用各种插件，你要想对事情有掌控感，最好多掌握一些工具。

 *一个是「批判性思维」。* 既然你要做选择，就得对这个世界是怎么回事有个基本的认识。你得区分哪些是事实，哪些是观点，哪些结论代表当前科学理解，哪些说法根本不值得讨论。你可能还需要一定的计算机思维，不是说非得编程，而是你得善于结构化、逻辑化的思考。

 *然后你还需要艺术和哲学。* 这会提高你的判断力，让你能提出好的问题。艺术修养尤其能让你善于理解他人，这样你才能知道当今社会消费者的需求是什么，乃至于想象出新的需求。

 *你还需要领导力。* 不一定非得是对人的领导力，你至少需要对AI的领导力。这包括制定战略目标、安排工作步骤、设置检验手段等等……管理AI，也是一门学问。

 *然后你还需要一定的传播能力和说服力。* 你能把一个复杂想法解释清楚吗？你能让人接受你的观点吗？你能把产品推销出去吗？高端工作很需要这些。

而所有这些智慧之中，沃尔夫勒姆认为， *人最核心的一个能力，是你得决定你关心什么、你想要什么。* 这只有你自己能决定，因为答案来自你的历史和你的生物结构。这也是至关重要的战略选择，因为如果选不好，你的路可就走差了。

北大考试研究院院长秦春华有个感慨。他去上海面试学生，发现他们的学习成绩、艺术特长、公益事业什么的全都是一模一样的，看起来都很完美实则没有任何特点。最可怕的是，问他们希望自己将来成为什么样的人，很少有人能答上来。

其实美国也差不多，同质化竞争之下，大量优等生都是「优秀的绵羊」。

这些人如果不开悟，几乎肯定会输给AI。你是历史的产物，你是现代教育系统的牺牲品，但你还可以独立学习和思考，你能做出更好的选择。

✵

说白了，这些都是古代贵族学的「自由技艺（liberal arts）」。你就直接把AI想象成是小人和奴隶，咱们都是君子和庄园主。我们要学的不是干活的技能，而是领导的艺术、生活的智慧。

当然历史上很多贵族是非常愚蠢的，搞不好就被人夺了权……所以要想当好贵族，你得学习。

我还是那句话，将来的社会必定是个人人如龙的社会。孔子、苏格拉底和佛陀他们那个轴心时代之所以是轴心时代，就是因为农业技术进步把一部分人解放出来不用干活儿整天想事儿，让社会有了阶层，生活变得复杂。现在AI来得太好了，我们正好回归轴心时代，个个学做圣贤。

好，以上就是这一讲的全部内容。下一讲，跟你分享几个我平时对AI的用法。下一讲见。

## 划重点

1.人的最根本作用，是选择未来发展的方向。人必须确保自己有足够多的选项和足够大的选择权。
2.人必须和AI共存，而我们必须确保人做的都是高端工作。
3.人更高级的技能，是「调用力」、批判性思维、艺术和哲学、领导力、传播能力和说服力。

![https://piccdn2.umiwi.com/uploader/image/ddarticle/2023052615/1809346432621163100/052615.jpeg](https://piccdn2.umiwi.com/uploader/image/ddarticle/2023052615/1809346432621163100/052615.jpeg)

---
