# 48｜计算机的本质：重新理解摩尔定律和信息时代

欢迎来到我的《科技史纲60讲》。

我们上一讲说了信息时代的方法论，那么如果我问你信息时代最大的科技成就是什么，你一定会说是计算机。不仅我们今天离不开计算机，而且它的应用之广远远超出人们的想象。对于计算机我们再熟悉不过了，因此我们在课程中将它的发明过程以及关于计算机大家熟知的部分简化，而采用能量和信息这两个主线分析计算机的本质和发展的过程。

要分析计算机的本质，就要先说说什么是计算机。我们在前面的课程中已经讲过，一种发明找到最初的发明人是很难的，因为人们永远可以往前回溯，不过回溯到太早阶段其实已经没有意义了，因为那些原型和后来的东西在本质上完全是两回事。

关于计算机，人们通常回溯到中国的算盘，关于为什么中国的算盘能够算是计算机，我在《Google方法论》中已经专门介绍过了（延伸阅读：为什么算盘是计算机？）。如果用一句话概括的话，它不仅有计算机的硬件，还有能够控制计算的指令集，也就是珠算口诀，相当于是计算机程序的基础。

那么算盘这种计算机的本质是什么呢？ **就是利用人的能量，在珠算口诀这种信息集合的控制下，完成信息的处理。** 也就是说，计算机需要有能量才能工作，需要信息的控制才能工作。

接下来出现的计算机就是帕斯卡的手动计算机。

简单地讲，帕斯卡发明这种能做加减法的计算机，使用起来不用动脑筋，只要把数字旋钮拨到合适的位置，然后转转手柄就可以了。帕斯卡计算机并不比算盘更快，但是使用起来不需要学习。从能量的角度讲，它不如算盘有效，但是所需要的控制信息少。也就是用能量换信息。

在此之后，又出现了莱布尼茨的计算机，他通过改进机械，能够做更复杂的计算，因为他通过机械实现了一些本来需要指令才能实现的控制。到了19世纪机械论盛行的年代，巴贝奇相信任何运算都可以转变为机械运动，于是他发明了能够做微积分的计算机。

巴贝奇使用非常复杂的机械结构，实现了复杂的运算。他设计的那个庞然大物包括了上万个齿轮和1.5万个其它的零件，重达好几吨，其实人直接操作起来是很费力气的。 **如果从能量的角度讲，要完成复杂的运算就需要更多的能量。**

世界上第一个发明可编程计算机的是德国工程师楚泽。楚泽发现很多运算道理都是一样的，只是改改其中的数字，这种事情应该能让机器完成。在此之前巴贝奇等人的计算机一次只能做一种运算，而楚泽则希望机器能够按照流程完成一系列的运算。这件事自然就需要用程序控制。

楚泽发明的第一台计算机，即Z1，也是纯机械的。它非常复杂，也非常大，因此需要用马达驱动了。由于是纯机械的，一秒钟只能计算一次。也就是说，楚泽的计算机是利用更多的能量、更复杂的信息，完成更复杂的运算。

到目前为止，计算机虽然能完成越来越多的运算，但是消耗的能量也越来越高。打算盘进行一次计算可能只需要一粒芝麻的能量，摆弄帕斯卡和莱布尼茨的计算机就需要一颗绿豆的能量了，而巴贝奇的计算机需要一粒花生米的能量，楚泽的可能要一个橙子的能量。如果按照这个趋势发展下去，人类是无法实现大量的数据计算的。

因此，楚泽在它第二个计算机中就使用了继电器取代机械设备，这样不仅消耗的能量低，而且速度快。为什么继电器的计算机比机械的快呢？因为机械运动有惯性，齿轮不可能正着转完了马上反着转。继电器虽然也有惯性，但是接触和断开的时间间隔可以非常短。如果我们把机械计算机看成是纽卡门蒸汽机，每次工作一下都要等气缸冷却，那么继电器的计算机就如同瓦特改进后的蒸汽机，不再需要冷却这个过程，可以连续工作。

但是继电器开关的频率毕竟有限。如果能用电子设备取代继电器，那么计算的速度可以大幅度提升，这就是美国研制电子计算机的初衷。1946年，世界上第一台通用电子计算机埃尼亚克诞生了，它的速度在当时来讲是飞快的，一秒钟能进行5000次运算。

不过它的能耗也是巨大的，因为它里面有近18000个电子管，每个电子管相当于一个小灯泡，它的耗电量大约是15万瓦，当时它一启动，周围居民家的灯都会变暗。埃尼亚克消耗一度电大约能完成2.5万次运算，我们记住这个数字，以便于后面和今天的计算机作比较。

第一台通用电子计算机埃尼亚克用到了图灵在1936年提出的图灵机的理论。所谓的图灵机，是一种数学模型，它告诉人们，如何利用信息控制机械，实现计算。也就是说，计算的本质是一种机械运动，但它需要信息（指令）控制。计算机的这个本质直到今天都没有改变。至于计算是如何通过机械运动实现的，这就涉及到香农的一项发明——开关电路了。今天所有的集成电路里面其实都是各种各样的开关电路。

自1946年以来，计算机70多年的发展，从本质上讲就是提高能量利用率的过程。这70多年里有三个里程碑是你必须知道的。

 **第一个里程碑是晶体管的诞生，** 它将计算的能耗降低了两个数量级。这是上个世纪50年代的事情。

 **第二个里程碑是集成电路的发明，** 它将计算的能耗又降低了大约两个数量级。这是60年代初的事情。那时消耗一度电量可以完成1亿次的运算了。

 **第三个里程碑则是1965年摩尔提出摩尔定律，** 即集成电路的性能每12个月翻一番，1975年摩尔对摩尔定律有所修正，认为1980年起集成电路的性能每两年就会翻一番。

摩尔和他的同事诺伊斯当时预见到，将很多小集成电路芯片集成到一个大的芯片中，将是未来半导体行业发展的方向。而当时他们所在的仙童公司董事会却意识不到这一点。于是二人离开了仙童创办了英特尔公司。

在随后的半个多世纪里，全世界半导体产业还真按照摩尔当年预见的速度在发展。从英特尔在1971年推出第一款处理器4004到2005年摩尔定律40周年之际，集成电路的性能还真提高了1000万倍，完全符合摩尔定律的要求。

在2005年之后的十多年里，虽然集成电路的进步速度有所放缓，但是基本上还能做到每两年翻一番，这样累积下来又提高了百倍。这样翻番进步叠加的结果是惊人的，以至于我们今天最差劲的智能手机，性能都比当年控制阿波罗登月的巨型计算机系统强很多。

如果我们用单位能耗提供的计算能力来衡量，这个进步也是相当快的。到2018年，世界上最快的橡树岭超级计算机一秒钟最多能完成20亿亿次浮点运算，耗电2.7度，相当于一度电完成了7.5亿亿次的运算，比上世纪60年代最早的集成电路计算机进步了7亿倍左右。

在经历了50年的翻番进步后，基于半导体材料的集成电路里面器件的集成度已经接近了物理的极限。因此有人认为摩尔定律不再适用了。但是，集成电路依然有发展的空间，那便是继续提高单位能耗的计算能力，而不是一个芯片中绝对的计算能力。

如果我们以单位能耗的计算能力来衡量过去70多年计算机的进步，大约是每两年半翻一番，比摩尔定律进步的速度略慢，这中间的差距是源于半导体芯片在变得复杂之后，大量的能量被用在发热而非计算本身上面。实际上从十多年前开始，整个半导体产业的努力方向已经从单纯提高性能，转变为提高单位能耗性能了，并且在沿着这个方向取得了不小的进步。

那么科学家和工程师们是怎么做到这一点的呢？ *简单地讲就是用信息置换能量。* 我们不妨用两个大家经常听说的例子来说明。

第一个就是英伟达公司所谓的人工智能芯片。它其实是一种特殊的图形处理器，并且对很多人工智能的应用作了专门的优化。相比英特尔的通用处理器，它单位能耗的计算能力能提高两个数量级（百倍左右）。

那么英伟达是怎么做到的呢？它其实并没有往处理器里面塞更多的晶体管，而是根据人工智能计算的特点，将计算的精度从64位降低到8位，这样就可以用同样数量的晶体管搭建几十倍的内核了，于是每一个内核的能耗就降低了。而这么做的前提是，需要对人工智能算法的信息处理过程有深刻的了解。

第二个例子是Google的人工智能芯片TPU。Google自己讲，它比英伟达的人工智能芯片单位能耗的计算能力又提高了两个数量级（当然英伟达不承认）。Google是怎么做到的呢？其实这种TPU只适合进行和深度学习有关的计算，不适合其他的信息处理，Google是将深度学习算法的特点设计到了处理器中。

从这两个例子可以看出，如果我们在处理器中将信息处理的算法集成进去，就能大幅度提高单位能耗的计算能力，当然，这样一来相应处理器的应用场景也就受到限制了。不过当某一类计算使用的人非常多了以后，这么做还是值得的。

今天我们使用了能量和信息这两根主线，将人类几千年来，特别是最近几十年来在计算机领域的成就，概括成了十来分钟的内容。这样你就能够看清当今计算机领域的发展方向了，它一直沿着提高单位能耗的计算能力在进步，在过去，这体现为摩尔定律，今天，它更多地体现为利用信息置换能量。 *而计算的本质，就是在信息的控制下，利用能量实现运算。*

 **预告：**

下一讲，我将为你讲述在信息线索上的另外一个伟大科技发明，看看人类是如何把遗传这个生物问题变成信息问题的。我们下一讲再见。

## 吴军锦囊

![https://piccdn3.umiwi.com/img/201903/02/201903022046073148576424.jpg](https://piccdn3.umiwi.com/img/201903/02/201903022046073148576424.jpg)

![https://piccdn3.umiwi.com/img/201903/02/201903022046244545905780.jpg](https://piccdn3.umiwi.com/img/201903/02/201903022046244545905780.jpg)

---
