你好，我是刘松博。我给你带来这篇加餐的原因非常简单。

前两天，OpenAI董事会突然发动“政变”，投票把CEO奥特曼开除了，其后各方登场，神仙掐架，多次反转，最后以奥特曼完胜告终，他不但重返OpenAI，还重组了董事会。

这是一个非常典型的“公司治理”案例。所以我想借这个时间，带你复习一下公司治理的基本知识。

这件事刚发生的时候，很多分析文章认为，这和乔布斯当年被苹果董事会踢出局一样。但如果仔细看，其实奥特曼的情况和乔布斯不一样。

乔布斯被踢出去之前，很多产品都是失败的。而奥特曼是在风头正劲的时刻遭遇狙击，此时距离他在OpenAI开发者大会上发表惊艳演讲仅仅过去十一天。OpenAI正在引起全球的高度关注，估值已经接近900亿。

奥特曼在这种时候被干掉，确实太过突然，出乎所有人，包括他本人的预料，这也使得奥特曼精心设计的治理结构成为被质疑的焦点，很多人认为这是一个彻底失败的治理结构。

但请你先思考一下，如果这个治理结构是彻底失败的，那OpenAI又怎么能如此迅猛地成长为AI王者呢？

为了解答这个问题，我们需要回到公司治理的常识。 **为什么会有公司治理，是因为人性有风险。** 公司制度是不完美的，人类为了弥补和修正这种不完美，逐步探索出一整套公司顶层制度设计。

 **它主要涉及两类人：股东和经理人，主要是涉及两件事：权力和利益。** 400年来，公司治理的制度就在“出现问题-解决问题”的循环中不断完善，逐渐呈现出今天的样貌。

但是在AI时代，公司制度会遇到新问题。为什么呢？我们接下来展开来讲。

首先，拿OpenAI这家公司来说，他们其实在公司治理上是做出了一些有益的尝试的。

原本，这群组织里的人，财富自由，思想自由，能决定处在AI十字路口的人类社会的发展方向，但是他们时刻警惕技术被资本垄断，拒绝股东至上，甚至对员工至上和客户至上也不感冒，而是选择人类至上，要“致力于为人类的最佳利益行事”。

所以，他们采用非营利组织的模式，所有赚的钱都继续投入公司，所有的投资都是捐赠的形式。

但这种形式很快就会带来问题。因为训练大模型需要太多的资金，光靠捐赠没有办法支持这样的烧钱速度，很多优秀的AI人才也不愿接受低于市场水平的薪酬。

这就导致产品迟迟打不开局面，怎么办呢？2019年OpenAI的新治理结构就力图解决这个问题。

简单来说，就是OpenAI设计出一个营利和非营利的混合结构，设立了一家有限合伙企业。

OpenAI的非营利主体作为这个合伙企业的普通合伙人（GP）掌握控制权，其他投资者则作为有限合伙人获得分红收益，但是不参与经营管理，也不进入董事会，这本身就是一个控制权的设计。

不仅如此，OpenAI还为不同阶段进入的资本设计了不同的收益上限，和不同的分步骤退出节奏。举例来说，微软可以用130亿美元的投资，获得920亿的封顶收益，分四步逐渐降低分红比例，并最终彻底退出OpenAI。

你可以理解为OpenAI是向不同的投资人借了不同利率的高利贷，来干自己的事业，等到把钱还完了，这个事业也就跟投资人没啥关系了。正是在这个新治理结构下，大量资金进入公司，OpenAI才获得惊人发展。

而OpenAI的尝试是尤其值得肯定的，因为有一些同样拥有类似理念的人并没有把这条路走通。

同样在2019年，美国181家顶级企业的CEO共同签署了《公司的目的》的宣言，声明不会再把股东利益放在第一位，而是要让每一个美国人都过上有意义和有尊严的美好生活。但后来，他们没有任何路线图和行动细节。

相比之下，奥特曼的治理结构让创始人守住了初心，又能获得资本的支持，还将OpenAI打造成今天最受瞩目的AI翘楚，所以它决不能说是一次彻底失败的尝试。

至少在对股东的利益分配和权力控制上，它是令人满意的。那哪部分出了问题呢？

 **主要是经理人治理环节，包括董事会对经理人产生不信任、合伙人之间内讧。** 但这也可以说是公司治理本身固有的缺陷。为什么这么说，我们得再回到公司治理的常识。

为什么要对经理人进行治理？根本原因是委托代理双方的利益不一致和信息不对称，所以股东会要么会委托董事会对经理人进行监督，要么会让经理人持有公司股份。

但是在OpenAI的治理结构中，股东的权力被限制，他们不能选择代表自己利益的董事， OpenAI甚至为了保证董事会决策不被资本控制，规定拥有投票权的董事是不能有股份的，不管是外部董事还是内部董事，所以包括奥特曼本人也不在公司持股。

不持股对于奥特曼也许不是特别大的问题，因为奥特曼自己已经财务自由，干这件事主要是出于内驱力。

但问题的关键在于董事会的所有人都不持股，这其中包括三个独立的外部董事，和三个不持股的内部董事。

而再进一步说，强化独立董事这个做法本身也是一个补丁，主要是为了消解“内部人控制”现象。

这个补丁也存在新的问题，那就是无法保证那些跟公司没有任何利益关系的董事，一定会为了公司长远发展来做决策，比如OpenAI的董事们就完全没有在意奥特曼出局可能给公司带来的负面影响，甚至认为“宁可让OpenAI毁掉,也要维护其使命”。

另一方面，合伙人内讧也是公司治理要去应对的事情，因为合伙人之间发生矛盾几乎是必然的，最主要的矛盾有三个： **战略矛盾、权力矛盾和利益矛盾。**

这里面大家容易认为利益矛盾是最主要的，但对于很多高端的合伙人来说并不是。比如奥特曼和苏茨克维。虽然我们现在还不知道这次政变的真正原因，但他们两个确实在实现理想的路径上有不同的期待和计划，这就是典型的战略矛盾，战略矛盾继而又引发了激烈的权力矛盾。

一般这种情况怎么解决呢？比如说，合伙人可以约定好特定情况下的议事规则和退出机制，不过这不具有强制性，真有合伙人最后不认也没办法；还有一招就是通过设计章程或者股权架构，来保证某一方的决策权更大。

但OpenAI没这么干，这也是他们被批评的焦点之一。眼看着有乔布斯等创始人被逼宫出局的先例，还有那么多各种成熟的控制权设计方法可参考，他们竟然没有做控制权的设计。

但问题其实并没有这么简单。方法确实很多，比如规定他有一票否决权。但是你想，在2019年他刚刚成为CEO时，董事会怎么能相信他有威望和能力控制OpenAI呢？这可是连马斯克都没做到的事情。也就是说， **公司治理手段就放在那里，还不见得用得了，因为还要考虑种种约束条件。**

好，除了董事会问题和合伙人问题，这次事件还体现出一个更为重要的风险，就是 **AI时代公司治理特有的人性风险。**

比如苏茨克维和三名外部董事可以为了坚持理想而不惜毁掉公司，苏茨克维很快又表示后悔，并且还在要求恢复奥特曼职位的员工联名信上签字，可以看到他在投票时并没有想得很清楚，一次冲动的投票竟然拥有决定人类未来的力量。

有人可能会说，这是因为他们的理想是超越了公司的，所以牺牲公司是可以理解的，但是在公司的视角下，理想主义可能会摧毁实现理想的载体，这是更可怕的。

不仅如此，在资本层面，这个故事还存在另外的可能性。你可以看到，OpenAI过于依赖微软这一家资本，所以也一直被质疑已经沦为资本的棋子。

事实上，在2023年6月，OpenAI又进行了架构的调整，为微软单独成立了一家持股公司，这很可能是为微软参与经营决策铺路。很多人对此表示担心，我非常理解。OpenAI会不会自此后发展进入失控状态，成为大公司操控人类的工具呢？其实并不是没有可能。

在公司治理中，对于企业家的激活和约束是一对悖论，我们的课程曾提到，初创公司要保证创始人的控制权，而公司发展到一定阶段就要把权力放在笼子里。

而OpenAI的难点在于，这是一家刚刚创立没有几年就已经可以决定人类未来命运的公司。虽然当前AI的发展还很初步，但是它的能力太过惊人，所以到底要更多地激活奥特曼，还是要更多地约束他，实在是难以下定论。

我个人认为，考虑到这家公司目前体现出的影响力，还是要对奥特曼有所约束，才是对公司和人类都更加负责的方案。

 **但这次的波折并不完全是坏事，因为它给人类社会探索全新公司治理模式提供了契机。** 时代呼唤一个更加透明、开放、平衡、高效的治理结构，现在已经有了一个开始。

我们一起见证了一个极具意义的历史瞬间，所以我特别想用加餐的形式，把这个瞬间记录在我们的课程中。相信包括奥特曼在内的各方力量会继续优化治理方案，为这次出现的问题打上新的补丁。

另外，我们还有一个外部治理手段可以依赖，那就是政府。当出现可能威胁人类未来的巨大隐患时，政府也会出手。

好，最后，除了OpenAI，其实还有很多先行者，也在探索AI时代的公司治理应该如何设计。

我推荐一家叫Anthropic的公司，这是一家人工智能初创公司，他们研发了一款类似ChatGPT的产品叫Claude，创始人阿莫迪曾是OpenAI的副总裁，他在OpenAI与微软联合后，认为与资本紧密绑定对人工智能安全有严重威胁，所以选择离开公司。

阿莫迪对于OpenAI的治理有很大的质疑，所以他在创办自己的公司时，针对OpenAI治理的缺陷设计了一个全新的架构，长期利益信托。我把Antropic官网上对于这个治理结构的介绍放在了本文的最后作为附录，感兴趣的话，你可以去了解一下。

## 划重点

好，总结一下这一讲的内容：

1、OpenAI设计出了一个营利和非营利的混合结构，让大量资金进入公司，由此获得了惊人发展；但同时，他们也存在经理人治理的问题，包括董事会不持股，以及合伙人之间的矛盾问题。

2、此次OpenAI公司的波折并不是一个完全的坏事，它提醒了我们AI时代公司治理特有的人性风险，给人类社会探索全新公司治理模式提供了契机。

本节课后，请你思考下，如果你是奥特曼，重返公司后，你将有足够的权威来打造新的治理结构，请问你会如何设计OpenAI的治理结构？你认为在治理方面，OpenAI当前最需要优化的是什么？

OpenAI的公司治理作为一个典型案例，很多知识点在我们的课程里面都有所体现，我帮你做了下梳理。距离你上次学习是不是已经很久了，那么，结合案例再来复习一下：

- 没有股份，没有投票权，已经被开掉的奥特曼，靠什么重回公司？创始人如何掌握控制权？

- 为什么董事长布罗克曼也被开除了？董事会里不是董事长最大吗？

- OpenAI的董事会为什么做出这样的冲动的行为？

- OpenAI创立的初衷是不想被资本裹挟，为什么最后还是要和微软强绑定？

- 为什么说奥特曼也需要被控制？

- 公司治理控制奥特曼的手段都有什么？

- 奥特曼和苏茨克维的合作看起来互补到天衣无缝，还是出了嫌隙，为什么会有矛盾？到底是些什么矛盾？

- 合伙人看来是真不好找，应该怎么找合伙人？

- OpenAI的背后大佬，微软的萨提亚·纳德拉再次封神，为什么说他是职业经理人的天花板？

- OpenAI的外部治理力量都有些什么？

- 公司治理是如何发展成今天这样的面貌的？

- 奥特曼如果想成为伟大的企业家，就必须做到企业家自觉。什么是企业家自觉？

附录：

 **长期利益信托**

（The Long-Term Benefit Trust）

今天，我们将分享更多有关我们的新治理结构--"长期利益信托"（LTBT）--的细节，这是我们自Anthropic诞生以来一直在发展的。LTBT 是我们对公司治理进行微调的尝试，以应对我们认为变革性人工智能将带来的独特挑战和长期机遇。

该信托基金是一个独立机构，由五名在财务上无利害关系的成员组成，他们有权选择和罢免我们董事会的一部分成员，随着时间的推移，这部分成员将逐渐增加（最终会成为董事会的多数成员）。LTBT与我们的公益公司地位相配合，有助于使我们的公司治理与我们为人类的长期利益开发和维护先进人工智能的使命保持一致。

 **公司治理基础**

公司由董事会监管。董事会遴选并监督领导团队（尤其是首席执行官），然后由他们聘用和管理员工。默认的公司治理设置使董事在多个方面对股东负责。例如：

- 董事由股东选举产生，并可被股东罢免。

- 董事在法律上对股东负责，履行受托责任。

- 董事通常以公司股票支付薪酬，这有助于使他们的激励与股东的财务利益保持一致。

重要的是，选举、罢免和起诉董事的权利完全属于股东。因此，有人不禁要问，是否允许公司董事为公司股东以外的利益相关者（如客户和公众）进行优化。这个问题争论不休，我们在此不做深入探讨。就目前而言，只要注意到公司法中所有关键的问责机制都促使董事优先考虑股东的经济利益就足够了。

 **微调Anthropic的公司治理**

公司治理经历了数百年的法律先例和迭代，人们对其有效性、优缺点的看法也大相径庭。在 Anthropic，我们的观点是，公司治理能否产生有益于社会的结果，在很大程度上取决于非市场外部性。

外部性是市场失灵的一种类型，当双方之间的交易给未同意交易的第三方带来成本或利益时，就会产生外部性。成本的常见例子包括工厂的污染、银行的系统性金融风险和武器制造商的国家安全风险。积极溢出效应的例子包括教育的社会效益超出了受教育者的范围，或研发投资促进了包含投资公司在内的整个行业的发展。

与公司签订合同的许多方面，如客户、工人和供应商，都有能力谈判或要求价格和条款反映其交换的全部成本和收益。但其他各方，如普通大众，并不直接与公司签订合同，因此没有办法对他们所经历的成本和收益进行收费或支付。

外部性越大，我们就越不期望公司治理的默认做法能够服务于非合同方（如普通大众）的利益。我们认为，人工智能可能会产生前所未有的巨大外部性，从国家安全风险、大规模经济破坏、对人类的根本威胁，到对人类安全和健康的巨大益处，不一而足。

这项技术的发展如此迅速，以至于约束其他高外部性企业活动的法律和社会规范尚未跟上人工智能的步伐；这促使我们投入资金，对 Anthropic 的治理进行微调，以应对我们面临的挑战。

需要明确的是，对于Anthropic公司的大部分日常决策而言，公益性与商业成功或股东回报并不冲突，而且我们的经验表明，这两者往往具有很强的协同作用：我们进行有效安全研究的能力取决于建立前沿模型（商业成功极大地帮助了我们获得这方面的资源），而我们促进 "竞相发展 "的能力则取决于在技术和商业意义上成为生态系统中一家有生存能力的公司。我们不希望 LTBT 介入这些日常决策或我们的普通商业战略。

相反，对治理结构进行微调的必要性最终来自于极端事件的可能性，以及以人类利益为重来处理这些事件的必要性。例如，LTBT 可以确保激励组织领导层仔细评估未来模式的灾难性风险，或确保它们具有国家级别的安全性，而不是将率先进入市场置于所有其他目标之上。

 **基准线： 公共福利公司**

我们已经分享过的一个治理特点是，Anthropic 是一家特拉华州公共福利公司，简称 PBC。与美国大多数大公司一样，Anthropic 也是在特拉华州注册成立的，特拉华州公司法明确允许公益公司的董事在股东的经济利益与公司注册证书中规定的公益目的以及受公司行为重大影响者的最佳利益之间取得平衡。

Anthropic 公司章程中规定的公益目的是负责任地开发和维护先进的人工智能，以长期造福人类。这为我们的董事会提供了权衡决策的长期和短期外部性（例如，是否部署特定的人工智能系统）以及股东经济利益的法律空间。

我们的 PBC 架构所提供的法律自由度对于使 Anthropic 的治理与我们的公益使命保持一致非常重要。但我们认为，这还不足以应对我们在开发变革性人工智能过程中预见到的治理挑战。

虽然 PBC 形式在法律上允许董事平衡公众利益与股东价值最大化，但它并没有让公司董事直接对其他利益相关者负责，也没有让他们的激励机制与公众利益保持一致。我们开始设计一种结构，为我们的董事提供必要的问责和激励机制，以便在关键时刻适当平衡股东的经济利益和我们的公益目的，因为我们预计我们的决策后果将远远超出 Anthropic 的范围。

 **LTBT：基本结构和特点**

Anthropic 长期利益信托基金（LTBT，或称信托基金）是一个独立机构，由五名在人工智能安全、国家安全、公共政策和社会企业方面拥有背景和专业知识的受托人组成。该信托基金的安排旨在使受托人与 Anthropic 的经济利益相隔离，并赋予他们足够的独立性，以平衡公众利益与 Anthropic 股东利益之间的关系。

在 C 轮融资结束时，我们修订了公司章程，创建了一个新的股票类别（T类），由信托机构（the Trust）独家持有。T类股票授予信托机构（the Trust）选举和罢免 Anthropic 董事会成员的权力，这将根据时间和资金的里程碑逐步产生；在任何情况下，信托机构（the Trust）都将在 4 年内选出董事会的大多数成员。同时，我们还设立了一个新的董事席位，由 C 轮及后续投资者选举产生，以确保未来董事会中能直接代表投资者的观点。

T 类股票还包括 "保护条款"，要求信托机构收到可能会显著改变公司或其业务的某些行动的通知。

根据特拉华州的普通法，该信托基金是以 "目的信托 "的形式组建的，其目的与 Anthropic 的目的相同。信托基金必须利用其权力，确保 Anthropic 负责任地平衡股东的经济利益与受 Anthropic 行为影响者的利益以及我们的公益目的。

 **与众不同的股东**

在建立长期利益信托基金的过程中，我们实际上为 Anthropic 创建了一个不同类型的股东。Anthropic 将继续接受董事会的监督，我们希望董事会能在人工智能变革的道路上做出重要决策。

在做出这些决策时，董事会的大多数成员将最终对信托基金和股东负责，从而有动力在公众利益和股东利益之间取得适当平衡。此外，董事会还将受益于在 Anthropic 公益使命的关键领域拥有深厚专业知识和经验的受托人的见解。我们共同相信，信托基金所提供的洞察力和激励机制将在利害关系最大化的时候帮助我们做出更好的决策。

LTBT 的逐步 "分阶段实施 "将使我们能够对试验性结构进行修正，同时也反映了一种假设，即在公司发展的早期，如果治理精简、利益相关者不多，公司往往能够发挥最佳作用；而随着公司日趋成熟，对社会的影响越来越深远，外部性往往会逐渐显现出来，制衡也就变得更加重要。

 **公司治理实验**

长期福利信托基金是一项实验。它的设计是经过深思熟虑的假设，参考了美国一些最有成就的公司治理学者和从业人员的意见，他们帮助我们的领导层设计并 "批判性检查"了这一结构。我们还没有准备好将其作为效仿的榜样；我们是经验主义者，想看看它是如何运作的。

设计过程中最困难的挑战之一，是如何协调信托基金的结构，使其既能抵御最终运行的风险，又能兼顾信托基金的实验性质。重要的是要防止这种安排被轻易推翻，但这样的事情也很难一蹴而就。因此，我们设计了一套修正程序，在持久性和灵活性之间取得了谨慎的平衡。

我们预计，大多数调整将由受托人和 Anthropic 董事会或受托人和其他股东共同商定。不过，鉴于信托基金的试验性质，我们还设计了一系列 "故障安全 "条款，允许在获得足够多的超级多数股东同意的情况下，无需托管人同意即可对信托基金及其权力进行变更。随着信托基金权力的逐步扩大，所需的超级多数也会随之增加，其理论依据是，随着时间的推移，我们会积累更多的经验，而且对反复修改的需求也会减少，风险也会越来越大。

 **首任托管人**

首批受托人是：

杰森-马特尼（Jason Matheny）： 兰德公司首席执行官

卡尼卡-巴哈尔 证据行动组织首席执行官兼总裁

尼尔-巴迪-沙阿：克林顿健康获取倡议组织首席执行官（主席）

保罗-克里斯蒂亚诺 对齐研究中心创始人

扎克-罗宾逊：美国有效风险投资公司临时首席执行官

Anthropic董事会在经过长达一年的搜寻和面试后，选出了这些首批受托人，这些受托人思想深邃、品格高尚，对人工智能的风险、益处和发展轨迹及其对社会的影响有着深刻的理解。受托人的任期为一年，未来的受托人将由受托人投票选举产生。我们很荣幸这批创始理事选择接受他们在信托基金中的席位，我们相信他们将提供宝贵的洞察力和判断力。

文章来源：https://www.anthropic.com/index/the-long-term-benefit-trust?continueFlag=8e8aee31b6c8da05e9985b154f1c92b6

---
